# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
"""
TensorFlow, Keras and TFLite versions of YOLOv5
Authored by https://github.com/zldrobit in PR https://github.com/ultralytics/yolov5/pull/1127

Usage:
    $ python models/tf.py --weights yolov5s.pt

Export:
    $ python export.py --weights yolov5s.pt --include saved_model pb tflite tfjs
"""

import argparse
import sys
from copy import deepcopy
from pathlib import Path

FILE = Path(__file__).resolve()
ROOT = FILE.parents[1]  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è YOLOv5
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ ROOT –≤ PATH

import numpy as np
import tensorflow as tf
import torch
import torch.nn as nn
from tensorflow import keras

from models.common import (C3, SPP, SPPF, Bottleneck, BottleneckCSP, C3x, Concat, Conv, CrossConv, DWConv,
                           DWConvTranspose2d, Focus, autopad)
from models.experimental import MixConv2d, attempt_load
from models.yolo import Detect, Segment
from utils.activations import SiLU
from utils.general import LOGGER, make_divisible, print_args


class TFBN(keras.layers.Layer):
    # –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è TensorFlow BatchNormalization
    def __init__(self, w=None):
        super().__init__()
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ—è —Å –≤–µ—Å–∞–º–∏ –∏–∑ PyTorch
        self.bn = keras.layers.BatchNormalization(
            beta_initializer=keras.initializers.Constant(w.bias.numpy()),
            gamma_initializer=keras.initializers.Constant(w.weight.numpy()),
            moving_mean_initializer=keras.initializers.Constant(w.running_mean.numpy()),
            moving_variance_initializer=keras.initializers.Constant(w.running_var.numpy()),
            epsilon=w.eps)

    def call(self, inputs):
        return self.bn(inputs)


class TFPad(keras.layers.Layer):
    # –ü–∞–¥–¥–∏–Ω–≥ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏–∑–º–µ—Ä–µ–Ω–∏—è—Ö 1 –∏ 2
    def __init__(self, pad):
        super().__init__()
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø–∞–¥–¥–∏–Ω–≥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç TensorFlow
        if isinstance(pad, int):
            self.pad = tf.constant([[0, 0], [pad, pad], [pad, pad], [0, 0]])
        else:  # tuple/list
            self.pad = tf.constant([[0, 0], [pad[0], pad[0]], [pad[1], pad[1]], [0, 0]])

    def call(self, inputs):
        return tf.pad(inputs, self.pad, mode='constant', constant_values=0)


class TFConv(keras.layers.Layer):
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True, w=None):
        # ch_in, ch_out, –≤–µ—Å–∞, —è–¥—Ä–æ, —à–∞–≥, –ø–∞–¥–¥–∏–Ω–≥, –≥—Ä—É–ø–ø—ã
        super().__init__()
        assert g == 1, "TF v2.2 Conv2D –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 'groups'"
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–≤–µ—Ä—Ç–∫–∏ —Å —É—á–µ—Ç–æ–º –ø–∞–¥–¥–∏–Ω–≥–∞
        conv = keras.layers.Conv2D(
            filters=c2,
            kernel_size=k,
            strides=s,
            padding='SAME' if s == 1 else 'VALID',
            use_bias=not hasattr(w, 'bn'),
            kernel_initializer=keras.initializers.Constant(w.conv.weight.permute(2, 3, 1, 0).numpy()),
            bias_initializer='zeros' if hasattr(w, 'bn') else keras.initializers.Constant(w.conv.bias.numpy()))
        self.conv = conv if s == 1 else keras.Sequential([TFPad(autopad(k, p)), conv])
        self.bn = TFBN(w.bn) if hasattr(w, 'bn') else tf.identity
        self.act = activations(w.act) if act else tf.identity

    def call(self, inputs):
        return self.act(self.bn(self.conv(inputs)))


class TFDWConv(keras.layers.Layer):
    # –ì–ª—É–±–∏–Ω–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞
    def __init__(self, c1, c2, k=1, s=1, p=None, act=True, w=None):
        # ch_in, ch_out, –≤–µ—Å–∞, —è–¥—Ä–æ, —à–∞–≥, –ø–∞–¥–¥–∏–Ω–≥, –≥—Ä—É–ø–ø—ã
        super().__init__()
        assert c2 % c1 == 0, f'–í—ã—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä {c2} –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫—Ä–∞—Ç–Ω—ã–º {c1}'
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–ª—É–±–∏–Ω–Ω–æ–π —Å–≤–µ—Ä—Ç–∫–∏
        conv = keras.layers.DepthwiseConv2D(
            kernel_size=k,
            depth_multiplier=c2 // c1,
            strides=s,
            padding='SAME' if s == 1 else 'VALID',
            use_bias=not hasattr(w, 'bn'),
            depthwise_initializer=keras.initializers.Constant(w.conv.weight.permute(2, 3, 1, 0).numpy()),
            bias_initializer='zeros' if hasattr(w, 'bn') else keras.initializers.Constant(w.conv.bias.numpy()))
        self.conv = conv if s == 1 else keras.Sequential([TFPad(autopad(k, p)), conv])
        self.bn = TFBN(w.bn) if hasattr(w, 'bn') else tf.identity
        self.act = activations(w.act) if act else tf.identity

    def call(self, inputs):
        return self.act(self.bn(self.conv(inputs)))


class TFDWConvTranspose2d(keras.layers.Layer):
    # –ì–ª—É–±–∏–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞
    def __init__(self, c1, c2, k=1, s=1, p1=0, p2=0, w=None):
        # ch_in, ch_out, –≤–µ—Å–∞, —è–¥—Ä–æ, —à–∞–≥, –ø–∞–¥–¥–∏–Ω–≥, –≥—Ä—É–ø–ø—ã
        super().__init__()
        assert c1 == c2, '–í—Ö–æ–¥–Ω–æ–π –∏ –≤—ã—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä—ã –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å'
        assert k == 4 and p1 == 1, '–¢–æ–ª—å–∫–æ k=4 –∏ p1=1 –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è'
        # –†–∞–∑–±–∏–≤–∫–∞ –≤–µ—Å–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–∞–ª–∞
        weight, bias = w.weight.permute(2, 3, 1, 0).numpy(), w.bias.numpy()
        self.c1 = c1
        self.conv = [
            keras.layers.Conv2DTranspose(filters=1,
                                         kernel_size=k,
                                         strides=s,
                                         padding='VALID',
                                         output_padding=p2,
                                         use_bias=True,
                                         kernel_initializer=keras.initializers.Constant(weight[..., i:i + 1]),
                                         bias_initializer=keras.initializers.Constant(bias[i])) for i in range(c1)]

    def call(self, inputs):
        return tf.concat([m(x) for m, x in zip(self.conv, tf.split(inputs, self.c1, 3))], 3)[:, 1:-1, 1:-1]


class TFFocus(keras.layers.Layer):
    # –°–∂–∞—Ç–∏–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –≤ –∫–∞–Ω–∞–ª—ã
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True, w=None):
        # ch_in, ch_out, —è–¥—Ä–æ, —à–∞–≥, –ø–∞–¥–¥–∏–Ω–≥, –≥—Ä—É–ø–ø—ã
        super().__init__()
        # –°–≤–µ—Ä—Ç–æ—á–Ω—ã–π —Å–ª–æ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∂–∞—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.conv = TFConv(c1 * 4, c2, k, s, p, g, act, w.conv)

    def call(self, inputs):  # x(b,w,h,c) -> y(b,w/2,h/2,4c)
        # –°–∂–∞—Ç–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—É—Ç–µ–º –¥–µ–∫—Å–∏–º–∞—Ü–∏–∏
        inputs = [inputs[:, ::2, ::2, :], inputs[:, 1::2, ::2, :], inputs[:, ::2, 1::2, :], inputs[:, 1::2, 1::2, :]]
        return self.conv(tf.concat(inputs, 3))


class TFBottleneck(keras.layers.Layer):
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –±—É—Ç—ã–ª–æ—á–Ω—ã–π —Å–ª–æ–π
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5, w=None):  # ch_in, ch_out, shortcut, –≥—Ä—É–ø–ø—ã, —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        super().__init__()
        c_ = int(c2 * e)  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        # –°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–ª–æ–∏ –±—É—Ç—ã–ª–æ—á–Ω–æ–≥–æ —Å–ª–æ—è
        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)
        self.cv2 = TFConv(c_, c2, 3, 1, g=g, w=w.cv2)
        self.add = shortcut and c1 == c2

    def call(self, inputs):
        return inputs + self.cv2(self.cv1(inputs)) if self.add else self.cv2(self.cv1(inputs))


class TFCrossConv(keras.layers.Layer):
    # –ö—Ä–æ—Å—Å-—Å–≤—ë—Ä—Ç–∫–∞
    def __init__(self, c1, c2, k=3, s=1, g=1, e=1.0, shortcut=False, w=None):
        super().__init__()
        c_ = int(c2 * e)  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        # –°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–ª–æ–∏ –¥–ª—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –∏ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è
        self.cv1 = TFConv(c1, c_, (1, k), (1, s), w=w.cv1)
        self.cv2 = TFConv(c_, c2, (k, 1), (s, 1), g=g, w=w.cv2)
        self.add = shortcut and c1 == c2

    def call(self, inputs):
        return inputs + self.cv2(self.cv1(inputs)) if self.add else self.cv2(self.cv1(inputs))

class TFConv2d(keras.layers.Layer):
    # –ó–∞–º–µ–Ω–∞ –¥–ª—è PyTorch nn.Conv2D
    def __init__(self, c1, c2, k, s=1, g=1, bias=True, w=None):
        super().__init__()
        assert g == 1, "TF v2.2 Conv2D –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 'groups'"
        # –°–ª–æ–π —Å–≤–µ—Ä—Ç–∫–∏ —Å –≤–µ—Å–∞–º–∏ –∏–∑ PyTorch
        self.conv = keras.layers.Conv2D(filters=c2,
                                        kernel_size=k,
                                        strides=s,
                                        padding='VALID',
                                        use_bias=bias,
                                        kernel_initializer=keras.initializers.Constant(
                                            w.weight.permute(2, 3, 1, 0).numpy()),
                                        bias_initializer=keras.initializers.Constant(w.bias.numpy()) if bias else None)

    def call(self, inputs):
        return self.conv(inputs)


class TFBottleneckCSP(keras.layers.Layer):
    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, w=None):
        # ch_in, ch_out, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, shortcut, –≥—Ä—É–ø–ø—ã, —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        super().__init__()
        c_ = int(c2 * e)  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)
        self.cv2 = TFConv2d(c1, c_, 1, 1, bias=False, w=w.cv2)
        self.cv3 = TFConv2d(c_, c_, 1, 1, bias=False, w=w.cv3)
        self.cv4 = TFConv(2 * c_, c2, 1, 1, w=w.cv4)
        self.bn = TFBN(w.bn)
        self.act = lambda x: keras.activations.swish(x)
        self.m = keras.Sequential([TFBottleneck(c_, c_, shortcut, g, e=1.0, w=w.m[j]) for j in range(n)])

    def call(self, inputs):
        y1 = self.cv3(self.m(self.cv1(inputs)))
        y2 = self.cv2(inputs)
        return self.cv4(self.act(self.bn(tf.concat((y1, y2), axis=3))))


class TFC3(keras.layers.Layer):
    # CSP Bottleneck —Å —Ç—Ä–µ–º—è —Å–≤–µ—Ä—Ç–∫–∞–º–∏
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, w=None):
        # ch_in, ch_out, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, shortcut, –≥—Ä—É–ø–ø—ã, —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        super().__init__()
        c_ = int(c2 * e)  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)
        self.cv2 = TFConv(c1, c_, 1, 1, w=w.cv2)
        self.cv3 = TFConv(2 * c_, c2, 1, 1, w=w.cv3)
        self.m = keras.Sequential([TFBottleneck(c_, c_, shortcut, g, e=1.0, w=w.m[j]) for j in range(n)])

    def call(self, inputs):
        return self.cv3(tf.concat((self.m(self.cv1(inputs)), self.cv2(inputs)), axis=3))


class TFC3x(keras.layers.Layer):
    # C3 –º–æ–¥—É–ª—å —Å –∫—Ä–æ—Å—Å-—Å–≤—ë—Ä—Ç–∫–∞–º–∏
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, w=None):
        # ch_in, ch_out, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, shortcut, –≥—Ä—É–ø–ø—ã, —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        super().__init__()
        c_ = int(c2 * e)  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)
        self.cv2 = TFConv(c1, c_, 1, 1, w=w.cv2)
        self.cv3 = TFConv(2 * c_, c2, 1, 1, w=w.cv3)
        self.m = keras.Sequential([
            TFCrossConv(c_, c_, k=3, s=1, g=g, e=1.0, shortcut=shortcut, w=w.m[j]) for j in range(n)])

    def call(self, inputs):
        return self.cv3(tf.concat((self.m(self.cv1(inputs)), self.cv2(inputs)), axis=3))


class TFSPP(keras.layers.Layer):
    # Spatial pyramid pooling —Å–ª–æ–π –∏–∑ YOLOv3-SPP
    def __init__(self, c1, c2, k=(5, 9, 13), w=None):
        super().__init__()
        c_ = c1 // 2  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)
        self.cv2 = TFConv(c_ * (len(k) + 1), c2, 1, 1, w=w.cv2)
        self.m = [keras.layers.MaxPool2D(pool_size=x, strides=1, padding='SAME') for x in k]

    def call(self, inputs):
        x = self.cv1(inputs)
        return self.cv2(tf.concat([x] + [m(x) for m in self.m], 3))


class TFSPPF(keras.layers.Layer):
    # Spatial pyramid pooling-Fast —Å–ª–æ–π
    def __init__(self, c1, c2, k=5, w=None):
        super().__init__()
        c_ = c1 // 2  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)
        self.cv2 = TFConv(c_ * 4, c2, 1, 1, w=w.cv2)
        self.m = keras.layers.MaxPool2D(pool_size=k, strides=1, padding='SAME')

    def call(self, inputs):
        x = self.cv1(inputs)
        y1 = self.m(x)
        y2 = self.m(y1)
        return self.cv2(tf.concat([x, y1, y2, self.m(y2)], 3))


class TFDetect(keras.layers.Layer):
    # TF YOLOv5 –¥–µ—Ç–µ–∫—Ç —Å–ª–æ–π
    def __init__(self, nc=80, anchors=(), ch=(), imgsz=(640, 640), w=None):  # detection layer
        super().__init__()
        self.stride = tf.convert_to_tensor(w.stride.numpy(), dtype=tf.float32)
        self.nc = nc  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
        self.no = nc + 5  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–æ–≤ –Ω–∞ —è–∫–æ—Ä—å
        self.nl = len(anchors)  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ç–µ–∫—Ç —Å–ª–æ–µ–≤
        self.na = len(anchors[0]) // 2  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–∫–æ—Ä–Ω—ã—Ö –±–æ–∫—Å–æ–≤
        self.grid = [tf.zeros(1)] * self.nl  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ç–∫–∏
        self.anchors = tf.convert_to_tensor(w.anchors.numpy(), dtype=tf.float32)
        self.anchor_grid = tf.reshape(self.anchors * tf.reshape(self.stride, [self.nl, 1, 1]), [self.nl, 1, -1, 1, 2])
        self.m = [TFConv2d(x, self.no * self.na, 1, w=w.m[i]) for i, x in enumerate(ch)]
        self.training = False  # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å False –ø–æ—Å–ª–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        self.imgsz = imgsz
        for i in range(self.nl):
            ny, nx = self.imgsz[0] // self.stride[i], self.imgsz[1] // self.stride[i]
            self.grid[i] = self._make_grid(nx, ny)

    def call(self, inputs):
        z = []  # –í—ã—Ö–æ–¥ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        x = []
        for i in range(self.nl):
            x.append(self.m[i](inputs[i]))
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ x(bs,20,20,255) ‚Üí x(bs,3,20,20,85)
            ny, nx = self.imgsz[0] // self.stride[i], self.imgsz[1] // self.stride[i]
            x[i] = tf.reshape(x[i], [-1, ny * nx, self.na, self.no])

            if not self.training:  # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
                y = x[i]
                grid = tf.transpose(self.grid[i], [0, 2, 1, 3]) - 0.5
                anchor_grid = tf.transpose(self.anchor_grid[i], [0, 2, 1, 3]) * 4
                xy = (tf.sigmoid(y[..., 0:2]) * 2 + grid) * self.stride[i]  # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã xy
                wh = tf.sigmoid(y[..., 2:4]) ** 2 * anchor_grid  # –†–∞–∑–º–µ—Ä—ã wh
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                xy /= tf.constant([[self.imgsz[1], self.imgsz[0]]], dtype=tf.float32)
                wh /= tf.constant([[self.imgsz[1], self.imgsz[0]]], dtype=tf.float32)
                y = tf.concat([xy, wh, tf.sigmoid(y[..., 4:5 + self.nc]), y[..., 5 + self.nc:]], -1)
                z.append(tf.reshape(y, [-1, self.na * ny * nx, self.no]))

        return tf.transpose(x, [0, 2, 1, 3]) if self.training else (tf.concat(z, 1),)

        @staticmethod
        def _make_grid(nx=20, ny=20):
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ç–∫–∏ –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
            xv, yv = tf.meshgrid(tf.range(nx), tf.range(ny))
            return tf.cast(tf.reshape(tf.stack([xv, yv], 2), [1, 1, ny * nx, 2]), dtype=tf.float32)

    class TFSegment(TFDetect):
        # –ì–æ–ª–æ–≤–∞ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ YOLOv5
        def __init__(self, nc=80, anchors=(), nm=32, npr=256, ch=(), imgsz=(640, 640), w=None):
            super().__init__(nc, anchors, ch, imgsz, w)
            self.nm = nm  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Å–æ–∫
            self.npr = npr  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ç–æ—Ç–∏–ø–æ–≤
            self.no = 5 + nc + self.nm  # –í—ã—Ö–æ–¥—ã –Ω–∞ —è–∫–æ—Ä—å
            self.m = [TFConv2d(x, self.no * self.na, 1, w=w.m[i]) for i, x in enumerate(ch)]  # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
            self.proto = TFProto(ch[0], self.npr, self.nm, w=w.proto)  # –ü—Ä–æ—Ç–æ—Ç–∏–ø—ã
            self.detect = TFDetect.call

        def call(self, x):
            p = self.proto(x[0])
            # p = TFUpsample(None, scale_factor=4, mode='nearest')(self.proto(x[0]))  # –ü–æ–ª–Ω–æ—Ä–∞–∑–º–µ—Ä–Ω—ã–µ –ø—Ä–æ—Ç–æ—Ç–∏–ø—ã
            p = tf.transpose(p, [0, 3, 1, 2])  # –ú–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
            x = self.detect(self, x)
            return (x, p) if self.training else (x[0], p)

    class TFProto(keras.layers.Layer):

        def __init__(self, c1, c_=256, c2=32, w=None):
            super().__init__()
            self.cv1 = TFConv(c1, c_, k=3, w=w.cv1)
            self.upsample = TFUpsample(None, scale_factor=2, mode='nearest')
            self.cv2 = TFConv(c_, c_, k=3, w=w.cv2)
            self.cv3 = TFConv(c_, c2, w=w.cv3)

        def call(self, inputs):
            return self.cv3(self.cv2(self.upsample(self.cv1(inputs))))

    class TFUpsample(keras.layers.Layer):
        # TF –≤–µ—Ä—Å–∏—è torch.nn.Upsample()
        def __init__(self, size, scale_factor, mode, w=None):  # –í—Å–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã
            super().__init__()
            assert scale_factor % 2 == 0, "–ú–∞—Å—à—Ç–∞–± –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫—Ä–∞—Ç–Ω—ã–º 2"
            self.upsample = lambda x: tf.image.resize(x, (x.shape[1] * scale_factor, x.shape[2] * scale_factor), mode)

        def call(self, inputs):
            return self.upsample(inputs)

    class TFConcat(keras.layers.Layer):
        # TF –≤–µ—Ä—Å–∏—è torch.concat()
        def __init__(self, dimension=1, w=None):
            super().__init__()
            assert dimension == 1, "–¢–æ–ª—å–∫–æ –¥–ª—è NCHW ‚Üí NHWC"
            self.d = 3

        def call(self, inputs):
            return tf.concat(inputs, self.d)

    def parse_model(d, ch, model, imgsz):  # model_dict, input_channels(3)
        LOGGER.info(f"\n{'':>3}{'from':>18}{'n':>3}{'params':>10}  {'module':<40}{'arguments':<30}")
        anchors, nc, gd, gw = d['anchors'], d['nc'], d['depth_multiple'], d['width_multiple']
        na = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–∫–æ—Ä–Ω—ã—Ö –±–æ–∫—Å–æ–≤
        no = na * (nc + 5)  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–æ–≤

        layers, save, c2 = [], [], ch[-1]  # –°–ª–æ–∏, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ, –∫–∞–Ω–∞–ª—ã –≤—ã—Ö–æ–¥–∞
        for i, (f, n, m, args) in enumerate(d['backbone'] + d['head']):  # from, number, module, args
            m_str = m
            m = eval(m) if isinstance(m, str) else m  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –≤ –∫–ª–∞—Å—Å
            for j, a in enumerate(args):
                try:
                    args[j] = eval(a) if isinstance(a, str) else a  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
                except NameError:
                    pass

            n = max(round(n * gd), 1) if n > 1 else n  # –ì–ª—É–±–∏–Ω–∞ —Å–µ—Ç–∏
            if m in [
                nn.Conv2d, Conv, DWConv, DWConvTranspose2d, Bottleneck, SPP, SPPF, MixConv2d, Focus, CrossConv,
                BottleneckCSP, C3, C3x]:
                c1, c2 = ch[f], args[0]
                c2 = make_divisible(c2 * gw, 8) if c2 != no else c2

                args = [c1, c2, *args[1:]]
                if m in [BottleneckCSP, C3, C3x]:
                    args.insert(2, n)
                    n = 1
            elif m is nn.BatchNorm2d:
                args = [ch[f]]
            elif m is Concat:
                c2 = sum(ch[-1 if x == -1 else x + 1] for x in f)
            elif m in [Detect, Segment]:
                args.append([ch[x + 1] for x in f])
                if isinstance(args[1], int):
                    args[1] = [list(range(args[1] * 2))] * len(f)
                if m is Segment:
                    args[3] = make_divisible(args[3] * gw, 8)
                args.append(imgsz)
            else:
                c2 = ch[f]

            tf_m = eval('TF' + m_str.replace('nn.', ''))
            m_ = keras.Sequential([tf_m(*args, w=model.model[i][j]) for j in range(n)]) if n > 1 \
                else tf_m(*args, w=model.model[i])  # –ú–æ–¥—É–ª—å

            torch_m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args)  # –ú–æ–¥—É–ª—å PyTorch
            t = str(m)[8:-2].replace('__main__.', '')  # –¢–∏–ø –º–æ–¥—É–ª—è
            np = sum(x.numel() for x in torch_m_.parameters())  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            m_.i, m_.f, m_.type, m_.np = i, f, t, np  # –ü—Ä–∏–≤—è–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            LOGGER.info(f'{i:>3}{str(f):>18}{str(n):>3}{np:>10}  {t:<40}{str(args):<30}')  # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            save.extend(x % i for x in ([f] if isinstance(f, int) else f) if x != -1)  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤
            layers.append(m_)
            ch.append(c2)
        return keras.Sequential(layers), sorted(save)

    class TFModel:
        # TensorFlow –º–æ–¥–µ–ª—å YOLOv5
        def __init__(self, cfg='yolov5s.yaml', ch=3, nc=None, model=None, imgsz=(640, 640)):
            super().__init__()
            if isinstance(cfg, dict):
                self.yaml = cfg  # –°–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–∏
            else:  # *.yaml
                import yaml
                self.yaml_file = Path(cfg).name
                with open(cfg) as f:
                    self.yaml = yaml.load(f, Loader=yaml.FullLoader)  # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            if nc and nc != self.yaml['nc']:
                LOGGER.info(f"–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {cfg} nc={self.yaml['nc']} ‚Üí nc={nc}")
                self.yaml['nc'] = nc  # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–æ–≤
            self.model, self.savelist = parse_model(deepcopy(self.yaml), ch=[ch], model=model, imgsz=imgsz)

        def predict(self,
                    inputs,
                    tf_nms=False,
                    agnostic_nms=False,
                    topk_per_class=100,
                    topk_all=100,
                    iou_thres=0.45,
                    conf_thres=0.25):
            y = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            x = inputs  # –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            for m in self.model.layers:
                if m.f != -1:  # –ï—Å–ª–∏ —Å–ª–æ–π –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–π –≤—ã—Ö–æ–¥
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–ª–æ–µ–≤
                    x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]

                x = m(x)  # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ —Ç–µ–∫—É—â–∏–π —Å–ª–æ–π
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã—Ö–æ–¥, –µ—Å–ª–∏ —Å–ª–æ–π —É–∫–∞–∑–∞–Ω –≤ savelist
                y.append(x if m.i in self.savelist else None)

            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ TensorFlow NMS
            if tf_nms:
                # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏–∑ xywh –≤ xyxy
                boxes = self._xywh2xyxy(x[0][..., :4])
                probs = x[0][:, :, 4:5]  # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                classes = x[0][:, :, 5:]  # –ö–ª–∞—Å—Å—ã
                scores = probs * classes  # –°—É–º–º–∞—Ä–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
                if agnostic_nms:
                    # –ë–µ–∑–∫–ª–∞—Å—Å–æ–≤–∞—è NMS
                    nms = AgnosticNMS()((boxes, classes, scores), topk_all, iou_thres, conf_thres)
                else:
                    # –ö–ª–∞—Å—Å–æ–≤–∞—è NMS
                    boxes = tf.expand_dims(boxes, 2)
                    nms = tf.image.combined_non_max_suppression(boxes,
                                                                scores,
                                                                topk_per_class,
                                                                topk_all,
                                                                iou_thres,
                                                                conf_thres,
                                                                clip_boxes=False)
                return (nms,)
            return x  # –í—ã—Ö–æ–¥ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [1,6300,85] = [xywh, conf, class0, class1, ...]

        @staticmethod
        def _xywh2xyxy(xywh):
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏–∑ [x, y, w, h] –≤ [x1, y1, x2, y2]
            x, y, w, h = tf.split(xywh, num_or_size_splits=4, axis=-1)
            return tf.concat([x - w / 2, y - h / 2, x + w / 2, y + h / 2], axis=-1)

    class AgnosticNMS(keras.layers.Layer):
        # –ö–ª–∞—Å—Å –¥–ª—è –±–µ–∑–∫–ª–∞—Å—Å–æ–≤–æ–π NMS –≤ TensorFlow
        def call(self, input, topk_all, iou_thres, conf_thres):
            # –û–±–µ—Ä—Ç–∫–∞ map_fn –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞—Ç—á–∞
            return tf.map_fn(lambda x: self._nms(x, topk_all, iou_thres, conf_thres),
                             input,
                             fn_output_signature=(tf.float32, tf.float32, tf.float32, tf.int32),
                             name='agnostic_nms')

        @staticmethod
        def _nms(x, topk_all=100, iou_thres=0.45, conf_thres=0.25):  # –ë–µ–∑–∫–ª–∞—Å—Å–æ–≤–∞—è NMS
            boxes, classes, scores = x  # –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: –±–æ–∫—Å—ã, –∫–ª–∞—Å—Å—ã, –æ—Ü–µ–Ω–∫–∏
            class_inds = tf.cast(tf.argmax(classes, axis=-1), tf.float32)  # –ò–Ω–¥–µ–∫—Å—ã –∫–ª–∞—Å—Å–æ–≤
            scores_inp = tf.reduce_max(scores, -1)  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
            # –ù–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –±–æ–∫—Å–æ–≤
            selected_inds = tf.image.non_max_suppression(boxes,
                                                         scores_inp,
                                                         max_output_size=topk_all,
                                                         iou_threshold=iou_thres,
                                                         score_threshold=conf_thres)
            # –í—ã–±–æ—Ä –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            selected_boxes = tf.gather(boxes, selected_inds)
            padded_boxes = tf.pad(selected_boxes,
                                  paddings=[[0, topk_all - tf.shape(selected_boxes)[0]], [0, 0]],
                                  constant_values=0.0)
            selected_scores = tf.gather(scores_inp, selected_inds)
            padded_scores = tf.pad(selected_scores,
                                   paddings=[[0, topk_all - tf.shape(selected_boxes)[0]]],
                                   constant_values=-1.0)
            selected_classes = tf.gather(class_inds, selected_inds)
            padded_classes = tf.pad(selected_classes,
                                    paddings=[[0, topk_all - tf.shape(selected_boxes)[0]]],
                                    constant_values=-1.0)
            valid_detections = tf.shape(selected_inds)[0]  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
            return padded_boxes, padded_scores, padded_classes, valid_detections


def activations(act=nn.SiLU):
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—É—é –∞–∫—Ç–∏–≤–∞—Ü–∏—é TensorFlow –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ PyTorch
    if isinstance(act, nn.LeakyReLU):
        # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é LeakyReLU –¥–ª—è TensorFlow
        return lambda x: keras.activations.relu(x, alpha=0.1)
    elif isinstance(act, nn.Hardswish):
        # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é Hardswish –¥–ª—è TensorFlow
        return lambda x: x * tf.nn.relu6(x + 3) * 0.166666667
    elif isinstance(act, (nn.SiLU, SiLU)):
        # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é Swish –¥–ª—è TensorFlow
        return lambda x: keras.activations.swish(x)
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ TensorFlow, –≤—ã–∑—ã–≤–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
        raise Exception(f'no matching TensorFlow activation found for PyTorch activation {act}')


def representative_dataset_gen(dataset, ncalib=100):
    # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å converter.representative_dataset.
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –º–∞—Å—Å–∏–≤–æ–≤ NumPy.
    for n, (path, img, im0s, vid_cap, string) in enumerate(dataset):
        # –ü–µ—Ä–µ—Å—Ç–∞–≤–ª—è–µ–º –æ—Å–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ PyTorch (CHW) –≤ —Ñ–æ—Ä–º–∞—Ç TensorFlow (HWC)
        im = np.transpose(img, [1, 2, 0])
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±–∞—Ç—á–∞
        im = np.expand_dims(im, axis=0).astype(np.float32)
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        im /= 255
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        yield [im]
        if n >= ncalib:
            # –ü—Ä–µ—Ä—ã–≤–∞–µ–º —Ü–∏–∫–ª, –µ—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –∑–∞–¥–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
            break


def run(
        weights=ROOT / 'yolov5s.pt',  # –ü—É—Ç—å –∫ –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏ PyTorch
        imgsz=(640, 640),  # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (–≤—ã—Å–æ—Ç–∞, —à–∏—Ä–∏–Ω–∞)
        batch_size=1,  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        dynamic=False,  # –§–ª–∞–≥ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞
):
    # PyTorch –º–æ–¥–µ–ª—å
    # –°–æ–∑–¥–∞–µ–º —Ç–µ–Ω–∑–æ—Ä-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –≤—Ö–æ–¥–∞ –≤ PyTorch –º–æ–¥–µ–ª—å (—Ñ–æ—Ä–º–∞—Ç BCHW)
    im = torch.zeros((batch_size, 3, *imgsz))
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å PyTorch —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏
    model = attempt_load(weights, device=torch.device('cpu'), inplace=True, fuse=False)
    # –ü—Ä–æ–≤–æ–¥–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –ø—É—Å—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    _ = model(im)
    # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
    model.info()

    # TensorFlow –º–æ–¥–µ–ª—å
    # –°–æ–∑–¥–∞–µ–º —Ç–µ–Ω–∑–æ—Ä-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –≤—Ö–æ–¥–∞ –≤ TensorFlow –º–æ–¥–µ–ª—å (—Ñ–æ—Ä–º–∞—Ç BHWC)
    im = tf.zeros((batch_size, *imgsz, 3))
    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä TensorFlow –º–æ–¥–µ–ª–∏
    tf_model = TFModel(cfg=model.yaml, model=model, nc=model.nc, imgsz=imgsz)
    # –ü—Ä–æ–≤–æ–¥–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –ø—É—Å—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    _ = tf_model.predict(im)

    # Keras –º–æ–¥–µ–ª—å
    # –°–æ–∑–¥–∞–µ–º –≤—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π Keras –º–æ–¥–µ–ª–∏
    im = keras.Input(shape=(*imgsz, 3), batch_size=None if dynamic else batch_size)
    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä Keras –º–æ–¥–µ–ª–∏
    keras_model = keras.Model(inputs=im, outputs=tf_model.predict(im))
    # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É –æ Keras –º–æ–¥–µ–ª–∏
    keras_model.summary()

    # –í—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± —É—Å–ø–µ—à–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ –º–æ–¥–µ–ª–µ–π
    LOGGER.info('PyTorch, TensorFlow and Keras models successfully verified.\nUse export.py for TF model export.')


def parse_opt():
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    parser = argparse.ArgumentParser()
    # –î–æ–±–∞–≤–ª—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –ø—É—Ç–∏ –∫ –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏
    parser.add_argument('--weights', type=str, default=ROOT / 'yolov5s.pt', help='weights path')
    # –î–æ–±–∞–≤–ª—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640], help='inference size h,w')
    # –î–æ–±–∞–≤–ª—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞
    parser.add_argument('--batch-size', type=int, default=1, help='batch size')
    # –î–æ–±–∞–≤–ª—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞
    parser.add_argument('--dynamic', action='store_true', help='dynamic batch size')
    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    opt = parser.parse_args()
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞–¥–∞–Ω –≤ –≤–∏–¥–µ –¥–≤—É—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–≤—ã—Å–æ—Ç–∞, —à–∏—Ä–∏–Ω–∞)
    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1
    # –í—ã–≤–æ–¥–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    print_args(vars(opt))
    return opt


def main(opt):
    # –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é run —Å —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–Ω—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏
    run(**vars(opt))


if __name__ == "__main__":
    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    opt = parse_opt()
    # –í—ã–∑—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
    main(opt)