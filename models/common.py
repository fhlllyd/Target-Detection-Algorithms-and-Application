# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
"""
Common modules
"""

import ast
import contextlib
import json
import math
import platform
import warnings
import zipfile
from collections import OrderedDict, namedtuple
from copy import copy
from pathlib import Path
from urllib.parse import urlparse

import cv2
import numpy as np
import pandas as pd
import requests
import torch
import torch.nn as nn
from IPython.display import display
from PIL import Image
from torch.cuda import amp

from utils import TryExcept
from utils.dataloaders import exif_transpose, letterbox
from utils.general import (LOGGER, ROOT, Profile, check_requirements, check_suffix, check_version, colorstr,
                           increment_path, is_notebook, make_divisible, non_max_suppression, scale_boxes, xywh2xyxy,
                           xyxy2xywh, yaml_load)
from utils.plots import Annotator, colors, save_one_box
from utils.torch_utils import copy_attr, smart_inference_mode

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ padding –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è 'same' —Ñ–æ—Ä–º—ã –≤—ã—Ö–æ–¥–∞
def autopad(k, p=None, d=1):  # kernel, padding, dilation
    # –ï—Å–ª–∏ dilation > 1, –≤—ã—á–∏—Å–ª—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä —è–¥—Ä–∞
    if d > 1:
        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]  # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä —è–¥—Ä–∞
    # –ï—Å–ª–∏ padding –Ω–µ –∑–∞–¥–∞–Ω, –≤—ã—á–∏—Å–ª—è–µ–º –µ–≥–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    if p is None:
        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π padding
    return p

# –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞
class Conv(nn.Module):
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞ —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ (ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)
    default_act = nn.SiLU()  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏

    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):
        super().__init__()
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ —Å–ª–æ—è
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ—è –±–∞—Ç—á-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        self.bn = nn.BatchNorm2d(c2)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ —Å–≤–µ—Ä—Ç–∫—É, –±–∞—Ç—á-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –∏ —Ñ—É–Ω–∫—Ü–∏—é –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        return self.act(self.bn(self.conv(x)))

    def forward_fuse(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ –±–µ–∑ –±–∞—Ç—á-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        return self.act(self.conv(x))

# –ì–ª—É–±–∏–Ω–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞
class DWConv(Conv):
    # –ì–ª—É–±–∏–Ω–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞
    def __init__(self, c1, c2, k=1, s=1, d=1, act=True):  # ch_in, ch_out, kernel, stride, dilation, activation
        super().__init__(c1, c2, k, s, g=math.gcd(c1, c2), d=d, act=act)

# –ì–ª—É–±–∏–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞
class DWConvTranspose2d(nn.ConvTranspose2d):
    # –ì–ª—É–±–∏–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞
    def __init__(self, c1, c2, k=1, s=1, p1=0, p2=0):  # ch_in, ch_out, kernel, stride, padding, padding_out
        super().__init__(c1, c2, k, s, p1, p2, groups=math.gcd(c1, c2))

# –°–ª–æ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞
class TransformerLayer(nn.Module):
    # –°–ª–æ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ https://arxiv.org/abs/2010.11929 (–°–ª–æ–∏ LayerNorm —É–¥–∞–ª–µ–Ω—ã –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
    def __init__(self, c, num_heads):
        super().__init__()
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª–∏–Ω–µ–π–Ω—ã—Ö —Å–ª–æ–µ–≤ –¥–ª—è Q, K, V
        self.q = nn.Linear(c, c, bias=False)
        self.k = nn.Linear(c, c, bias=False)
        self.v = nn.Linear(c, c, bias=False)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ—èÂ§öÂ§¥Ê≥®ÊÑèÂäõ
        self.ma = nn.MultiheadAttention(embed_dim=c, num_heads=num_heads)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª–∏–Ω–µ–π–Ω—ã—Ö —Å–ª–æ–µ–≤ –¥–ª—è –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã—Ö –±–ª–æ–∫–æ–≤
        self.fc1 = nn.Linear(c, c, bias=False)
        self.fc2 = nn.Linear(c, c, bias=False)

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ —Å–ª–æ–πÂ§öÂ§¥Ê≥®ÊÑèÂäõ –∏ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ –±–ª–æ–∫–∏
        x = self.ma(self.q(x), self.k(x), self.v(x))[0] + x
        x = self.fc2(self.fc1(x)) + x
        return x

# –ë–ª–æ–∫ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞
class TransformerBlock(nn.Module):
    # Vision Transformer https://arxiv.org/abs/2010.11929
    def __init__(self, c1, c2, num_heads, num_layers):
        super().__init__()
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ —Å–ª–æ—è, –µ—Å–ª–∏ –≤—Ö–æ–¥–Ω—ã–µ –∏ –≤—ã—Ö–æ–¥–Ω—ã–µ –∫–∞–Ω–∞–ª—ã —Ä–∞–∑–ª–∏—á–Ω—ã
        self.conv = None
        if c1 != c2:
            self.conv = Conv(c1, c2)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è –¥–ª—è –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –≤–ª–æ–∂–µ–Ω–∏—è
        self.linear = nn.Linear(c2, c2)  # –£—á–µ–±–Ω–æ–µ –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ –≤–ª–æ–∂–µ–Ω–∏–µ
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–ª–æ–µ–≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞
        self.tr = nn.Sequential(*(TransformerLayer(c2, num_heads) for _ in range(num_layers)))
        self.c2 = c2

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π —Å–ª–æ–π (–µ—Å–ª–∏ –µ—Å—Ç—å), –∞ –∑–∞—Ç–µ–º —á–µ—Ä–µ–∑ –±–ª–æ–∫ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞
        if self.conv is not None:
            x = self.conv(x)
        b, _, w, h = x.shape
        p = x.flatten(2).permute(2, 0, 1)
        return self.tr(p + self.linear(p)).permute(1, 2, 0).reshape(b, self.c2, w, h)

# –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –±—É—Ç—ã–ª–æ—á–Ω–æ–µ –≥–æ—Ä–ª—ã—à–∫–æ
class Bottleneck(nn.Module):
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –±—É—Ç—ã–ª–æ—á–Ω–æ–µ –≥–æ—Ä–ª—ã—à–∫–æ
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ–µ–≤
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –±—É—Ç—ã–ª–æ—á–Ω–æ–µ –≥–æ—Ä–ª—ã—à–∫–æ
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))

# CSP Bottleneck
class BottleneckCSP(nn.Module):
    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ–µ–≤
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)
        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)
        self.cv4 = Conv(2 * c_, c2, 1, 1)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ—è –±–∞—Ç—á-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        self.bn = nn.BatchNorm2d(2 * c_)  # –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫ cat(cv2, cv3)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        self.act = nn.SiLU()
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –±—É—Ç—ã–ª–æ—á–Ω—ã—Ö –≥–æ—Ä–ª—ã—à–µ–∫
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ CSP Bottleneck
        y1 = self.cv3(self.m(self.cv1(x)))
        y2 = self.cv2(x)
        return self.cv4(self.act(self.bn(torch.cat((y1, y2), 1))))

# –ö—Ä–æ—Å—Å- —Å–≤–µ—Ä—Ç–∫–∞ —Å –ø–æ–Ω–∏–∂–µ–Ω–∏–µ–º –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
class CrossConv(nn.Module):
    # –ö—Ä–æ—Å—Å- —Å–≤–µ—Ä—Ç–∫–∞ —Å –ø–æ–Ω–∏–∂–µ–Ω–∏–µ–º –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
    def __init__(self, c1, c2, k=3, s=1, g=1, e=1.0, shortcut=False):
        # ch_in, ch_out, kernel, stride, groups, expansion, shortcut
        super().__init__()
        c_ = int(c2 * e)  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ–µ–≤
        self.cv1 = Conv(c1, c_, (1, k), (1, s))
        self.cv2 = Conv(c_, c2, (k, 1), (s, 1), g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –∫—Ä–æ—Å—Å- —Å–≤–µ—Ä—Ç–∫—É
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))


# CSP Bottleneck —Å —Ç—Ä–µ–º—è —Å–≤–µ—Ä—Ç–∫–∞–º–∏
class C3(nn.Module):
    # CSP Bottleneck —Å —Ç—Ä–µ–º—è —Å–≤–µ—Ä—Ç–∫–∞–º–∏
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, shortcut, –≥—Ä—É–ø–ø—ã, —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        super().__init__()
        c_ = int(c2 * e)  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ–µ–≤
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ act=FReLU(c2)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –±—É—Ç—ã–ª–æ—á–Ω—ã—Ö –≥–æ—Ä–ª—ã—à–µ–∫
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ C3 –º–æ–¥—É–ª—å
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))

# C3 –º–æ–¥—É–ª—å —Å –∫—Ä–æ—Å—Å- —Å–≤–µ—Ä—Ç–∫–∞–º–∏
class C3x(C3):
    # C3 –º–æ–¥—É–ª—å —Å –∫—Ä–æ—Å—Å- —Å–≤–µ—Ä—Ç–∫–∞–º–∏
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫—Ä–æ—Å—Å- —Å–≤–µ—Ä—Ç–æ–∫
        self.m = nn.Sequential(*(CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)))

# C3 –º–æ–¥—É–ª—å —Å TransformerBlock()
class C3TR(C3):
    # C3 –º–æ–¥—É–ª—å —Å TransformerBlock()
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±–ª–æ–∫–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞
        self.m = TransformerBlock(c_, c_, 4, n)

# C3 –º–æ–¥—É–ª—å —Å SPP()
class C3SPP(C3):
    # C3 –º–æ–¥—É–ª—å —Å SPP()
    def __init__(self, c1, c2, k=(5, 9, 13), n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–∏—Ä–∞–º–∏–¥–∞–ª—å–Ω–æ–≥–æ –ø—É–ª–∏–Ω–≥–∞
        self.m = SPP(c_, c_, k)

# C3 –º–æ–¥—É–ª—å —Å GhostBottleneck()
class C3Ghost(C3):
    # C3 –º–æ–¥—É–ª—å —Å GhostBottleneck()
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ GhostBottleneck
        self.m = nn.Sequential(*(GhostBottleneck(c_, c_) for _ in range(n)))

# Spatial Pyramid Pooling (SPP) —Å–ª–æ–π https://arxiv.org/abs/1406.4729
class SPP(nn.Module):
    # Spatial Pyramid Pooling (SPP) —Å–ª–æ–π https://arxiv.org/abs/1406.4729
    def __init__(self, c1, c2, k=(5, 9, 13)):
        super().__init__()
        c_ = c1 // 2  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ–µ–≤
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–µ–≤ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –ø—É–ª–∏–Ω–≥–∞
        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ SPP —Å–ª–æ–π
        x = self.cv1(x)
        with warnings.catch_warnings():
            warnings.simplefilter('ignore')  # –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è torch 1.9.0 max_pool2d()
            return self.cv2(torch.cat([x] + [m(x) for m in self.m], 1))

# Spatial Pyramid Pooling - Fast (SPPF) —Å–ª–æ–π –¥–ª—è YOLOv5 –æ—Ç Glenn Jocher
class SPPF(nn.Module):
    # Spatial Pyramid Pooling - Fast (SPPF) —Å–ª–æ–π –¥–ª—è YOLOv5 –æ—Ç Glenn Jocher
    def __init__(self, c1, c2, k=5):  # –≠–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ SPP(k=(5, 9, 13))
        super().__init__()
        c_ = c1 // 2  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ–µ–≤
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * 4, c2, 1, 1)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –ø—É–ª–∏–Ω–≥–∞
        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ SPPF —Å–ª–æ–π
        x = self.cv1(x)
        with warnings.catch_warnings():
            warnings.simplefilter('ignore')  # –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è torch 1.9.0 max_pool2d()
            y1 = self.m(x)
            y2 = self.m(y1)
            return self.cv2(torch.cat((x, y1, y2, self.m(y2)), 1))

# Focus wh –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ c-–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ
class Focus(nn.Module):
    # Focus wh –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ c-–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, —è–¥—Ä–æ, —à–∞–≥, padding, –≥—Ä—É–ø–ø—ã
        super().__init__()
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ —Å–ª–æ—è
        self.conv = Conv(c1 * 4, c2, k, s, p, g, act=act)
        # self.contract = Contract(gain=2)

    def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w/2,h/2)
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ Focus —Å–ª–æ–π
        return self.conv(torch.cat((x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]), 1))
        # return self.conv(self.contract(x))

# Ghost Convolution https://github.com/huawei-noah/ghostnet
class GhostConv(nn.Module):
    # Ghost Convolution https://github.com/huawei-noah/ghostnet
    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):  # ch_in, ch_out, —è–¥—Ä–æ, —à–∞–≥, –≥—Ä—É–ø–ø—ã
        super().__init__()
        c_ = c2 // 2  # –°–∫—Ä—ã—Ç—ã–µ –∫–∞–Ω–∞–ª—ã
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ–µ–≤
        self.cv1 = Conv(c1, c_, k, s, None, g, act=act)
        self.cv2 = Conv(c_, c_, 5, 1, None, c_, act=act)

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ GhostConv —Å–ª–æ–π
        y = self.cv1(x)
        return torch.cat((y, self.cv2(y)), 1)

# Ghost Bottleneck https://github.com/huawei-noah/ghostnet
class GhostBottleneck(nn.Module):
    # Ghost Bottleneck https://github.com/huawei-noah/ghostnet
    def __init__(self, c1, c2, k=3, s=1):  # ch_in, ch_out, —è–¥—Ä–æ, —à–∞–≥
        super().__init__()
        c_ = c2 // 2
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–ª–æ–µ–≤ GhostBottleneck
        self.conv = nn.Sequential(
            GhostConv(c1, c_, 1, 1),  # pw
            DWConv(c_, c_, k, s, act=False) if s == 2 else nn.Identity(),  # dw
            GhostConv(c_, c2, 1, 1, act=False))  # pw-linear
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ shortcut
        self.shortcut = nn.Sequential(DWConv(c1, c1, k, s, act=False), Conv(c1, c2, 1, 1,
                                                                            act=False)) if s == 2 else nn.Identity()

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ GhostBottleneck
        return self.conv(x) + self.shortcut(x)

# –°–∂–∞—Ç–∏–µ —à–∏—Ä–∏–Ω—ã-–≤—ã—Å–æ—Ç—ã –≤ –∫–∞–Ω–∞–ª—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä, x(1,64,80,80) –≤ x(1,256,40,40)
class Contract(nn.Module):
    # –°–∂–∞—Ç–∏–µ —à–∏—Ä–∏–Ω—ã-–≤—ã—Å–æ—Ç—ã –≤ –∫–∞–Ω–∞–ª—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä, x(1,64,80,80) –≤ x(1,256,40,40)
    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ Contract —Å–ª–æ–π
        b, c, h, w = x.size()  # assert (h / s == 0) and (W / s == 0), 'Indivisible gain'
        s = self.gain
        x = x.view(b, c, h // s, s, w // s, s)  # x(1,64,40,2,40,2)
        x = x.permute(0, 3, 5, 1, 2, 4).contiguous()  # x(1,2,2,64,40,40)
        return x.view(b, c * s * s, h // s, w // s)  # x(1,256,40,40)

# –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–æ–≤ –≤ —à–∏—Ä–∏–Ω—É-–≤—ã—Å–æ—Ç—É, –Ω–∞–ø—Ä–∏–º–µ—Ä, x(1,64,80,80) –≤ x(1,16,160,160)
class Expand(nn.Module):
    # –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–æ–≤ –≤ —à–∏—Ä–∏–Ω—É-–≤—ã—Å–æ—Ç—É, –Ω–∞–ø—Ä–∏–º–µ—Ä, x(1,64,80,80) –≤ x(1,16,160,160)
    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ Expand —Å–ª–æ–π
        b, c, h, w = x.size()  # assert C / s ** 2 == 0, 'Indivisible gain'
        s = self.gain
        x = x.view(b, s, s, c // s ** 2, h, w)  # x(1,2,2,16,80,80)
        x = x.permute(0, 3, 4, 1, 5, 2).contiguous()  # x(1,16,80,2,80,2)
        return x.view(b, c // s ** 2, h * s, w * s)  # x(1,16,160,160)

# –ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ —Ç–µ–Ω–∑–æ—Ä–æ–≤ –ø–æ –∏–∑–º–µ—Ä–µ–Ω–∏—é
class Concat(nn.Module):
    # –ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ —Ç–µ–Ω–∑–æ—Ä–æ–≤ –ø–æ –∏–∑–º–µ—Ä–µ–Ω–∏—é
    def __init__(self, dimension=1):
        super().__init__()
        self.d = dimension

    def forward(self, x):
        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ Concat —Å–ª–æ–π
        return torch.cat(x, self.d)


# –ö–ª–∞—Å—Å YOLOv5 MultiBackend –¥–ª—è Python-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –±—ç–∫–µ–Ω–¥–∞—Ö
class DetectMultiBackend(nn.Module):
    # YOLOv5 MultiBackend –∫–ª–∞—Å—Å –¥–ª—è Python-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –±—ç–∫–µ–Ω–¥–∞—Ö
    def __init__(self, weights='yolov5s.pt', device=torch.device('cpu'), dnn=False, data=None, fp16=False, fuse=True):
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
        #   PyTorch:              weights = *.pt
        #   TorchScript:                    *.torchscript
        #   ONNX Runtime:                   *.onnx
        #   ONNX OpenCV DNN:                *.onnx --dnn
        #   OpenVINO:                       *_openvino_model
        #   CoreML:                         *.mlmodel
        #   TensorRT:                       *.engine
        #   TensorFlow SavedModel:          *_saved_model
        #   TensorFlow GraphDef:            *.pb
        #   TensorFlow Lite:                *.tflite
        #   TensorFlow Edge TPU:            *_edgetpu.tflite
        #   PaddlePaddle:                   *_paddle_model
        from models.experimental import attempt_download, attempt_load  # –ª–æ–∫–∞–ª—å–Ω–æ–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞

        super().__init__()
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤ –≤ —Å—Ç—Ä–æ–∫—É
        w = str(weights[0] if isinstance(weights, list) else weights)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏
        pt, jit, onnx, xml, engine, coreml, saved_model, pb, tflite, edgetpu, tfjs, paddle, triton = self._model_type(w)
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–µ–∂–∏–º–∞ FP16 –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π
        fp16 &= pt or jit or onnx or engine  # FP16
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ñ–æ—Ä–º–∞—Ç—ã BHWC (–≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç torch BCWH)
        nhwc = coreml or saved_model or pb or tflite or edgetpu  # BHWC —Ñ–æ—Ä–º–∞—Ç—ã (vs torch BCWH)
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è —à–∞–≥–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        stride = 32  # –∑–Ω–∞—á–µ–Ω–∏–µ —à–∞–≥–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ CUDA –∏ —Ç–∏–ø–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        cuda = torch.cuda.is_available() and device.type != 'cpu'  # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CUDA
        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ
        if not (pt or triton):
            w = attempt_download(w)  # –∑–∞–≥—Ä—É–∑–∫–∞, –µ—Å–ª–∏ –Ω–µ –ª–æ–∫–∞–ª—å–Ω–æ

        if pt:  # PyTorch
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ PyTorch
            model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —à–∞–≥–∞ –º–æ–¥–µ–ª–∏
            stride = max(int(model.stride.max()), 32)  # —à–∞–≥ –º–æ–¥–µ–ª–∏
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω –∫–ª–∞—Å—Å–æ–≤
            names = model.module.names if hasattr(model, 'module') else model.names  # –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω –∫–ª–∞—Å—Å–æ–≤
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏
            model.half() if fp16 else model.float()
            # –ü—Ä–∏—Å–≤–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∞—Ç—Ä–∏–±—É—Ç—É
            self.model = model  # —è–≤–Ω–æ–µ –ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ –¥–ª—è to(), cpu(), cuda(), half()
        elif jit:  # TorchScript
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ TorchScript
            LOGGER.info(f'–ó–∞–≥—Ä—É–∑–∫–∞ {w} –¥–ª—è TorchScript-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...')
            # –§–∞–π–ª —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª–∏
            extra_files = {'config.txt': ''}  # –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ TorchScript
            model = torch.jit.load(w, _extra_files=extra_files, map_location=device)
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏
            model.half() if fp16 else model.float()
            if extra_files['config.txt']:  # –∑–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                d = json.loads(extra_files['config.txt'],
                               object_hook=lambda d: {int(k) if k.isdigit() else k: v
                                                      for k, v in d.items()})
                # –ü–æ–ª—É—á–µ–Ω–∏–µ —à–∞–≥–∞ –∏ –∏–º–µ–Ω –∫–ª–∞—Å—Å–æ–≤
                stride, names = int(d['stride']), d['names']
        elif dnn:  # ONNX OpenCV DNN
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ ONNX —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenCV DNN
            LOGGER.info(f'–ó–∞–≥—Ä—É–∑–∫–∞ {w} –¥–ª—è ONNX OpenCV DNN-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...')
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
            check_requirements('opencv-python>=4.5.4')
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ONNX –≤ OpenCV DNN
            net = cv2.dnn.readNetFromONNX(w)
        elif onnx:  # ONNX Runtime
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ ONNX —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ONNX Runtime
            LOGGER.info(f'–ó–∞–≥—Ä—É–∑–∫–∞ {w} –¥–ª—è ONNX Runtime-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...')
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
            check_requirements(('onnx', 'onnxruntime-gpu' if cuda else 'onnxruntime'))
            import onnxruntime
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –¥–ª—è ONNX Runtime
            providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏ ONNX Runtime
            session = onnxruntime.InferenceSession(w, providers=providers)
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤
            output_names = [x.name for x in session.get_outputs()]
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏
            meta = session.get_modelmeta().custom_metadata_map  # –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            if 'stride' in meta:
                # –ü–æ–ª—É—á–µ–Ω–∏–µ —à–∞–≥–∞ –∏ –∏–º–µ–Ω –∫–ª–∞—Å—Å–æ–≤ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                stride, names = int(meta['stride']), eval(meta['names'])
        elif xml:  # OpenVINO
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ OpenVINO
            LOGGER.info(f'–ó–∞–≥—Ä—É–∑–∫–∞ {w} –¥–ª—è OpenVINO-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...')
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
            check_requirements('openvino')  # —Ç—Ä–µ–±—É–µ—Ç—Å—è openvino-dev: https://pypi.org/project/openvino-dev/
            from openvino.runtime import Core, Layout, get_batch
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —è–¥—Ä–∞ OpenVINO
            ie = Core()
            if not Path(w).is_file():  # –µ—Å–ª–∏ –Ω–µ *.xml
                # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–∞ *.xml –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                w = next(Path(w).glob('*.xml'))  # –ø–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ *.xml –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ *_openvino_model
            # –ß—Ç–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ OpenVINO
            network = ie.read_model(model=w, weights=Path(w).with_suffix('.bin'))
            if network.get_parameters()[0].get_layout().empty:
                # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞
                network.get_parameters()[0].set_layout(Layout("NCHW"))
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –±–∞—Ç—á–∞
            batch_dim = get_batch(network)
            if batch_dim.is_static:
                # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞
                batch_size = batch_dim.get_length()
            # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏ OpenVINO
            executable_network = ie.compile_model(network, device_name="CPU")  # device_name="MYRIAD" –¥–ª—è Intel NCS2
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            stride, names = self._load_metadata(Path(w).with_suffix('.yaml'))  # –∑–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        elif engine:  # TensorRT
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ TensorRT
            LOGGER.info(f'–ó–∞–≥—Ä—É–∑–∫–∞ {w} –¥–ª—è TensorRT-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...')
            import tensorrt as trt  # https://developer.nvidia.com/nvidia-tensorrt-download
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ TensorRT
            check_version(trt.__version__, '7.0.0', hard=True)  # —Ç—Ä–µ–±—É–µ—Ç—Å—è tensorrt>=7.0.0
            if device.type == 'cpu':
                # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –Ω–∞ GPU, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU
                device = torch.device('cuda:0')
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ—Ä—Ç–µ–∂–∞ –¥–ª—è –ø—Ä–∏–≤—è–∑–æ–∫
            Binding = namedtuple('Binding', ('name', 'dtype', 'shape', 'data', 'ptr'))
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞ TensorRT
            logger = trt.Logger(trt.Logger.INFO)
            with open(w, 'rb') as f, trt.Runtime(logger) as runtime:
                # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ TensorRT
                model = runtime.deserialize_cuda_engine(f.read())
            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            context = model.create_execution_context()
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è –¥–ª—è –ø—Ä–∏–≤—è–∑–æ–∫
            bindings = OrderedDict()
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ –∏–º–µ–Ω –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤
            output_names = []
            fp16 = False  # –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –Ω–∏–∂–µ
            dynamic = False
            for i in range(model.num_bindings):
                # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –ø—Ä–∏–≤—è–∑–∫–∏
                name = model.get_binding_name(i)
                # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–≤—è–∑–∫–∏
                dtype = trt.nptype(model.get_binding_dtype(i))
                if model.binding_is_input(i):
                    if -1 in tuple(model.get_binding_shape(i)):  # –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä
                        dynamic = True
                        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞
                        context.set_binding_shape(i, tuple(model.get_profile_shape(0, i)[2]))
                    if dtype == np.float16:
                        fp16 = True
                else:  # –≤—ã—Ö–æ–¥
                    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ –≤ —Å–ø–∏—Å–æ–∫
                    output_names.append(name)
                # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –ø—Ä–∏–≤—è–∑–∫–∏
                shape = tuple(context.get_binding_shape(i))
                # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–∞ PyTorch –∏–∑ –ø—É—Å—Ç–æ–≥–æ –º–∞—Å—Å–∏–≤–∞ NumPy
                im = torch.from_numpy(np.empty(shape, dtype=dtype)).to(device)
                # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–≤—è–∑–∫–∏ –≤ —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å
                bindings[name] = Binding(name, dtype, shape, im, int(im.data_ptr()))
            # –°–æ–∑–¥–∞–Ω–∏–µ —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è —Å –∞–¥—Ä–µ—Å–∞–º–∏ –ø—Ä–∏–≤—è–∑–æ–∫
            binding_addrs = OrderedDict((n, d.ptr) for n, d in bindings.items())
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞
            batch_size = bindings['images'].shape[0]  # –µ—Å–ª–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π, —ç—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        elif coreml:  # CoreML
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ CoreML
            LOGGER.info(f'–ó–∞–≥—Ä—É–∑–∫–∞ {w} –¥–ª—è CoreML-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...')
            import coremltools as ct
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ CoreML
            model = ct.models.MLModel(w)
        elif saved_model:  # TF SavedModel
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ TensorFlow SavedModel
            LOGGER.info(f'–ó–∞–≥—Ä—É–∑–∫–∞ {w} –¥–ª—è TensorFlow SavedModel-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...')
            import tensorflow as tf
            keras = False  # –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è TF1 saved_model
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ TensorFlow SavedModel
            model = tf.keras.models.load_model(w) if keras else tf.saved_model.load(w)
        elif pb:  # GraphDef https://www.tensorflow.org/guide/migrate#a_graphpb_or_graphpbtxt
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ TensorFlow GraphDef
            LOGGER.info(f'–ó–∞–≥—Ä—É–∑–∫–∞ {w} –¥–ª—è TensorFlow GraphDef-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...')
            import tensorflow as tf

            def wrap_frozen_graph(gd, inputs, outputs):
                # –û–±–µ—Ä—Ç–∫–∞ –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∞ TensorFlow
                x = tf.compat.v1.wrap_function(lambda: tf.compat.v1.import_graph_def(gd, name=""), [])  # –æ–±–µ—Ä–Ω—É—Ç–æ
                ge = x.graph.as_graph_element
                return x.prune(tf.nest.map_structure(ge, inputs), tf.nest.map_structure(ge, outputs))

            def gd_outputs(gd):
                # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤ –∏–∑ –≥—Ä–∞—Ñ–∞ TensorFlow
                name_list, input_list = [], []
                for node in gd.node:  # tensorflow.core.framework.node_def_pb2.NodeDef
                    name_list.append(node.name)
                    input_list.extend(node.input)
                return sorted(f'{x}:0' for x in list(set(name_list) - set(input_list)) if not x.startswith('NoOp'))

            gd = tf.Graph().as_graph_def()  # TF GraphDef
            with open(w, 'rb') as f:
                # –ß—Ç–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ TensorFlow –∏–∑ —Ñ–∞–π–ª–∞
                gd.ParseFromString(f.read())
            # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
            frozen_func = wrap_frozen_graph(gd, inputs="x:0", outputs=gd_outputs(gd))
        elif tflite or edgetpu:  # https://www.tensorflow.org/lite/guide/python#install_tensorflow_lite_for_python
            try:  # https://coral.ai/docs/edgetpu/tflite-python/#update-existing-tf-lite-code-for-the-edge-tpu
                from tflite_runtime.interpreter import Interpreter, load_delegate
            except ImportError:
                import tensorflow as tf
                Interpreter, load_delegate = tf.lite.Interpreter, tf.lite.experimental.load_delegate,
            if edgetpu:  # TF Edge TPU https://coral.ai/software/#edgetpu-runtime
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ TensorFlow Lite Edge TPU
                LOGGER.info(f'–ó–∞–≥—Ä—É–∑–∫–∞ {w} –¥–ª—è TensorFlow Lite Edge TPU-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...')
                delegate = {
                    'Linux': 'libedgetpu.so.1',
                    'Darwin': 'libedgetpu.1.dylib',
                    'Windows': 'edgetpu.dll'}[platform.system()]
                # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä–∞ TensorFlow Lite Edge TPU
                interpreter = Interpreter(model_path=w, experimental_delegates=[load_delegate(delegate)])
            else:  # TFLite
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ TensorFlow Lite
                LOGGER.info(f'–ó–∞–≥—Ä—É–∑–∫–∞ {w} –¥–ª—è TensorFlow Lite-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...')
                # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä–∞ TensorFlow Lite
                interpreter = Interpreter(model_path=w)  # –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ TFLite
            # –í—ã–¥–µ–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –¥–ª—è —Ç–µ–Ω–∑–æ—Ä–æ–≤
            interpreter.allocate_tensors()  # –≤—ã–¥–µ–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤—Ö–æ–¥–Ω—ã—Ö —Ç–µ–Ω–∑–æ—Ä–∞—Ö
            input_details = interpreter.get_input_details()  # –≤—Ö–æ–¥—ã
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ç–µ–Ω–∑–æ—Ä–∞—Ö
            output_details = interpreter.get_output_details()  # –≤—ã—Ö–æ–¥—ã
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            with contextlib.suppress(zipfile.BadZipFile):
                with zipfile.ZipFile(w, "r") as model:
                    meta_file = model.namelist()[0]
                    meta = ast.literal_eval(model.read(meta_file).decode("utf-8"))
                    stride, names = int(meta['stride']), meta['names']
        elif tfjs:  # TF.js
            # –í—ã–±—Ä–∞—Å—ã–≤–∞–Ω–∏–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è TF.js
            raise NotImplementedError('–û–®–ò–ë–ö–ê: YOLOv5 TF.js-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è')
        elif paddle:  # PaddlePaddle
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ PaddlePaddle
            LOGGER.info(f'–ó–∞–≥—Ä—É–∑–∫–∞ {w} –¥–ª—è PaddlePaddle-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...')
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
            check_requirements('paddlepaddle-gpu' if cuda else 'paddlepaddle')
            import paddle.inference as pdi
            if not Path(w).is_file():  # –µ—Å–ª–∏ –Ω–µ *.pdmodel
                # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–∞ *.pdmodel –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                w = next(Path(w).rglob('*.pdmodel'))  # –ø–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ *.pdmodel –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ *_paddle_model
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏
            weights = Path(w).with_suffix('.pdiparams')
            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ PaddlePaddle
            config = pdi.Config(str(w), str(weights))
            if cuda:
                # –í–∫–ª—é—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU
                config.enable_use_gpu(memory_pool_init_size_mb=2048, device_id=0)
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞ PaddlePaddle
            predictor = pdi.create_predictor(config)
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ö—ç–Ω–¥–ª–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞
            input_handle = predictor.get_input_handle(predictor.get_input_names()[0])
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤
            output_names = predictor.get_output_names()
        elif triton:  # NVIDIA Triton Inference Server
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–∞ NVIDIA Triton Inference Server
            LOGGER.info(f'–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ {w} –∫–∞–∫ —Å–µ—Ä–≤–µ—Ä–∞ NVIDIA Triton Inference Server...')
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
            check_requirements('tritonclient[all]')
            from utils.triton import TritonRemoteModel
            # –°–æ–∑–¥–∞–Ω–∏–µ —É–¥–∞–ª–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ Triton
            model = TritonRemoteModel(url=w)
            nhwc = model.runtime.startswith("tensorflow")
        else:
            # –í—ã–±—Ä–∞—Å—ã–≤–∞–Ω–∏–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è, –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –º–æ–¥–µ–ª–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
            raise NotImplementedError(f'–û–®–ò–ë–ö–ê: {w} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º')

            # class names
            if 'names' not in locals():
                # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–º–µ–Ω –∫–ª–∞—Å—Å–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞ data –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö
                names = yaml_load(data)['names'] if data else {i: f'class{i}' for i in range(999)}
                # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å ImageNet - –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–∏—Ç–∞–µ–º—ã–µ –∏–º–µ–Ω–∞
                if names[0] == 'n01440764' and len(names) == 1000:  # ImageNet
                    names = yaml_load(ROOT / 'data/ImageNet.yaml')['names']  # —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ –∏–º–µ–Ω–∞

            # –ü—Ä–∏—Å–≤–æ–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤ self
            self.__dict__.update(locals())  # assign all variables to self

        def forward(self, im, augment=False, visualize=False):
            # YOLOv5 MultiBackend inference
            b, ch, h, w = im.shape  # batch, channel, height, width
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ FP16 –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if self.fp16 and im.dtype != torch.float16:
                im = im.half()  # to FP16
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ BHWC –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
            if self.nhwc:
                im = im.permute(0, 2, 3, 1)  # torch BCHW -> numpy BHWC shape(1,320,192,3)

            # PyTorch inference
            if self.pt:  # PyTorch
                y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)
            # TorchScript inference
            elif self.jit:  # TorchScript
                y = self.model(im)
            # ONNX OpenCV DNN inference
            elif self.dnn:  # ONNX OpenCV DNN
                im = im.cpu().numpy()  # torch -> numpy
                self.net.setInput(im)
                y = self.net.forward()
            # ONNX Runtime inference
            elif self.onnx:  # ONNX Runtime
                im = im.cpu().numpy()  # torch -> numpy
                y = self.session.run(self.output_names, {self.session.get_inputs()[0].name: im})
            # OpenVINO inference
            elif self.xml:  # OpenVINO
                im = im.cpu().numpy()  # FP32
                y = list(self.executable_network([im]).values())
            # TensorRT inference
            elif self.engine:  # TensorRT
                # –ï—Å–ª–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä - –æ–±–Ω–æ–≤–ª—è–µ–º
                if self.dynamic and im.shape != self.bindings['images'].shape:
                    i = self.model.get_binding_index('images')
                    self.context.set_binding_shape(i, im.shape)  # reshape if dynamic
                    self.bindings['images'] = self.bindings['images']._replace(shape=im.shape)
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤
                    for name in self.output_names:
                        i = self.model.get_binding_index(name)
                        self.bindings[name].data.resize_(tuple(self.context.get_binding_shape(i)))
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤
                s = self.bindings['images'].shape
                assert im.shape == s, f"input size {im.shape} {'>' if self.dynamic else 'not equal to'} max model size {s}"
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–¥—Ä–µ—Å –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞
                self.binding_addrs['images'] = int(im.data_ptr())
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
                self.context.execute_v2(list(self.binding_addrs.values()))
                # –°–æ–±–∏—Ä–∞–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                y = [self.bindings[x].data for x in sorted(self.output_names)]
            # CoreML inference
            elif self.coreml:  # CoreML
                im = im.cpu().numpy()
                im = Image.fromarray((im[0] * 255).astype('uint8'))
                # im = im.resize((192, 320), Image.ANTIALIAS)
                y = self.model.predict({'image': im})  # –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã xywh –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                if 'confidence' in y:
                    box = xywh2xyxy(y['coordinates'] * [[w, h, w, h]])  # xyxy –ø–∏–∫—Å–µ–ª–∏
                    conf, cls = y['confidence'].max(1), y['confidence'].argmax(1).astype(np.float)
                    y = np.concatenate((box, conf.reshape(-1, 1), cls.reshape(-1, 1)), 1)
                else:
                    y = list(reversed(y.values()))  # –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (pred, proto)
            # PaddlePaddle inference
            elif self.paddle:  # PaddlePaddle
                im = im.cpu().numpy().astype(np.float32)
                self.input_handle.copy_from_cpu(im)
                self.predictor.run()
                y = [self.predictor.get_output_handle(x).copy_to_cpu() for x in self.output_names]
            # NVIDIA Triton inference
            elif self.triton:  # NVIDIA Triton Inference Server
                y = self.model(im)
            # TensorFlow inference (SavedModel, GraphDef, Lite, Edge TPU)
            else:  # TensorFlow (SavedModel, GraphDef, Lite, Edge TPU)
                im = im.cpu().numpy()
                if self.saved_model:  # SavedModel
                    y = self.model(im, training=False) if self.keras else self.model(im)
                elif self.pb:  # GraphDef
                    y = self.frozen_func(x=self.tf.constant(im))
                else:  # Lite or Edge TPU
                    input = self.input_details[0]
                    int8 = input['dtype'] == np.uint8  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                    if int8:
                        scale, zero_point = input['quantization']
                        im = (im / scale + zero_point).astype(np.uint8)  # –¥–µ—Å–∫–µ–π–ª–∏–Ω–≥
                    self.interpreter.set_tensor(input['index'], im)
                    self.interpreter.invoke()
                    y = []
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤
                    for output in self.output_details:
                        x = self.interpreter.get_tensor(output['index'])
                        if int8:
                            scale, zero_point = output['quantization']
                            x = (x.astype(np.float32) - zero_point) * scale  # —Ä–µ—Å–µ–π–ª–∏–Ω–≥
                        y.append(x)
                # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –≤ –ø–∏–∫—Å–µ–ª–∏
                y = [x if isinstance(x, np.ndarray) else x.numpy() for x in y]
                y[0][..., :4] *= [w, h, w, h]  # xywh –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ -> –ø–∏–∫—Å–µ–ª–∏

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if isinstance(y, (list, tuple)):
                return self.from_numpy(y[0]) if len(y) == 1 else [self.from_numpy(x) for x in y]
            else:
                return self.from_numpy(y)

        def from_numpy(self, x):
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑ numpy –≤ torch
            return torch.from_numpy(x).to(self.device) if isinstance(x, np.ndarray) else x

        def warmup(self, imgsz=(1, 3, 640, 640)):
            # –¢–æ–ø–ª–∏–≤–æ –¥–ª—è –º–æ–¥–µ–ª–∏ (Îü∞ 1 inference)
            warmup_types = self.pt, self.jit, self.onnx, self.engine, self.saved_model, self.pb, self.triton
            if any(warmup_types) and (self.device.type != 'cpu' or self.triton):
                im = torch.empty(*imgsz, dtype=torch.half if self.fp16 else torch.float, device=self.device)  # –≤—Ö–æ–¥
                for _ in range(2 if self.jit else 1):  #
                    self.forward(im)  # —Ç–æ–ø–ª–∏–≤–æ

        @staticmethod
        def _model_type(p='path/to/model.pt'):
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏ –ø–æ –ø—É—Ç–∏
            from export import export_formats
            from utils.downloads import is_url
            sf = list(export_formats().Suffix)  # —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
            if not is_url(p, check=False):
                check_suffix(p, sf)  # –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
            url = urlparse(p)  # –µ—Å–ª–∏ URL - –≤–æ–∑–º–æ–∂–Ω–æ Triton
            types = [s in Path(p).name for s in sf]
            types[8] &= not types[9]  # tflite &= not edgetpu
            triton = not any(types) and all([any(s in url.scheme for s in ["http", "grpc"]), url.netloc])
            return types + [triton]

        @staticmethod
        def _load_metadata(f=Path('path/to/meta.yaml')):
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ meta.yaml
            if f.exists():
                d = yaml_load(f)
                return d['stride'], d['names']  # –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç stride –∏ names
            return None, None

class AutoShape(nn.Module):
    # –û–±–µ—Ä—Ç–∫–∞ YOLOv5 –¥–ª—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (cv2/np/PIL/torch). –í–∫–ª—é—á–∞–µ—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É, –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –∏ NMS
    conf = 0.25  # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ NMS
    iou = 0.45  # –ü–æ—Ä–æ–≥ IoU NMS
    agnostic = False  # –ö–ª–∞—Å—Å-–∞–≥–Ω–æ—Å—Ç–∏—á–Ω—ã–π NMS
    multi_label = False  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –Ω–∞ –±–æ–∫—Å
    classes = None  # (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫) —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª–∞—Å—Å–∞–º, –Ω–∞–ø—Ä–∏–º–µ—Ä [0, 15, 16] –¥–ª—è COCO (–ª—é–¥–∏, –∫–æ—à–∫–∏, —Å–æ–±–∞–∫–∏)
    max_det = 1000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ç–µ–∫—Ü–∏–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    amp = False  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–º–µ—à–∞–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (AMP) –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞

    def __init__(self, model, verbose=True):
        super().__init__()
        if verbose:
            LOGGER.info('–î–æ–±–∞–≤–ª–µ–Ω–∏–µ AutoShape... ')
        # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –∏–∑ –º–æ–¥–µ–ª–∏
        copy_attr(self, model, include=('yaml', 'nc', 'hyp', 'names', 'stride', 'abc'), exclude=())
        self.dmb = isinstance(model, DetectMultiBackend)  # –≠–∫–∑–µ–º–ø–ª—è—Ä DetectMultiBackend
        self.pt = not self.dmb or model.pt  # PyTorch –º–æ–¥–µ–ª—å
        self.model = model.eval()
        if self.pt:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è Detect
            m = self.model.model.model[-1] if self.dmb else self.model.model[-1]
            m.inplace = False  # –ë–µ–∑ inplace-–æ–ø–µ—Ä–∞—Ü–∏–π –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≤ –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ–π —Å—Ä–µ–¥–µ
            m.export = True  # –ù–µ –≤—ã–≤–æ–¥–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ—Ç–µ—Ä—å

    def _apply(self, fn):
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ to(), cpu(), cuda(), half() –∫ —Ç–µ–Ω–∑–æ—Ä–∞–º –º–æ–¥–µ–ª–∏, –Ω–µ —è–≤–ª—è—é—â–∏–º—Å—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏–ª–∏ –±—É—Ñ–µ—Ä–∞–º–∏
        self = super()._apply(fn)
        if self.pt:
            m = self.model.model.model[-1] if self.dmb else self.model.model[-1]
            m.stride = fn(m.stride)
            m.grid = list(map(fn, m.grid))
            if isinstance(m.anchor_grid, list):
                m.anchor_grid = list(map(fn, m.anchor_grid))
        return self

    @smart_inference_mode()
    def forward(self, ims, size=640, augment=False, profile=False):
        # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å —Å —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. –î–ª—è size(height=640, width=1280) –ø—Ä–∏–º–µ—Ä—ã –≤—Ö–æ–¥–æ–≤:
        #   —Ñ–∞–π–ª:        ims = 'data/images/zidane.jpg'
        #   URI:          = 'https://ultralytics.com/images/zidane.jpg'
        #   OpenCV:       = cv2.imread('image.jpg')[:,:,::-1]  # HWC BGR ‚Üí RGB
        #   PIL:          = Image.open('image.jpg')
        #   numpy:        = np.zeros((640,1280,3))  # HWC
        #   torch:        = torch.zeros(16,3,320,640)  # BCHW (–º–∞—Å—à—Ç–∞–± 0-1)
        #   —Å–ø–∏—Å–æ–∫:       = [Image.open('image1.jpg'), ...]

        dt = (Profile(), Profile(), Profile())
        with dt[0]:
            if isinstance(size, int):
                size = (size, size)
            p = next(self.model.parameters()) if self.pt else torch.empty(1, device=self.model.device)
            autocast = self.amp and (p.device.type != 'cpu')
            if isinstance(ims, torch.Tensor):  # Torch
                with amp.autocast(autocast):
                    return self.model(ims.to(p.device).type_as(p), augment=augment)

            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
            n, ims = (len(ims), list(ims)) if isinstance(ims, (list, tuple)) else (1, [ims])
            shape0, shape1, files = [], [], []
            for i, im in enumerate(ims):
                f = f'image{i}'
                if isinstance(im, (str, Path)):  # –ò–º—è —Ñ–∞–π–ª–∞ –∏–ª–∏ URI
                    im, f = Image.open(requests.get(im, stream=True).raw if str(im).startswith('http') else im), im
                    im = np.asarray(exif_transpose(im))
                elif isinstance(im, Image.Image):  # PIL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    im, f = np.asarray(exif_transpose(im)), getattr(im, 'filename', f) or f
                files.append(Path(f).with_suffix('.jpg').name)
                if im.shape[0] < 5:  # CHW ‚Üí HWC
                    im = im.transpose((1, 2, 0))
                im = im[..., :3] if im.ndim == 3 else cv2.cvtColor(im, cv2.COLOR_GRAY2BGR)  # –¢—Ä–µ—Ö–∫–∞–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                s = im.shape[:2]
                shape0.append(s)
                g = max(size) / max(s)  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
                shape1.append([int(y * g) for y in s])
                ims[i] = im if im.data.contiguous else np.ascontiguousarray(im)
            shape1 = [make_divisible(x, self.stride) for x in np.array(shape1).max(0)]  # –§–æ—Ä–º–∞ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
            x = [letterbox(im, shape1, auto=False)[0] for im in ims]  # Padding
            x = np.ascontiguousarray(np.array(x).transpose((0, 3, 1, 2)))  # BHWC ‚Üí BCHW
            x = torch.from_numpy(x).to(p.device).type_as(p) / 255  # uint8 ‚Üí fp16/32

        with amp.autocast(autocast):
            # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
            with dt[1]:
                y = self.model(x, augment=augment)

            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
            with dt[2]:
                y = non_max_suppression(y if self.dmb else y[0],
                                        self.conf,
                                        self.iou,
                                        self.classes,
                                        self.agnostic,
                                        self.multi_label,
                                        max_det=self.max_det)
                for i in range(n):
                    scale_boxes(shape1, y[i][:, :4], shape0[i])

            return Detections(ims, y, files, dt, self.names, x.shape)


class Detections:
    # –ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ YOLOv5
    def __init__(self, ims, pred, files, times=(0, 0, 0), names=None, shape=None):
        super().__init__()
        d = pred[0].device
        gn = [torch.tensor([*(im.shape[i] for i in [1, 0, 1, 0]), 1, 1], device=d) for im in ims]  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        self.ims = ims  # –°–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ numpy
        self.pred = pred  # –°–ø–∏—Å–æ–∫ —Ç–µ–Ω–∑–æ—Ä–æ–≤ (xyxy, conf, cls)
        self.names = names  # –ò–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤
        self.files = files  # –ò–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        self.times = times  # –í—Ä–µ–º—è –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        self.xyxy = pred  # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ xyxy (–ø–∏–∫—Å–µ–ª–∏)
        self.xywh = [xyxy2xywh(x) for x in pred]  # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ xywh (–ø–∏–∫—Å–µ–ª–∏)
        self.xyxyn = [x / g for x, g in zip(self.xyxy, gn)]  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ xyxy
        self.xywhn = [x / g for x, g in zip(self.xywh, gn)]  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ xywh
        self.n = len(self.pred)  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞)
        self.t = tuple(x.t / self.n * 1E3 for x in times)  # –í—Ä–µ–º—è –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
        self.s = tuple(shape)  # –§–æ—Ä–º–∞ BCHW –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞

        def _run(self, pprint=False, show=False, save=False, crop=False, render=False, labels=True, save_dir=Path('')):
            s, crops = '', []
            for i, (im, pred) in enumerate(zip(self.ims, self.pred)):
                s += f'\nimage {i + 1}/{len(self.pred)}: {im.shape[0]}x{im.shape[1]} '
                if pred.shape[0]:
                    # –ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–µ—Ç–µ–∫—Ü–∏–π –ø–æ –∫–ª–∞—Å—Å–∞–º
                    for c in pred[:, -1].unique():
                        n = (pred[:, -1] == c).sum()
                        s += f"{n} {self.names[int(c)]}{'s' * (n > 1)}, "
                    s = s.rstrip(', ')
                    if show or save or render or crop:
                        # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
                        annotator = Annotator(im, example=str(self.names))
                        # –†–µ–Ω–¥–µ—Ä–∏–Ω–≥ –∫–∞–∂–¥–æ–≥–æ –±–æ–∫—Å–∞
                        for *box, conf, cls in reversed(pred):
                            label = f'{self.names[int(cls)]} {conf:.2f}'
                            if crop:
                                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—ã—Ä–µ–∑–æ–≤
                                file = save_dir / 'crops' / self.names[int(cls)] / self.files[i] if save else None
                                crops.append({
                                    'box': box,
                                    'conf': conf,
                                    'cls': cls,
                                    'label': label,
                                    'im': save_one_box(box, im, file=file, save=save)})
                            else:
                                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ—Ç–æ–∫
                                annotator.box_label(box, label if labels else '', color=colors(cls))
                        im = annotator.im
                else:
                    s += '(no detections)'

                # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                im = Image.fromarray(im.astype(np.uint8)) if isinstance(im, np.ndarray) else im
                if show:
                    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    display(im) if is_notebook() else im.show(self.files[i])
                if save:
                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    f = self.files[i]
                    im.save(save_dir / f)
                    if i == self.n - 1:
                        LOGGER.info(
                            f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {self.n} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ{'–π' * (self.n > 1)} –≤ {colorstr('bold', save_dir)}")
                if render:
                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≤–∏–¥–µ –º–∞—Å—Å–∏–≤–∞
                    self.ims[i] = np.asarray(im)
            if pprint:
                # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥
                s = s.lstrip('\n')
                return f'{s}\n–°–∫–æ—Ä–æ—Å—Ç—å: %.1fms –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞, %.1fms –∏–Ω—Ñ–µ—Ä–µ–Ω—Å, %.1fms NMS –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏ —Ä–∞–∑–º–µ—Ä–µ {self.s}' % self.t
            if crop:
                if save:
                    LOGGER.info(f'–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã—Ä–µ–∑–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {save_dir}\n')
                return crops

        @TryExcept('Showing images is not supported in this environment')
        def show(self, labels=True):
            # –ú–µ—Ç–æ–¥ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self._run(show=True, labels=labels)  # show results

        def save(self, labels=True, save_dir='runs/detect/exp', exist_ok=False):
            # –ú–µ—Ç–æ–¥ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            save_dir = increment_path(save_dir, exist_ok, mkdir=True)  # increment save_dir
            self._run(save=True, labels=labels, save_dir=save_dir)  # save results

        def crop(self, save=True, save_dir='runs/detect/exp', exist_ok=False):
            # –ú–µ—Ç–æ–¥ –¥–ª—è –≤—ã—Ä–µ–∑–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤
            save_dir = increment_path(save_dir, exist_ok, mkdir=True) if save else None
            return self._run(crop=True, save=save, save_dir=save_dir)  # crop results

        def render(self, labels=True):
            # –ú–µ—Ç–æ–¥ –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self._run(render=True, labels=labels)  # render results
            return self.ims

        def pandas(self):
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ pandas DataFrame
            new = copy(self)  # return copy
            ca = 'xmin', 'ymin', 'xmax', 'ymax', 'confidence', 'class', 'name'  # xyxy columns
            cb = 'xcenter', 'ycenter', 'width', 'height', 'confidence', 'class', 'name'  # xywh columns
            for k, c in zip(['xyxy', 'xyxyn', 'xywh', 'xywhn'], [ca, ca, cb, cb]):
                # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                a = [[x[:5] + [int(x[5]), self.names[int(x[5])]] for x in x.tolist()] for x in getattr(self, k)]
                setattr(new, k, [pd.DataFrame(x, columns=c) for x in a])
            return new

        def tolist(self):
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ Detections
            r = range(self.n)  # iterable
            x = [Detections([self.ims[i]], [self.pred[i]], [self.files[i]], self.times, self.names, self.s) for i in r]
            return x

        def print(self):
            # –ü–µ—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            LOGGER.info(self.__str__())

        def __len__(self):  # override len(results)
            return self.n

        def __str__(self):  # override print(results)
            return self._run(pprint=True)  # print results

        def __repr__(self):
            return f'YOLOv5 {self.__class__} instance\n' + self.__str__()

    class Proto(nn.Module):
        # –ú–æ–¥—É–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ—Ç–∏–ø–æ–≤ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        def __init__(self, c1, c_=256, c2=32):  # ch_in, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ç–æ—Ç–∏–ø–æ–≤, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Å–æ–∫
            super().__init__()
            self.cv1 = Conv(c1, c_, k=3)
            self.upsample = nn.Upsample(scale_factor=2, mode='nearest')
            self.cv2 = Conv(c_, c_, k=3)
            self.cv3 = Conv(c_, c2)

        def forward(self, x):
            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å
            return self.cv3(self.cv2(self.upsample(self.cv1(x))))

    class Classify(nn.Module):
        # –ì–æ–ª–æ–≤–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ YOLOv5
        def __init__(self, c1, c2, k=1, s=1, p=None, g=1):  # ch_in, ch_out, kernel, stride, padding, groups
            super().__init__()
            c_ = 1280  # –†–∞–∑–º–µ—Ä –¥–ª—è efficientnet_b0
            self.conv = Conv(c1, c_, k, s, autopad(k, p), g)
            self.pool = nn.AdaptiveAvgPool2d(1)  # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ —Ä–∞–∑–º–µ—Ä—É (b,c_,1,1)
            self.drop = nn.Dropout(p=0.0, inplace=True)
            self.linear = nn.Linear(c_, c2)  # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π

        def forward(self, x):
            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –≥–æ–ª–æ–≤—É
            if isinstance(x, list):
                x = torch.cat(x, 1)
            return self.linear(self.drop(self.pool(self.conv(x)).flatten(1)))