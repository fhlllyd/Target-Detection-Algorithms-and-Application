# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
"""
Run YOLOv5 segmentation inference on images, videos, directories, streams, etc.

Usage - sources:
    $ python segment/predict.py --weights yolov5s-seg.pt --source 0                               # webcam
                                                                  img.jpg                         # image
                                                                  vid.mp4                         # video
                                                                  screen                          # screenshot
                                                                  path/                           # directory
                                                                  'path/*.jpg'                    # glob
                                                                  'https://youtu.be/Zgi9g1ksQHc'  # YouTube
                                                                  'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream

Usage - formats:
    $ python segment/predict.py --weights yolov5s-seg.pt                 # PyTorch
                                          yolov5s-seg.torchscript        # TorchScript
                                          yolov5s-seg.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                                          yolov5s-seg_openvino_model     # OpenVINO
                                          yolov5s-seg.engine             # TensorRT
                                          yolov5s-seg.mlmodel            # CoreML (macOS-only)
                                          yolov5s-seg_saved_model        # TensorFlow SavedModel
                                          yolov5s-seg.pb                 # TensorFlow GraphDef
                                          yolov5s-seg.tflite             # TensorFlow Lite
                                          yolov5s-seg_edgetpu.tflite     # TensorFlow Edge TPU
                                          yolov5s-seg_paddle_model       # PaddlePaddle
"""

import argparse
import os
import platform
import sys
from pathlib import Path

import torch

# –ü–æ–ª—É—á–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ —Ç–µ–∫—É—â–µ–º—É —Ñ–∞–π–ª—É
FILE = Path(__file__).resolve()
# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é YOLOv5
ROOT = FILE.parents[1]
# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—É—Ç—å, –µ—Å–ª–∏ –µ–µ —Ç–∞–º –µ—â–µ –Ω–µ—Ç
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))
# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))

from models.common import DetectMultiBackend
from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams
from utils.general import (LOGGER, Profile, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,
                           increment_path, non_max_suppression, print_args, scale_boxes, scale_segments,
                           strip_optimizer, xyxy2xywh)
from utils.plots import Annotator, colors, save_one_box
from utils.segment.general import masks2segments, process_mask
from utils.torch_utils import select_device, smart_inference_mode


@smart_inference_mode()
def run(
    weights=ROOT / 'yolov5s-seg.pt',  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –≤–µ—Å–∞–º–∏ –º–æ–¥–µ–ª–∏
    source=ROOT / 'data/images',  # –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö (—Ñ–∞–π–ª, –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è, URL –∏ —Ç.–¥.)
    data=ROOT / 'data/coco128.yaml',  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
    imgsz=(640, 640),  # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (–≤—ã—Å–æ—Ç–∞, —à–∏—Ä–∏–Ω–∞)
    conf_thres=0.25,  # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    iou_thres=0.45,  # –ü–æ—Ä–æ–≥ IoU –¥–ª—è –Ω–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è (NMS)
    max_det=1000,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ç–µ–∫—Ü–∏–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    device='',  # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (GPU –∏–ª–∏ CPU)
    view_img=False,  # –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
    save_txt=False,  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–∞—Ö
    save_conf=False,  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–∞—Ö —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    save_crop=False,  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤—ã—Ä–µ–∑–∞–Ω–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
    nosave=False,  # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –≤–∏–¥–µ–æ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    classes=None,  # –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ –∫–ª–∞—Å—Å–∞–º
    agnostic_nms=False,  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å-–∞–≥–Ω–æ—Å—Ç–∏—á–Ω–æ–µ –Ω–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ
    augment=False,  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ
    visualize=False,  # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏
    update=False,  # –û–±–Ω–æ–≤–∏—Ç—å –≤—Å–µ –º–æ–¥–µ–ª–∏
    project=ROOT / 'runs/predict-seg',  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    name='exp',  # –ò–º—è –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    exist_ok=False,  # –†–∞–∑—Ä–µ—à–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    line_thickness=3,  # –¢–æ–ª—â–∏–Ω–∞ —Ä–∞–º–æ–∫ –≤–æ–∫—Ä—É–≥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
    hide_labels=False,  # –°–∫—Ä—ã—Ç—å –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
    hide_conf=False,  # –°–∫—Ä—ã—Ç—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
    half=False,  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–ª–æ–≤–∏–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å (FP16) –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ
    dnn=False,  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OpenCV DNN –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å ONNX –º–æ–¥–µ–ª—å—é
    vid_stride=1,  # –®–∞–≥ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ–∫–∞–¥—Ä–æ–≤
    retina_masks=False,
):
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç—Ä–æ–∫—É
    source = str(source)
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
    save_img = not nosave and not source.endswith('.txt')
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ —Ñ–∞–π–ª–æ–º —Å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –≤–∏–¥–µ–æ
    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ URL
    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –≤–µ–±-–∫–∞–º–µ—Ä–æ–π, —Ç–µ–∫—Å—Ç–æ–≤—ã–º —Ñ–∞–π–ª–æ–º –∏–ª–∏ URL
    webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–º
    screenshot = source.lower().startswith('screen')
    if is_url and is_file:
        # –ï—Å–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ - URL –∏ —Ñ–∞–π–ª, —Å–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        source = check_file(source)

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)
    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    device = select_device(device)
    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)
    # –ü–æ–ª—É—á–∞–µ–º —à–∞–≥ –º–æ–¥–µ–ª–∏, –∏–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤ –∏ —Ñ–ª–∞–≥, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ PyTorch
    stride, names, pt = model.stride, model.names, model.pt
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —à–∞–≥—É –º–æ–¥–µ–ª–∏
    imgsz = check_img_size(imgsz, s=stride)

    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö
    bs = 1  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
    if webcam:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        view_img = check_imshow(warn=True)
        # –°–æ–∑–¥–∞–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–ª—è –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞
        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)
        bs = len(dataset)
    elif screenshot:
        # –°–æ–∑–¥–∞–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–ª—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
        dataset = LoadScreenshots(source, img_size=imgsz, stride=stride, auto=pt)
    else:
        # –°–æ–∑–¥–∞–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ
    vid_path, vid_writer = [None] * bs, [None] * bs

    # –ü—Ä–æ–∏–∑–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏
    model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))
    # –°—á–µ—Ç—á–∏–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    seen = 0
    # –°–ø–∏—Å–æ–∫ –æ–∫–æ–Ω –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    windows = []
    # –°—á–µ—Ç—á–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —ç—Ç–∞–ø–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    dt = (Profile(), Profile(), Profile())
    for path, im, im0s, vid_cap, s in dataset:
        with dt[0]:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä –∏ –ø–µ—Ä–µ–º–µ—â–∞–µ–º –µ–≥–æ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            im = torch.from_numpy(im).to(model.device)
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–æ–ª–Ω—É—é –∏–ª–∏ –ø–æ–ª–æ–≤–∏–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å
            im = im.half() if model.fp16 else im.float()
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            im /= 255
            if len(im.shape) == 3:
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±–∞—Ç—á–∞, –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç
                im = im[None]

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
        with dt[1]:
            if visualize:
                # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                visualize = increment_path(save_dir / Path(path).stem, mkdir=True)
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –ø—Ä–æ—Ç–æ—Ç–∏–ø—ã –º–∞—Å–æ–∫
            pred, proto = model(im, augment=augment, visualize=visualize)[:2]

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ (NMS)
        with dt[2]:
            pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det, nm=32)

        # –í—Ç–æ—Ä–æ–π —ç—Ç–∞–ø –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
        # pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            for i, det in enumerate(pred):  # –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                seen += 1
                if webcam:  # batch_size >= 1
                    p, im0, frame = path[i], im0s[i].copy(), dataset.count
                    s += f'{i}: '
                else:
                    p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)

                p = Path(p)  # –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ Path
                save_path = str(save_dir / p.name)  # –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                txt_path = str(save_dir / 'labels' / p.stem) + (
                    '' if dataset.mode == 'image' else f'_{frame}')  # –ø—É—Ç—å –¥–ª—è .txt
                s += '%gx%g ' % im.shape[2:]  # —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
                imc = im0.copy() if save_crop else im0  # –∫–æ–ø–∏—è –¥–ª—è –≤—ã—Ä–µ–∑–∞–Ω–∏—è
                annotator = Annotator(im0, line_width=line_thickness, example=str(names))
                if len(det):
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Å–æ–∫
                    masks = process_mask(proto[i], det[:, 6:], det[:, :4], im.shape[2:], upsample=True)  # HWC
                    # –ú–∞—Å—à—Ç–∞–±–±–æ–∫—Å–æ–≤ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
                    det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()

                    # –°–µ–≥–º–µ–Ω—Ç—ã
                    if save_txt:
                        segments = reversed(masks2segments(masks))
                        segments = [scale_segments(im.shape[2:], x, im0.shape, normalize=True) for x in segments]

                    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    for c in det[:, 5].unique():
                        n = (det[:, 5] == c).sum()  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ç–µ–∫—Ü–∏–π
                        s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "  # –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫—É

                    # –†–∏—Å–æ–≤–∞–Ω–∏–µ –º–∞—Å–æ–∫
                    annotator.masks(masks,
                                    colors=[colors(x, True) for x in det[:, 5]],
                                    im_gpu=None if retina_masks else im[i])

                    # –ó–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    for j, (*xyxy, conf, cls) in enumerate(reversed(det[:, :6])):
                        if save_txt:  # –ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª
                            segj = segments[j].reshape(-1)  # –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞
                            line = (cls, *segj, conf) if save_conf else (cls, *segj)  # —Ñ–æ—Ä–º–∞—Ç –º–µ—Ç–∫–∏
                            with open(f'{txt_path}.txt', 'a') as f:
                                f.write(('%g ' * len(line)).rstrip() % line + '\n')

                        if save_img or save_crop or view_img:  # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–º–∫–∏
                            c = int(cls)  # –∫–ª–∞—Å—Å –∫–∞–∫ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ
                            label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')
                            annotator.box_label(xyxy, label, color=colors(c, True))
                        if save_crop:
                            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—ã—Ä–µ–∑–∞
                            save_one_box(xyxy, imc, file=save_dir / 'crops' / names[c] / f'{p.stem}.jpg', BGR=True)

                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                im0 = annotator.result()
                if view_img:
                    if platform.system() == 'Linux' and p not in windows:
                        windows.append(p)
                        # –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫–Ω–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞
                        cv2.namedWindow(str(p), cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)
                        cv2.resizeWindow(str(p), im0.shape[1], im0.shape[0])
                    cv2.imshow(str(p), im0)
                    if cv2.waitKey(1) == ord('q'):  # –≤—ã—Ö–æ–¥ –ø–æ –Ω–∞–∂–∞—Ç–∏—é Q
                        exit()

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                if save_img:
                    if dataset.mode == 'image':
                        cv2.imwrite(save_path, im0)
                    else:  # –≤–∏–¥–µ–æ –∏–ª–∏ –ø–æ—Ç–æ–∫
                        if vid_path[i] != save_path:  # –Ω–æ–≤—ã–π –≤–∏–¥–µ–æ—Ñ–∞–π–ª
                            vid_path[i] = save_path
                            if isinstance(vid_writer[i], cv2.VideoWriter):
                                vid_writer[i].release()  # –∑–∞–∫—Ä—ã—Ç–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø–∏—Å—á–∏–∫–∞
                            if vid_cap:  # –≤–∏–¥–µ–æ
                                fps = vid_cap.get(cv2.CAP_PROP_FPS)
                                w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                                h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                            else:  # –ø–æ—Ç–æ–∫
                                fps, w, h = 30, im0.shape[1], im0.shape[0]
                            save_path = str(Path(save_path).with_suffix('.mp4'))  # —Ñ–æ—Ä–º–∞—Ç mp4
                            vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
                        vid_writer[i].write(im0)

            # –í—ã–≤–æ–¥ –≤—Ä–µ–º–µ–Ω–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
            LOGGER.info(f"{s}{'' if len(det) else '(no detections), '}{dt[1].dt * 1E3:.1f}ms")

        # –ò—Ç–æ–≥–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        t = tuple(x.t / seen * 1E3 for x in dt)  # –≤—Ä–µ–º—è –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
        LOGGER.info(f'–°–∫–æ—Ä–æ—Å—Ç—å: %.1fms –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞, %.1fms –∏–Ω—Ñ–µ—Ä–µ–Ω—Å, %.1fms NMS –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ' % t)
        if save_txt or save_img:
            s = f"\n{len(list(save_dir.glob('labels/*.txt')))} –º–µ—Ç–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {save_dir / 'labels'}" if save_txt else ''
            LOGGER.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {colorstr('bold', save_dir)}{s}")
        if update:
            strip_optimizer(weights[0])  # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏


def parse_opt():
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    parser = argparse.ArgumentParser()

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
    parser.add_argument('--weights', nargs='+', type=str,
                        default=ROOT / 'runs/train-seg/wheel/weights/best.pt',
                        help='–ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏')
    parser.add_argument('--source', type=str,
                        default=ROOT / 'C:/Users/C110/Desktop/ÁßØÊ∞¥Ê£ÄÊµãÂÆûÈ™åÁÖßÁâá/wheel-2.jpg',
                        help='–∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö (—Ñ–∞–π–ª/–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è/URL/—ç–∫—Ä–∞–Ω/0 –¥–ª—è –≤–µ–±-–∫–∞–º–µ—Ä—ã)')
    parser.add_argument('--data', type=str,
                        default=ROOT / 'data/coco128.yaml',
                        help='–ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ–ø–∏—Å–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int,
                        default=[640],
                        help='—Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (–≤—ã—Å–æ—Ç–∞, —à–∏—Ä–∏–Ω–∞)')
    parser.add_argument('--conf-thres', type=float, default=0.25,
                        help='–ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π')
    parser.add_argument('--iou-thres', type=float, default=0.45,
                        help='–ø–æ—Ä–æ–≥ IoU –¥–ª—è –Ω–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è (NMS)')
    parser.add_argument('--max-det', type=int, default=1000,
                        help='–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ç–µ–∫—Ü–∏–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    parser.add_argument('--device', default='',
                        help='—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0, 0,1,2,3 –∏–ª–∏ cpu)')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    parser.add_argument('--view-img', action='store_true',
                        help='–ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–∞ —ç–∫—Ä–∞–Ω–µ')
    parser.add_argument('--save-txt', action='store_true',
                        help='—Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–∞—Ö')
    parser.add_argument('--save-conf', action='store_true',
                        help='—Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–∞—Ö')
    parser.add_argument('--save-crop', action='store_true',
                        help='—Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤—ã—Ä–µ–∑–∞–Ω–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ —Å –¥–µ—Ç–µ–∫—Ü–∏—è–º–∏')
    parser.add_argument('--nosave', action='store_true',
                        help='–Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/–≤–∏–¥–µ–æ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    parser.add_argument('--classes', nargs='+', type=int,
                        help='—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª–∞—Å—Å–∞–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, --classes 0 –∏–ª–∏ 0 2 3)')
    parser.add_argument('--agnostic-nms', action='store_true',
                        help='–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å-–∞–≥–Ω–æ—Å—Ç–∏—á–Ω–æ–µ –Ω–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ')
    parser.add_argument('--augment', action='store_true',
                        help='–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    parser.add_argument('--project', default=ROOT / 'runs/predict-seg',
                        help='–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    parser.add_argument('--name', default='exp',
                        help='–∏–º—è –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    parser.add_argument('--exist-ok', action='store_true',
                        help='—Ä–∞–∑—Ä–µ—à–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏')

    # –ü—Ä–æ—á–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument('--line-thickness', default=3, type=int,
                        help='—Ç–æ–ª—â–∏–Ω–∞ —Ä–∞–º–æ–∫ –≤–æ–∫—Ä—É–≥ –¥–µ—Ç–µ–∫—Ü–∏–π')
    parser.add_argument('--hide-labels', default=False, action='store_true',
                        help='—Å–∫—Ä—ã–≤–∞—Ç—å –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö')
    parser.add_argument('--hide-conf', default=False, action='store_true',
                        help='—Å–∫—Ä—ã–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö')
    parser.add_argument('--half', action='store_true',
                        help='–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–ª–æ–≤–∏–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å (FP16)')
    parser.add_argument('--dnn', action='store_true',
                        help='–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OpenCV DNN –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å ONNX –º–æ–¥–µ–ª—å—é')
    parser.add_argument('--vid-stride', type=int, default=1,
                        help='—à–∞–≥ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ–∫–∞–¥—Ä–æ–≤')
    parser.add_argument('--retina-masks', action='store_true',
                        help='–æ—Ç–æ–±—Ä–∞–∂–∞—Ç—å –º–∞—Å–∫–∏ –≤ –Ω–∞—Ç–∏–≤–Ω–æ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏')

    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    opt = parser.parse_args()
    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1
    # –í—ã–≤–æ–¥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    print_args(vars(opt))
    return opt


def main(opt):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
    check_requirements(exclude=('tensorboard', 'thop'))
    # –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
    run(**vars(opt))


if __name__ == "__main__":
    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∏ –∑–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–∞–º–º—ã
    opt = parse_opt()
    main(opt)