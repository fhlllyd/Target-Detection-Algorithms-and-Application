# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
"""
Train a YOLOv5 segment model on a segment dataset
Models and datasets download automatically from the latest YOLOv5 release.

Usage - Single-GPU training:
    $ python segment/train.py --data coco128-seg.yaml --weights yolov5s-seg.pt --img 640  # from pretrained (recommended)
    $ python segment/train.py --data coco128-seg.yaml --weights '' --cfg yolov5s-seg.yaml --img 640  # from scratch

Usage - Multi-GPU DDP training:
    $ python -m torch.distributed.run --nproc_per_node 4 --master_port 1 segment/train.py --data coco128-seg.yaml --weights yolov5s-seg.pt --img 640 --device 0,1,2,3

Models:     https://github.com/ultralytics/yolov5/tree/master/models
Datasets:   https://github.com/ultralytics/yolov5/tree/master/data
Tutorial:   https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data
"""

import argparse
import math
import os
import random
import sys
import time
from copy import deepcopy
from datetime import datetime
from pathlib import Path

import numpy as np
import torch
import torch.distributed as dist
import torch.nn as nn
import yaml
from torch.optim import lr_scheduler
from tqdm import tqdm

FILE = Path(__file__).resolve()
ROOT = FILE.parents[1]  # –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è YOLOv5
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—É—Ç—å
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å

import segment.val as validate  # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
from models.experimental import attempt_load
from models.yolo import SegmentationModel
from utils.autoanchor import check_anchors
from utils.autobatch import check_train_batch_size
from utils.callbacks import Callbacks
from utils.downloads import attempt_download, is_url
from utils.general import (LOGGER, TQDM_BAR_FORMAT, check_amp, check_dataset, check_file, check_git_info,
                           check_git_status, check_img_size, check_requirements, check_suffix, check_yaml, colorstr,
                           get_latest_run, increment_path, init_seeds, intersect_dicts, labels_to_class_weights,
                           labels_to_image_weights, one_cycle, print_args, print_mutation, strip_optimizer, yaml_save)
from utils.loggers import GenericLogger
from utils.plots import plot_evolve, plot_labels
from utils.segment.dataloaders import create_dataloader
from utils.segment.loss import ComputeLoss
from utils.segment.metrics import KEYS, fitness
from utils.segment.plots import plot_images_and_masks, plot_results_with_masks
from utils.torch_utils import (EarlyStopping, ModelEMA, de_parallel, select_device, smart_DDP, smart_optimizer,
                               smart_resume, torch_distributed_zero_first)

LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # –†–∞–Ω–≥ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞
RANK = int(os.getenv('RANK', -1))  # –†–∞–Ω–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞ –≤ÂàÜÂ∏ÉÂºè –æ–±—É—á–µ–Ω–∏–∏
WORLD_SIZE = int(os.getenv('WORLD_SIZE', 1))  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
GIT_INFO = check_git_info()  # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥–∏—Ç-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏


def train(hyp, opt, device, callbacks):  # hyp - –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å
    # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    save_dir, epochs, batch_size, weights, single_cls, evolve, data, cfg, resume, noval, nosave, workers, freeze, mask_ratio = \
        Path(opt.save_dir), opt.epochs, opt.batch_size, opt.weights, opt.single_cls, opt.evolve, opt.data, opt.cfg, \
            opt.resume, opt.noval, opt.nosave, opt.workers, opt.freeze, opt.mask_ratio

    # –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤
    w = save_dir / 'weights'
    (w.parent if evolve else w).mkdir(parents=True, exist_ok=True)  # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    last, best = w / 'last.pt', w / 'best.pt'  # –ü—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –∏ –ª—É—á—à–µ–º—É —á–µ–∫–ø–æ–∏–Ω—Ç—É

    # –ó–∞–≥—Ä—É–∑–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    if isinstance(hyp, str):
        with open(hyp, errors='ignore') as f:
            hyp = yaml.safe_load(f)  # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ YAML
    LOGGER.info(colorstr('hyperparameters: ') + ', '.join(f'{k}={v}' for k, v in hyp.items()))
    opt.hyp = hyp.copy()  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ opt

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫
    if not evolve:
        yaml_save(save_dir / 'hyp.yaml', hyp)
        yaml_save(save_dir / 'opt.yaml', vars(opt))

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–æ–≤
    data_dict = None
    if RANK in {-1, 0}:
        logger = GenericLogger(opt=opt, console_logger=LOGGER)

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
    plots = not evolve and not opt.noplots  # –í–∫–ª—é—á–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
    overlap = not opt.no_overlap  # –í–∫–ª—é—á–µ–Ω–∏–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    cuda = device.type != 'cpu'  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è CUDA
    init_seeds(opt.seed + 1 + RANK, deterministic=True)  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—èÁßçÂ≠ê–æ–≤
    with torch_distributed_zero_first(LOCAL_RANK):
        data_dict = data_dict or check_dataset(data)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
    train_path, val_path = data_dict['train'], data_dict['val']
    nc = 1 if single_cls else int(data_dict['nc'])  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
    names = {0: 'item'} if single_cls and len(data_dict['names']) != 1 else data_dict['names']  # –ò–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤
    is_coco = isinstance(val_path, str) and val_path.endswith('coco/val2017.txt')  # –ü—Ä–æ–≤–µ—Ä–∫–∞ COCO –¥–∞—Ç–∞—Å–µ—Ç–∞

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    check_suffix(weights, '.pt')  # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    pretrained = weights.endswith('.pt')
    if pretrained:
        with torch_distributed_zero_first(LOCAL_RANK):
            weights = attempt_download(weights)  # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤
        ckpt = torch.load(weights, map_location='cpu')  # –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        model = SegmentationModel(cfg or ckpt['model'].yaml, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)
        exclude = ['anchor'] if (cfg or hyp.get('anchors')) and not resume else []  # –ò—Å–∫–ª—é—á–∞–µ–º—ã–µ —Å–ª–æ–∏
        csd = ckpt['model'].float().state_dict()  # –°–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–¥–µ–ª–∏
        csd = intersect_dicts(csd, model.state_dict(), exclude=exclude)  # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å–ª–æ–µ–≤
        model.load_state_dict(csd, strict=False)  # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤
        LOGGER.info(f'Transferred {len(csd)}/{len(model.state_dict())} items from {weights}')
    else:
        model = SegmentationModel(cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏

    # –ó–∞–º–æ—Ä–æ–∑–∫–∞ —Å–ª–æ–µ–≤
    freeze = [f'model.{x}.' for x in (freeze if len(freeze) > 1 else range(freeze[0]))]  # –°–ª–æ–∏ –¥–ª—è –∑–∞–º–æ—Ä–æ–∑–∫–∏
    for k, v in model.named_parameters():
        v.requires_grad = True  # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
        if any(x in k for x in freeze):
            LOGGER.info(f'freezing {k}')
            v.requires_grad = False  # –ó–∞–º–æ—Ä–æ–∑–∫–∞

    # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    gs = max(int(model.stride.max()), 32)  # –†–∞–∑–º–µ—Ä —Å–µ—Ç–∫–∏ (–º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —à–∞–≥)
    imgsz = check_img_size(opt.imgsz, gs, floor=gs * 2)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

    # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
    if RANK == -1 and batch_size == -1:  # –û—Ü–µ–Ω–∏–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –±–∞—Ç—á–∞
        batch_size = check_train_batch_size(model, imgsz, amp)
        logger.update_params({"batch_size": batch_size})

    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    nbs = 64  # –ù–æ–º–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
    accumulate = max(round(nbs / batch_size), 1)  # –ê–∫–∫—É–º—É–ª—è—Ü–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
    hyp['weight_decay'] *= batch_size * accumulate / nbs  # –ú–∞—Å—à—Ç–∞–± –≤–µ—Å–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
    optimizer = smart_optimizer(model, opt.optimizer, hyp['lr0'], hyp['momentum'], hyp['weight_decay'])

    # Scheduler (–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è)
    if opt.cos_lr:
        # –§—É–Ω–∫—Ü–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –ø–æ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–º—É –∑–∞–∫–æ–Ω—É –æ—Ç 1 –¥–æ hyp['lrf'] –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥ –æ–±—É—á–µ–Ω–∏—è
        lf = one_cycle(1, hyp['lrf'], epochs)
    else:
        # –õ–∏–Ω–µ–π–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
        lf = lambda x: (1 - x / epochs) * (1.0 - hyp['lrf']) + hyp['lrf']
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)

    # EMA (–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –º–æ–¥–µ–ª–∏)
    ema = ModelEMA(model) if RANK in {-1, 0} else None

    # Resume (–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π —Ç–æ—á–∫–∏)
    best_fitness, start_epoch = 0.0, 0
    if pretrained:
        if resume:
            # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è
            best_fitness, start_epoch, epochs = smart_resume(ckpt, optimizer, ema, weights, epochs, resume)
        del ckpt, csd

    # DP mode (–†–µ–∂–∏–º Data Parallel, –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö GPU)
    if cuda and RANK == -1 and torch.cuda.device_count() > 1:
        LOGGER.warning('WARNING ‚ö†Ô∏è DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n'
                       'See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.')
        model = torch.nn.DataParallel(model)

    # SyncBatchNorm (–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è BatchNorm –º–µ–∂–¥—É GPU)
    if opt.sync_bn and cuda and RANK != -1:
        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)
        LOGGER.info('Using SyncBatchNorm()')

    # Trainloader (–ó–∞–≥—Ä—É–∑—á–∏–∫ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
    train_loader, dataset = create_dataloader(
        train_path,
        imgsz,
        batch_size // WORLD_SIZE,
        gs,
        single_cls,
        hyp=hyp,
        augment=True,
        cache=None if opt.cache == 'val' else opt.cache,
        rect=opt.rect,
        rank=LOCAL_RANK,
        workers=workers,
        image_weights=opt.image_weights,
        quad=opt.quad,
        prefix=colorstr('train: '),
        shuffle=True,
        mask_downsample_ratio=mask_ratio,
        overlap_mask=overlap,
    )
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –≤—Å–µ—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –Ω–∞–±–æ—Ä–µ
    labels = np.concatenate(dataset.labels, 0)
    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –∫–ª–∞—Å—Å–∞ –≤ –º–µ—Ç–∫–∞—Ö
    mlc = int(labels[:, 0].max())
    assert mlc < nc, f'Label class {mlc} exceeds nc={nc} in {data}. Possible class labels are 0-{nc - 1}'

    # Process 0 (–ü—Ä–æ—Ü–µ—Å—Å —Å —Ä–∞–Ω–≥–æ–º 0, –æ–±—ã—á–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
    if RANK in {-1, 0}:
        val_loader = create_dataloader(val_path,
                                       imgsz,
                                       batch_size // WORLD_SIZE * 2,
                                       gs,
                                       single_cls,
                                       hyp=hyp,
                                       cache=None if noval else opt.cache,
                                       rect=True,
                                       rank=-1,
                                       workers=workers * 2,
                                       pad=0.5,
                                       mask_downsample_ratio=mask_ratio,
                                       overlap_mask=overlap,
                                       prefix=colorstr('val: '))[0]

        if not resume:
            if not opt.noautoanchor:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —è–∫–æ—Ä–Ω—ã—Ö —è—â–∏–∫–æ–≤
                check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)
            model.half().float()  # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ —è–∫–æ—Ä–Ω—ã—Ö —è—â–∏–∫–æ–≤

            if plots:
                # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–µ—Ç–æ–∫ –∫–ª–∞—Å—Å–æ–≤
                plot_labels(labels, names, save_dir)
        # callbacks.run('on_pretrain_routine_end', labels, names)

    # DDP mode (–†–µ–∂–∏–º Distributed Data Parallel, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö GPU)
    if cuda and RANK != -1:
        model = smart_DDP(model)

    # Model attributes (–ê—Ç—Ä–∏–±—É—Ç—ã –º–æ–¥–µ–ª–∏)
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ –¥–µ—Ç–µ–∫—Ü–∏–∏
    nl = de_parallel(model).model[-1].nl
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –ø–æ—Ç–µ—Ä—å –¥–ª—è —Ä–∞–º–æ–∫
    hyp['box'] *= 3 / nl
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –ø–æ—Ç–µ—Ä—å –¥–ª—è –∫–ª–∞—Å—Å–æ–≤
    hyp['cls'] *= nc / 80 * 3 / nl
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –ø–æ—Ç–µ—Ä—å –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤
    hyp['obj'] *= (imgsz / 640) ** 2 * 3 / nl
    hyp['label_smoothing'] = opt.label_smoothing
    model.nc = nc  # –ü—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–æ–≤ –∫ –º–æ–¥–µ–ª–∏
    model.hyp = hyp  # –ü—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫ –º–æ–¥–µ–ª–∏
    # –ü—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤ –∫ –º–æ–¥–µ–ª–∏
    model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc
    model.names = names

    # Start training (–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è)
    t0 = time.time()
    nb = len(train_loader)  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –Ω–∞–±–æ—Ä–µ
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π —Ä–∞–∑–æ–≥—Ä–µ–≤–∞
    nw = max(round(hyp['warmup_epochs'] * nb), 100)
    last_opt_step = -1
    maps = np.zeros(nc)  # –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º (mAP)
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: —Ç–æ—á–Ω–æ—Å—Ç—å, –ø–æ–ª–Ω–æ—Ç–∞, mAP@.5, mAP@.5-.95, –ø–æ—Ç–µ—Ä–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (—Ä–∞–º–∫–∏, –æ–±—ä–µ–∫—Ç—ã, –∫–ª–∞—Å—Å—ã)
    results = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
    scheduler.last_epoch = start_epoch - 1  # –ù–µ –º–µ–Ω—è—Ç—å
    # –°–∫–µ–π–ª–µ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–º–µ—à–∞–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
    scaler = torch.cuda.amp.GradScaler(enabled=amp)
    # –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—É—á–µ–Ω–∏—è
    stopper, stop = EarlyStopping(patience=opt.patience), False
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å
    compute_loss = ComputeLoss(model, overlap=overlap)
    # callbacks.run('on_train_start')
    LOGGER.info(f'Image sizes {imgsz} train, {imgsz} val\n'
                f'Using {train_loader.num_workers * WORLD_SIZE} dataloader workers\n'
                f"Logging results to {colorstr('bold', save_dir)}\n"
                f'Starting training for {epochs} epochs...')
    for epoch in range(start_epoch, epochs):  # epoch ------------------------------------------------------------------
        # callbacks.run('on_train_epoch_start')
        model.train()

        # Update image weights (–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–¥–Ω–æ–≥–æ GPU)
        if opt.image_weights:
            # –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤, —É—á–∏—Ç—ã–≤–∞—é—â–∏–µ —Ç–µ–∫—É—â—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º
            cw = model.class_weights.cpu().numpy() * (1 - maps) ** 2 / nc
            # –í–µ—Å–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤
            iw = labels_to_image_weights(dataset.labels, nc=nc, class_weights=cw)
            # –°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä –∏–Ω–¥–µ–∫—Å–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —É—á–µ—Ç–æ–º –≤–µ—Å–æ–≤
            dataset.indices = random.choices(range(dataset.n), weights=iw, k=dataset.n)

        # Update mosaic border (–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü –º–æ–∑–∞–∏–∫–∏, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        # b = int(random.uniform(0.25 * imgsz, 0.75 * imgsz + gs) // gs * gs)
        # dataset.mosaic_border = [b - imgsz, -b]  # height, width borders

        mloss = torch.zeros(4, device=device)  # –°—Ä–µ–¥–Ω–∏–µ –ø–æ—Ç–µ—Ä–∏
        if RANK != -1:
            train_loader.sampler.set_epoch(epoch)
        pbar = enumerate(train_loader)
        LOGGER.info(('\n' + '%11s' * 8) %
                    ('Epoch', 'GPU_mem', 'box_loss', 'seg_loss', 'obj_loss', 'cls_loss', 'Instances', 'Size'))
        if RANK in {-1, 0}:
            pbar = tqdm(pbar, total=nb, bar_format=TQDM_BAR_FORMAT)  # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        optimizer.zero_grad()
        for i, (imgs, targets, paths, _, masks) in pbar:  # batch ------------------------------------------------------
            # callbacks.run('on_train_batch_start')
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–µ–π —Å –Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è
            ni = i + nb * epoch
            # –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            imgs = imgs.to(device, non_blocking=True).float() / 255

            # Warmup (–†–∞–∑–æ–≥—Ä–µ–≤ –æ–±—É—á–µ–Ω–∏—è)
            if ni <= nw:
                xi = [0, nw]  # –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –ø–æ –∏—Ç–µ—Ä–∞—Ü–∏—è–º
                # compute_loss.gr = np.interp(ni, xi, [0.0, 1.0])  # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å IoU (obj_loss = 1.0 –∏–ª–∏ iou)
                # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
                accumulate = max(1, np.interp(ni, xi, [1, nbs / batch_size]).round())
                for j, x in enumerate(optimizer.param_groups):
                    # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Å–º–µ—â–µ–Ω–∏—è —Å–Ω–∏–∂–∞–µ—Ç—Å—è –æ—Ç 0.1 –¥–æ lr0, –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ - –æ—Ç 0.0 –¥–æ lr0
                    x['lr'] = np.interp(ni, xi, [hyp['warmup_bias_lr'] if j == 0 else 0.0, x['initial_lr'] * lf(epoch)])
                    if 'momentum' in x:
                        # –ú–æ–º–µ–Ω—Ç—É–º –∏–∑–º–µ–Ω—è–µ—Ç—Å—è –æ—Ç warmup_momentum –¥–æ momentum
                        x['momentum'] = np.interp(ni, xi, [hyp['warmup_momentum'], hyp['momentum']])
                        # Multi-scale training (–ú—É–ª—å—Ç–∏-—Å–∫–µ–π–ª –æ–±—É—á–µ–Ω–∏–µ)
                        if opt.multi_scale:
                            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö [0.5*imgsz, 1.5*imgsz]
                            sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) // gs * gs
                            # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
                            sf = sz / max(imgs.shape[2:])
                            if sf != 1:
                                # –ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä —Å –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ–º –¥–æ –∫—Ä–∞—Ç–Ω–æ–≥–æ gs
                                ns = [math.ceil(x * sf / gs) * gs for x in imgs.shape[2:]]
                                # –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –Ω–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä
                                imgs = nn.functional.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)

                        # Forward pass (–ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥)
                        with torch.cuda.amp.autocast(amp):
                            pred = model(imgs)  # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
                            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å
                            loss, loss_items = compute_loss(pred, targets.to(device), masks=masks.to(device).float())
                            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ—Ç–µ—Ä—å –¥–ª—è DDP
                            if RANK != -1:
                                loss *= WORLD_SIZE
                            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ—Ç–µ—Ä—å –¥–ª—è quad augmentation
                            if opt.quad:
                                loss *= 4.

                        # Backward pass (–û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥)
                        scaler.scale(loss).backward()

                        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
                        if ni - last_opt_step >= accumulate:
                            scaler.unscale_(optimizer)  # –£–±–∏—Ä–∞–µ–º –º–∞—Å—à—Ç–∞–± –¥–ª—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
                            # –û–±—Ä–µ–∑–∫–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
                            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
                            scaler.step(optimizer)  # –®–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
                            scaler.update()
                            optimizer.zero_grad()
                            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ EMA –º–æ–¥–µ–ª–∏
                            if ema:
                                ema.update(model)
                            last_opt_step = ni

                        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                        if RANK in {-1, 0}:
                            # –°—Ä–µ–¥–Ω–∏–µ –ø–æ—Ç–µ—Ä–∏
                            mloss = (mloss * i + loss_items) / (i + 1)
                            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ GPU
                            mem = f'{torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0:.3g}G'
                            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
                            pbar.set_description(('%11s' * 2 + '%11.4g' * 6) %
                                                 (f'{epoch}/{epochs - 1}', mem, *mloss, targets.shape[0],
                                                  imgs.shape[-1]))
                            # callbacks.run('on_train_batch_end', model, ni, imgs, targets, paths)

                            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–∑–∞–∏–∫
                            if plots:
                                if ni < 3:
                                    plot_images_and_masks(imgs, targets, masks, paths,
                                                          save_dir / f"train_batch{ni}.jpg")
                                if ni == 10:
                                    files = sorted(save_dir.glob('train*.jpg'))
                                    logger.log_images(files, "Mosaics", epoch)
                        # end batch ------------------------------------------------------------------------------------------------

                    # Scheduler (–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ LR)
                    lr = [x['lr'] for x in optimizer.param_groups]
                    scheduler.step()

                    if RANK in {-1, 0}:
                        # mAP calculation (–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫)
                        final_epoch = (epoch + 1 == epochs) or stopper.possible_stop
                        if not noval or final_epoch:
                            results, maps, _ = validate.run(
                                data_dict,
                                batch_size=batch_size // WORLD_SIZE * 2,
                                imgsz=imgsz,
                                half=amp,
                                model=ema.ema,
                                single_cls=single_cls,
                                dataloader=val_loader,
                                save_dir=save_dir,
                                plots=False,
                                callbacks=callbacks,
                                compute_loss=compute_loss,
                                mask_downsample_ratio=mask_ratio,
                                overlap=overlap
                            )

                        # Fitness calculation (–ö—Ä–∏—Ç–µ—Ä–∏–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏)
                        fi = fitness(np.array(results).reshape(1, -1))
                        stop = stopper(epoch=epoch, fitness=fi)
                        if fi > best_fitness:
                            best_fitness = fi

                        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
                        log_vals = list(mloss) + list(results) + lr
                        metrics_dict = dict(zip(KEYS, log_vals))
                        logger.log_metrics(metrics_dict, epoch)

                        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                        if (not nosave) or (final_epoch and not evolve):
                            ckpt = {
                                'epoch': epoch,
                                'best_fitness': best_fitness,
                                'model': deepcopy(de_parallel(model)).half(),
                                'ema': deepcopy(ema.ema).half(),
                                'updates': ema.updates,
                                'optimizer': optimizer.state_dict(),
                                'opt': vars(opt),
                                'git': GIT_INFO,
                                'date': datetime.now().isoformat()
                            }

                            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
                            torch.save(ckpt, last)
                            if best_fitness == fi:
                                torch.save(ckpt, best)
                            if opt.save_period > 0 and epoch % opt.save_period == 0:
                                torch.save(ckpt, w / f'epoch{epoch}.pt')
                                logger.log_model(w / f'epoch{epoch}.pt')
                            del ckpt

                    # Early stopping (–†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞)
                    if RANK != -1:
                        broadcast_list = [stop if RANK == 0 else None]
                        dist.broadcast_object_list(broadcast_list, 0)
                        if RANK != 0:
                            stop = broadcast_list[0]
                    if stop:
                        break  # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤

    if RANK in {-1, 0}:
        # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –æ–±—É—á–µ–Ω–∏—è
        LOGGER.info(f'\n{epoch - start_epoch + 1} —ç–ø–æ—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∑–∞ {(time.time() - t0) / 3600:.3f} —á–∞—Å–æ–≤.')

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
        for f in last, best:
            if f.exists():
                # –£–¥–∞–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∏–∑ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
                strip_optimizer(f)

                # –í–∞–ª–∏–¥–∞—Ü–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
                if f is best:
                    LOGGER.info(f'\n–ü—Ä–æ–≤–µ—Ä–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ {f}...')
                    results, _, _ = validate.run(
                        data_dict,  # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
                        batch_size=batch_size // WORLD_SIZE * 2,  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                        imgsz=imgsz,  # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                        model=attempt_load(f, device).half(),  # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≤ –ø–æ–ª—É–ørecision
                        iou_thres=0.65 if is_coco else 0.60,  # –ü–æ—Ä–æ–≥ IoU (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è COCO)
                        single_cls=single_cls,  # –û–¥–Ω–æ-/–º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
                        dataloader=val_loader,  # –ó–∞–≥—Ä—É–∑—á–∏–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                        save_dir=save_dir,  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                        save_json=is_coco,  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ COCO
                        verbose=True,  # –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥
                        plots=plots,  # –í–∫–ª—é—á–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                        callbacks=callbacks,  # –ö–æ–ª–ª–±—ç–∫–∏
                        compute_loss=compute_loss,  # –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
                        mask_downsample_ratio=mask_ratio,  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —É–º–µ–Ω—å—à–µ–Ω–∏—è –º–∞—Å–∫–∏
                        overlap=overlap  # –í–∫–ª—é—á–µ–Ω–∏–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
                    )

                    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è COCO –¥–∞—Ç–∞—Å–µ—Ç–∞
                    if is_coco:
                        metrics_dict = dict(zip(KEYS, list(mloss) + list(results) + lr))
                        logger.log_metrics(metrics_dict, epoch)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        logger.log_metrics(dict(zip(KEYS[4:16], results)), epochs)
        if not opt.evolve:
            logger.log_model(best, epoch)  # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ TensorBoard

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
        if plots:
            plot_results_with_masks(file=save_dir / 'results.csv')  # –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞
            files = ['results.png', 'confusion_matrix.png', *(f'{x}_curve.png' for x in ('F1', 'PR', 'P', 'R'))]
            files = [(save_dir / f) for f in files if (save_dir / f).exists()]  # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤

            LOGGER.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {colorstr('bold', save_dir)}")
            logger.log_images(files, "Results", epoch + 1)  # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ TensorBoard
            logger.log_images(sorted(save_dir.glob('val*.jpg')), "Validation", epoch + 1)

    # –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ GPU
    torch.cuda.empty_cache()
    return results  # –í–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞

def parse_opt(known=False):
    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –ø–∞—Ä—Å–µ—Ä–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    parser = argparse.ArgumentParser()
    # –ü—É—Ç—å –∫ –Ω–∞—á–∞–ª—å–Ω—ã–º –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏
    parser.add_argument('--weights', type=str, default=ROOT / '', help='initial weights path')
    # –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏ (model.yaml)
    parser.add_argument('--cfg', type=str, default='', help='model.yaml path')
    # –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –¥–∞—Ç–∞—Å–µ—Ç–∞ (dataset.yaml)
    parser.add_argument('--data', type=str, default=ROOT / 'data/wheel-seg.yaml', help='dataset.yaml path')
    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    parser.add_argument('--hyp', type=str, default=ROOT / 'data/hyps/hyp.scratch-low.yaml', help='hyperparameters path')
    # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è
    parser.add_argument('--epochs', type=int, default=300, help='total training epochs')
    # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –≤—Å–µ—Ö GPU, -1 –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs, -1 for autobatch')
    # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–ø–∏–∫—Å–µ–ª–∏)
    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='train, val image size (pixels)')
    # –§–ª–∞–≥ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    parser.add_argument('--rect', action='store_true', help='rectangular training')
    # –§–ª–∞–≥ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')
    # –§–ª–∞–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
    parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')
    # –§–ª–∞–≥ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ç–æ–ª—å–∫–æ –Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —ç–ø–æ—Ö–µ
    parser.add_argument('--noval', action='store_true', help='only validate final epoch')
    # –§–ª–∞–≥ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è AutoAnchor
    parser.add_argument('--noautoanchor', action='store_true', help='disable AutoAnchor')
    # –§–ª–∞–≥ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    parser.add_argument('--noplots', action='store_true', help='save no plot files')
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    parser.add_argument('--evolve', type=int, nargs='?', const=300, help='evolve hyperparameters for x generations')
    # –ë–∞–∫–µ—Ç Google Cloud Storage
    parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')
    # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–≤ RAM –∏–ª–∏ –Ω–∞ –¥–∏—Å–∫)
    parser.add_argument('--cache', type=str, nargs='?', const='ram', help='image --cache ram/disk')
    # –§–ª–∞–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–∑–≤–µ—à–µ–Ω–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    parser.add_argument('--image-weights', action='store_true', help='use weighted image selection for training')
    # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ CUDA (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0 –∏–ª–∏ 0,1,2,3 –∏–ª–∏ cpu)
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    # –§–ª–∞–≥ –º—É–ª—å—Ç–∏ scales –æ–±—É—á–µ–Ω–∏—è (–∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è +/- 50%)
    parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')
    # –§–ª–∞–≥ –æ–±—É—á–µ–Ω–∏—è –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∫–∞–∫ –æ–¥–Ω–æ–∫–ª–∞—Å—Å–æ–≤—ã—Ö
    parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')
    # –¢–∏–ø –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ (SGD, Adam, AdamW)
    parser.add_argument('--optimizer', type=str, choices=['SGD', 'Adam', 'AdamW'], default='SGD', help='optimizer')
    # –§–ª–∞–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è SyncBatchNorm (–¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –≤ DDP —Ä–µ–∂–∏–º–µ)
    parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')
    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤ dataloader (–Ω–∞ –∫–∞–∂–¥—ã–π RANK –≤ DDP —Ä–µ–∂–∏–º–µ)
    parser.add_argument('--workers', type=int, default=8, help='max dataloader workers (per RANK in DDP mode)')
    # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è
    parser.add_argument('--project', default=ROOT / 'runs/train-seg', help='save to project/name')
    # –ò–º—è –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    parser.add_argument('--name', default='exp', help='save to project/name')
    # –§–ª–∞–≥ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π_project/name –±–µ–∑ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    # –§–ª–∞–≥ÂêØÁî® —á–µ—Ç—ã—Ä–µ—Ö-–ø–æ—Ç–æ—á–Ω–æ–≥–æ dataloader
    parser.add_argument('--quad', action='store_true', help='quad dataloader')
    # –§–ª–∞–≥ÂêØÁî® –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π scheduler LR
    parser.add_argument('--cos-lr', action='store_true', help='cosine LR scheduler')
    # –≠–ø—Å–∏–ª–æ–Ω —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –º–µ—Ç–æ–∫
    parser.add_argument('--label-smoothing', type=float, default=0.0, help='Label smoothing epsilon')
    # –üÂøçËÄê EarlyStopping (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è)
    parser.add_argument('--patience', type=int, default=100, help='EarlyStopping patience (epochs without improvement)')
    # –§.layers –¥–ª—è –∑–∞–º–æ—Ä–æ–∑–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, backbone=10, first3=0 1 2)
    parser.add_argument('--freeze', nargs='+', type=int, default=[0], help='Freeze layers: backbone=10, first3=0 1 2')
    # –ü–µ—Ä–∏–æ–¥–∏—á–Ω–æ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–∞ (–æ—Ç–∫–ª—é—á–∏—Ç—å, –µ—Å–ª–∏ < 1)
    parser.add_argument('--save-period', type=int, default=-1, help='Save checkpoint every x epochs (disabled if < 1)')
    # –ì–ª–æ–±–∞–ª—å–Ω—ã–π seed –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    parser.add_argument('--seed', type=int, default=0, help='Global training seed')
    # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ DDP Multi-GPU (–Ω–µ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å)
    parser.add_argument('--local_rank', type=int, default=-1, help='Automatic DDP Multi-GPU argument, do not modify')

    # –ê—Ä–≥—É–º–µ–Ω—Ç—ã Instance Segmentation
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç downsample –º–∞—Å–∫–∏ –¥–ª—è —Å—ç–∫–æ–Ω–æ–º –ø–∞–º—è—Ç–∏
    parser.add_argument('--mask-ratio', type=int, default=4, help='Downsample the truth masks to saving memory')
    # –§–ª–∞–≥ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –º–∞—Å–∫ (–æ–±—É—á–µ–Ω–∏–µ –±—ã—Å—Ç—Ä–µ–µ, –Ω–æ —ÅÁ®ç‰Ωé mAP)
    parser.add_argument('--no-overlap', action='store_true', help='Overlap masks train faster at slightly less mAP')

    return parser.parse_known_args()[0] if known else parser.parse_args()


def main(opt, callbacks=Callbacks()):
    # –ü—Ä–æ–≤–µ—Ä–∫–∏
    if RANK in {-1, 0}:
        # –í—ã–≤–æ–¥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        print_args(vars(opt))
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ Git
        check_git_status()
        # –ü—Ä–æ–≤–µ—Ä–∫–∞_requirements
        check_requirements()

    # –í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
    if opt.resume and not opt.evolve:  # –í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∏–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ last.pt
        last = Path(check_file(opt.resume) if isinstance(opt.resume, str) else get_latest_run())
        opt_yaml = last.parent.parent / 'opt.yaml'  # Train options yaml
        opt_data = opt.data  # Original dataset
        if opt_yaml.is_file():
            with open(opt_yaml, errors='ignore') as f:
                d = yaml.safe_load(f)
        else:
            d = torch.load(last, map_location='cpu')['opt']
        opt = argparse.Namespace(**d)  # –ó–∞–º–µ–Ω–∞
        opt.cfg, opt.weights, opt.resume = '', str(last), True  # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
        if is_url(opt_data):
            opt.data = check_file(opt_data)  # –ò–∑–±–µ–∂–∞–Ω–∏–µ HUB resume auth timeout
    else:
        opt.data, opt.cfg, opt.hyp, opt.weights, opt.project = \
            check_file(opt.data), check_yaml(opt.cfg), check_yaml(opt.hyp), str(opt.weights), str(opt.project)  # –ü—Ä–æ–≤–µ—Ä–∫–∏
        assert len(opt.cfg) or len(opt.weights), 'either --cfg or --weights must be specified'
        if opt.evolve:
            if opt.project == str(ROOT / 'runs/train'):  # –ï—Å–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∏–º—è –ø—Ä–æ–µ–∫—Ç–∞, –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å –≤ runs/evolve
                opt.project = str(ROOT / 'runs/evolve')
            opt.exist_ok, opt.resume = opt.resume, False  # –ü–µ—Ä–µ–Ω–æ—Å resume –≤ exist_ok –∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ resume
        if opt.name == 'cfg':
            opt.name = Path(opt.cfg).stem  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ model.yaml –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∏–º–µ–Ω–∏
        opt.save_dir = str(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))

        # –†–µ–∂–∏–º DDP
        device = select_device(opt.device, batch_size=opt.batch_size)
        # –ï—Å–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π —Ä–∞–Ω–≥ –Ω–µ —Ä–∞–≤–µ–Ω -1, —Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ–º —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        if LOCAL_RANK != -1:
            # –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ, –µ—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã —Å –º—É–ª—å—Ç–∏ - GPU DDP - –æ–±—É—á–µ–Ω–∏–µ–º YOLOv5
            msg = '–Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å –º–Ω–æ–≥–æ GPU DDP - –æ–±—É—á–µ–Ω–∏–µ–º YOLOv5'
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ–±—ã –ø–∞—Ä–∞–º–µ—Ç—Ä image_weights –Ω–µ –±—ã–ª —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
            assert not opt.image_weights, f'--image-weights {msg}'
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ–±—ã –ø–∞—Ä–∞–º–µ—Ç—Ä evolve –Ω–µ –±—ã–ª —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
            assert not opt.evolve, f'--evolve {msg}'
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ–±—ã –ø–∞—Ä–∞–º–µ—Ç—Ä batch_size –Ω–µ –±—ã–ª —Ä–∞–≤–µ–Ω -1
            assert opt.batch_size != -1, f'AutoBatch —Å --batch-size -1 {msg}, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π --batch-size'
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ–±—ã batch_size –±—ã–ª –∫—Ä–∞—Ç–Ω—ã–º WORLD_SIZE
            assert opt.batch_size % WORLD_SIZE == 0, f'--batch-size {opt.batch_size} –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫—Ä–∞—Ç–Ω—ã–º WORLD_SIZE'
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ–±—ã –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ CUDA - —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –±—ã–ª–æ –±–æ–ª—å—à–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ä–∞–Ω–≥–∞
            assert torch.cuda.device_count() > LOCAL_RANK, '–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ CUDA - —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –¥–ª—è DDP - –∫–æ–º–∞–Ω–¥—ã'
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ CUDA - —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
            torch.cuda.set_device(LOCAL_RANK)
            # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ CUDA - —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
            device = torch.device('cuda', LOCAL_RANK)
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä—É–ø–ø—ã –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
            dist.init_process_group(backend="nccl" if dist.is_nccl_available() else "gloo")

        # –û–±—É—á–µ–Ω–∏–µ
        if not opt.evolve:
            # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º
            train(opt.hyp, opt, device, callbacks)

        # –≠–≤–æ–ª—é—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
        else:
            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–º–∞—Å—à—Ç–∞–± –º—É—Ç–∞—Ü–∏–∏ 0 - 1, –Ω–∏–∂–Ω–∏–π –ø—Ä–µ–¥–µ–ª, –≤–µ—Ä—Ö–Ω–∏–π –ø—Ä–µ–¥–µ–ª)
            meta = {
                'lr0': (1, 1e-5, 1e-1),  # –Ω–∞—á–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (SGD = 1E - 2, Adam = 1E - 3)
                'lrf': (1, 0.01, 1.0),  # –∫–æ–Ω–µ—á–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è OneCycleLR (lr0 * lrf)
                'momentum': (0.3, 0.6, 0.98),  # –º–æ–º–µ–Ω—Ç—É–º SGD/–±–µ—Ç–∞1 Adam
                'weight_decay': (1, 0.0, 0.001),  # –∑–∞—Ç—É—Ö–∞–Ω–∏–µ –≤–µ—Å–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
                'warmup_epochs': (1, 0.0, 5.0),  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö —Ä–∞–∑–æ–≥—Ä–µ–≤–∞ (–º–æ–∂–Ω–æ –¥—Ä–æ–±–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
                'warmup_momentum': (1, 0.0, 0.95),  # –Ω–∞—á–∞–ª—å–Ω—ã–π –º–æ–º–µ–Ω—Ç—É–º –ø—Ä–∏ —Ä–∞–∑–æ–≥—Ä–µ–≤–µ
                'warmup_bias_lr': (1, 0.0, 0.2),  # –Ω–∞—á–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Å–º–µ—â–µ–Ω–∏—è –ø—Ä–∏ —Ä–∞–∑–æ–≥—Ä–µ–≤–µ
                'box': (1, 0.02, 0.2),  # –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø–æ—Ç–µ—Ä—å –¥–ª—è —Ä–∞–º–æ–∫
                'cls': (1, 0.2, 4.0),  # –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø–æ—Ç–µ—Ä—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                'cls_pw': (1, 0.5, 2.0),  # –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –≤–µ—Å BCELoss –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                'obj': (1, 0.2, 4.0),  # –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø–æ—Ç–µ—Ä—å –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ (–º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –ø–æ –ø–∏–∫—Å–µ–ª—è–º)
                'obj_pw': (1, 0.5, 2.0),  # –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –≤–µ—Å BCELoss –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤
                'iou_t': (0, 0.1, 0.7),  # –ø–æ—Ä–æ–≥ IoU –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
                'anchor_t': (1, 2.0, 8.0),  # –ø–æ—Ä–æ–≥ –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —è–∫–æ—Ä–Ω—ã—Ö —Ä–∞–º–æ–∫
                'anchors': (2, 2.0, 10.0),  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–∫–æ—Ä–Ω—ã—Ö —Ä–∞–º–æ–∫ –Ω–∞ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–µ—Ç–∫–µ (0 - –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å)
                'fl_gamma': (0, 0.0, 2.0),
                # –≥–∞–º–º–∞ - –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è —Ñ–æ–∫–∞–ª—å–Ω–æ–π –ø–æ—Ç–µ—Ä–∏ (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π Det –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é gamma = 1.5)
                'hsv_h': (1, 0.0, 0.1),  # —É—Å–∏–ª–µ–Ω–∏–µ HSV - –æ—Ç—Ç–µ–Ω–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–¥–æ–ª—è)
                'hsv_s': (1, 0.0, 0.9),  # —É—Å–∏–ª–µ–Ω–∏–µ HSV - –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–¥–æ–ª—è)
                'hsv_v': (1, 0.0, 0.9),  # —É—Å–∏–ª–µ–Ω–∏–µ HSV - –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–¥–æ–ª—è)
                'degrees': (1, 0.0, 45.0),  # –≤—Ä–∞—â–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (+/- –≥—Ä–∞–¥—É—Å—ã)
                'translate': (1, 0.0, 0.9),  # —Å–º–µ—â–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (+/- –¥–æ–ª—è)
                'scale': (1, 0.0, 0.9),  # –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (+/- –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç)
                'shear': (1, 0.0, 10.0),  # —Å–¥–≤–∏–≥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (+/- –≥—Ä–∞–¥—É—Å—ã)
                'perspective': (0, 0.0, 0.001),  # –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (+/- –¥–æ–ª—è), –¥–∏–∞–ø–∞–∑–æ–Ω 0 - 0.001
                'flipud': (1, 0.0, 1.0),  # –ø–µ—Ä–µ–≤–æ—Ä–æ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤–≤–µ—Ä—Ö –Ω–æ–≥–∞–º–∏ (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å)
                'fliplr': (0, 0.0, 1.0),  # –ø–µ—Ä–µ–≤–æ—Ä–æ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å)
                'mosaic': (1, 0.0, 1.0),  # —Å–º–µ—à–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å)
                'mixup': (1, 0.0, 1.0),  # —Å–º–µ—à–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å)
                'copy_paste': (1, 0.0, 1.0)}  # –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ - –≤—Å—Ç–∞–≤–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å)

            # –û—Ç–∫—Ä—ã—Ç–∏–µ —Ñ–∞–π–ª–∞ —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –∏—Ö –≤ —Å–ª–æ–≤–∞—Ä—å
            with open(opt.hyp, errors='ignore') as f:
                hyp = yaml.safe_load(f)  # –∑–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                # –ï—Å–ª–∏ –≤ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –Ω–µ—Ç –∫–ª—é—á–∞ 'anchors', —Ç–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏–µ —Ä–∞–≤–Ω—ã–º 3
                if 'anchors' not in hyp:  # —è–∫–æ—Ä–Ω—ã–µ —Ä–∞–º–∫–∏ –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ hyp.yaml
                    hyp['anchors'] = 3
            # –ï—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä noautoanchor —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —Ç–æ —É–¥–∞–ª—è–µ–º —è–∫–æ—Ä–Ω—ã–µ —Ä–∞–º–∫–∏ –∏–∑ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            if opt.noautoanchor:
                del hyp['anchors'], meta['anchors']
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            opt.noval, opt.nosave, save_dir = True, True, Path(
                opt.save_dir)  # —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è/—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π —ç–ø–æ—Ö–∏
            # ei = [isinstance(x, (int, float)) for x in hyp.values()]  # –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Ç–µ–π –¥–ª—è —Ñ–∞–π–ª–æ–≤ —Å —ç–≤–æ–ª—é—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            evolve_yaml, evolve_csv = save_dir / 'hyp_evolve.yaml', save_dir / 'evolve.csv'
            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –±–∞–∫–µ—Ç, —Ç–æ —Å–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª evolve.csv –∏–∑ –Ω–µ–≥–æ
            if opt.bucket:
                os.system(
                    f'gsutil cp gs://{opt.bucket}/evolve.csv {evolve_csv}')  # –∑–∞–≥—Ä—É–∑–∫–∞ evolve.csv, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

            # –¶–∏–∫–ª –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            for _ in range(opt.evolve):  # –ø–æ–∫–æ–ª–µ–Ω–∏—è –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏
                # –ï—Å–ª–∏ —Ñ–∞–π–ª evolve.csv —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Ç–æ –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –º—É—Ç–∏—Ä—É–µ–º –∏—Ö
                if evolve_csv.exists():  # –µ—Å–ª–∏ evolve.csv —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –º—É—Ç–∏—Ä—É–µ–º
                    # –í—ã–±–æ—Ä —Ä–æ–¥–∏—Ç–µ–ª—è(–µ–π)
                    parent = 'single'  # –º–µ—Ç–æ–¥ –≤—ã–±–æ—Ä–∞ —Ä–æ–¥–∏—Ç–µ–ª—è: 'single' –∏–ª–∏ 'weighted'
                    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ evolve.csv
                    x = np.loadtxt(evolve_csv, ndmin=2, delimiter=',', skiprows=1)
                    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è
                    n = min(5, len(x))  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è
                    # –í—ã–±–æ—Ä —Ç–æ–ø - n –º—É—Ç–∞—Ü–∏–π
                    x = x[np.argsort(-fitness(x))][:n]  # —Ç–æ–ø n –º—É—Ç–∞—Ü–∏–π
                    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤
                    w = fitness(x) - fitness(x).min() + 1E-6  # –≤–µ—Å–∞ (—Å—É–º–º–∞ > 0)
                    # –í—ã–±–æ—Ä —Ä–æ–¥–∏—Ç–µ–ª—è –æ–¥–Ω–∏–º –∏–∑ –º–µ—Ç–æ–¥–æ–≤
                    if parent == 'single' or len(x) == 1:
                        # x = x[random.randint(0, n - 1)]  # —Å–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä
                        # –í–∑–≤–µ—à–µ–Ω–Ω—ã–π –≤—ã–±–æ—Ä
                        x = x[random.choices(range(n), weights=w)[0]]
                    elif parent == 'weighted':
                        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
                        x = (x * w.reshape(n, 1)).sum(0) / w.sum()

                    # –ú—É—Ç–∞—Ü–∏—è
                    mp, s = 0.8, 0.2  # –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º—É—Ç–∞—Ü–∏–∏, —Å–∏–≥–º–∞
                    npr = np.random
                    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ–º–µ–Ω–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
                    npr.seed(int(time.time()))
                    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –º—É—Ç–∞—Ü–∏–∏
                    g = np.array([meta[k][0] for k in hyp.keys()])  # –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã 0 - 1
                    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏
                    ng = len(meta)
                    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–∞ –º—É—Ç–∞—Ü–∏–π
                    v = np.ones(ng)
                    # –ú—É—Ç–∞—Ü–∏—è –¥–æ —Ç–µ—Ö –ø–æ—Ä, –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–µ (–ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
                    while all(v == 1):
                        v = (g * (npr.random(ng) < mp) * npr.randn(ng) * npr.random() * s + 1).clip(0.3, 3.0)
                    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º—É—Ç–∞—Ü–∏–∏ –∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
                    for i, k in enumerate(hyp.keys()):
                        hyp[k] = float(x[i + 7] * v[i])  # –º—É—Ç–∞—Ü–∏—è

            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            for k, v in meta.items():
                # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –Ω–µ –Ω–∏–∂–µ –Ω–∏–∂–Ω–µ–≥–æ –ø—Ä–µ–¥–µ–ª–∞
                hyp[k] = max(hyp[k], v[1])  # –Ω–∏–∂–Ω–∏–π –ø—Ä–µ–¥–µ–ª
                # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –Ω–µ –≤—ã—à–µ –≤–µ—Ä—Ö–Ω–µ–≥–æ –ø—Ä–µ–¥–µ–ª–∞
                hyp[k] = min(hyp[k], v[2])  # –≤–µ—Ä—Ö–Ω–∏–π –ø—Ä–µ–¥–µ–ª
                # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –¥–æ 5 –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π
                hyp[k] = round(hyp[k], 5)  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–Ω–∞—á–∞—â–∏—Ö —Ü–∏—Ñ—Ä

            # –û–±—É—á–µ–Ω–∏–µ —Å –º—É—Ç–∏—Ä–æ–≤–∞–≤—à–∏–º–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            results = train(hyp.copy(), opt, device, callbacks)
            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –æ–±—Ä–∞—Ç–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤
            callbacks = Callbacks()
            # –ó–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º—É—Ç–∞—Ü–∏–∏ –≤ —Ñ–∞–π–ª
            print_mutation(KEYS, results, hyp.copy(), save_dir, opt.bucket)

            # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ —ç–≤–æ–ª—é—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            plot_evolve(evolve_csv)
            # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —ç–≤–æ–ª—é—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            LOGGER.info(f'–≠–≤–æ–ª—é—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ø–æ—Å–ª–µ {opt.evolve} –ø–æ–∫–æ–ª–µ–Ω–∏–π\n'
                        f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {colorstr('bold', save_dir)}\n"
                        f'–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è: $ python train.py --hyp {evolve_yaml}')

            def run(**kwargs):
                # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: import train; train.run(data='coco128.yaml', imgsz=320, weights='yolov5m.pt')
                # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ —Å —Ñ–ª–∞–≥–æ–º –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –≤—ã–∑–æ–≤–∞
                opt = parse_opt(True)
                # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
                for k, v in kwargs.items():
                    setattr(opt, k, v)
                # –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
                main(opt)
                return opt

            if __name__ == "__main__":
                # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
                opt = parse_opt()
                # –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
                main(opt)