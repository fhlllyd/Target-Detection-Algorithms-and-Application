# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
"""
Validate a trained YOLOv5 segment model on a segment dataset

Usage:
    $ bash data/scripts/get_coco.sh --val --segments  # download COCO-segments val split (1G, 5000 images)
    $ python segment/val.py --weights yolov5s-seg.pt --data coco.yaml --img 640  # validate COCO-segments

Usage - formats:
    $ python segment/val.py --weights yolov5s-seg.pt                 # PyTorch
                                      yolov5s-seg.torchscript        # TorchScript
                                      yolov5s-seg.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                                      yolov5s-seg_openvino_label     # OpenVINO
                                      yolov5s-seg.engine             # TensorRT
                                      yolov5s-seg.mlmodel            # CoreML (macOS-only)
                                      yolov5s-seg_saved_model        # TensorFlow SavedModel
                                      yolov5s-seg.pb                 # TensorFlow GraphDef
                                      yolov5s-seg.tflite             # TensorFlow Lite
                                      yolov5s-seg_edgetpu.tflite     # TensorFlow Edge TPU
                                      yolov5s-seg_paddle_model       # PaddlePaddle
"""

import argparse
import json
import os
import sys
from multiprocessing.pool import ThreadPool
from pathlib import Path

import numpy as np
import torch
from tqdm import tqdm

# –ü–æ–ª—É—á–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ —Ç–µ–∫—É—â–µ–º—É —Ñ–∞–π–ª—É
FILE = Path(__file__).resolve()
# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é YOLOv5 (—Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –≤—Ç–æ—Ä–æ–≥–æ —É—Ä–æ–≤–Ω—è)
ROOT = FILE.parents[1]  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –∫–æ—Ä–Ω—è YOLOv5
# –ï—Å–ª–∏ –ø—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –Ω–µ –≤ —Å–ø–∏—Å–∫–µ –ø—É—Ç–µ–π Python, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # –î–æ–±–∞–≤–ª—è–µ–º ROOT –≤ PATH
# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª PyTorch –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–µ–π—Ä–æ–Ω–Ω—ã–º–∏ —Å–µ—Ç—è–º–∏
import torch.nn.functional as F

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —É—Ç–∏–ª–∏—Ç –∏ –º–æ–¥–µ–ª–µ–π YOLOv5
from models.common import DetectMultiBackend
from models.yolo import SegmentationModel
from utils.callbacks import Callbacks
from utils.general import (LOGGER, NUM_THREADS, TQDM_BAR_FORMAT, Profile, check_dataset, check_img_size,
                           check_requirements, check_yaml, coco80_to_coco91_class, colorstr, increment_path,
                           non_max_suppression, print_args, scale_boxes, xywh2xyxy, xyxy2xywh)
from utils.metrics import ConfusionMatrix, box_iou
from utils.plots import output_to_target, plot_val_study
from utils.segment.dataloaders import create_dataloader
from utils.segment.general import mask_iou, process_mask, process_mask_upsample, scale_image
from utils.segment.metrics import Metrics, ap_per_class_box_and_mask
from utils.segment.plots import plot_images_and_masks
from utils.torch_utils import de_parallel, select_device, smart_inference_mode


def save_one_txt(predn, save_conf, shape, file):
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–¥–∏–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –±–æ–∫—Å–æ–≤
    gn = torch.tensor(shape)[[1, 0, 1, 0]]  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ whwh
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–º—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—é
    for *xyxy, conf, cls in predn.tolist():
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –±–æ–∫—Å–æ–≤ –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ xyxy –≤ xywh –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ xywh
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª
        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # –§–æ—Ä–º–∞—Ç –º–µ—Ç–∫–∏
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É
        with open(file, 'a') as f:
            f.write(('%g ' * len(line)).rstrip() % line + '\n')


def save_one_json(predn, jdict, path, class_map, pred_masks):
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–¥–∏–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
    # {"image_id": 42, "category_id": 18, "bbox": [258.15, 41.29, 348.26, 243.78], "score": 0.236}
    from pycocotools.mask import encode

    def single_encode(x):
        # –ö–æ–¥–∏—Ä—É–µ–º –º–∞—Å–∫—É –≤ —Ñ–æ—Ä–º–∞—Ç RLE
        rle = encode(np.asarray(x[:, :, None], order="F", dtype="uint8"))[0]
        rle["counts"] = rle["counts"].decode("utf-8")
        return rle

    # –ü–æ–ª—É—á–∞–µ–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    image_id = int(path.stem) if path.stem.isnumeric() else path.stem
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –±–æ–∫—Å–æ–≤ –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ xyxy –≤ xywh
    box = xyxy2xywh(predn[:, :4])  # xywh
    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ü–µ–Ω—Ç—Ä –±–æ–∫—Å–∞ –≤ –≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π —É–≥–æ–ª
    box[:, :2] -= box[:, 2:] / 2  # –¶–µ–Ω—Ç—Ä xy –≤ –≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π —É–≥–æ–ª
    # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º –º–∞—Å–∫–∏ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
    pred_masks = np.transpose(pred_masks, (2, 0, 1))
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—É–ª –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–∞—Å–æ–∫
    with ThreadPool(NUM_THREADS) as pool:
        rles = pool.map(single_encode, pred_masks)
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–º—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—é –∏ –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ JSON
    for i, (p, b) in enumerate(zip(predn.tolist(), box.tolist())):
        jdict.append({
            'image_id': image_id,
            'category_id': class_map[int(p[5])],
            'bbox': [round(x, 3) for x in b],
            'score': round(p[4], 5),
            'segmentation': rles[i]
        })


def process_batch(detections, labels, iouv, pred_masks=None, gt_masks=None, overlap=False, masks=False):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        detections (array[N, 6]), x1, y1, x2, y2, conf, class
        labels (array[M, 5]), class, x1, y1, x2, y2
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        correct (array[N, 10]), –¥–ª—è 10 —É—Ä–æ–≤–Ω–µ–π IoU
    """
    if masks:
        if overlap:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ç–æ–∫
            nl = len(labels)
            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏ –∫–∞–∂–¥–æ–π –º–∞—Å–∫–∏
            index = torch.arange(nl, device=gt_masks.device).view(nl, 1, 1) + 1
            # –ü–æ–≤—Ç–æ—Ä—è–µ–º –º–∞—Å–∫–∏ –∏—Å—Ç–∏–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç–∫–∏
            gt_masks = gt_masks.repeat(nl, 1, 1)  # shape(1,640,640) -> (n,640,640)
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –º–∞—Å–∫–∏ –≤ 1 —Ç–æ–ª—å–∫–æ —Ç–∞–º, –≥–¥–µ –∏–Ω–¥–µ–∫—Å —Å–æ–≤–ø–∞–¥–∞–µ—Ç
            gt_masks = torch.where(gt_masks == index, 1.0, 0.0)
        # –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä—ã –º–∞—Å–∫–∏ –∏—Å—Ç–∏–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –º–∞—Å–∫ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç, –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ–º
        if gt_masks.shape[1:] != pred_masks.shape[1:]:
            gt_masks = F.interpolate(gt_masks[None], pred_masks.shape[1:], mode="bilinear", align_corners=False)[0]
            gt_masks = gt_masks.gt_(0.5)
        # –í—ã—á–∏—Å–ª—è–µ–º IoU –º–µ–∂–¥—É –º–∞—Å–∫–∞–º–∏ –∏—Å—Ç–∏–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –º–∞—Å–∫
        iou = mask_iou(gt_masks.view(gt_masks.shape[0], -1), pred_masks.view(pred_masks.shape[0], -1))
    else:  # –†–∞–±–æ—Ç–∞–µ–º —Å –±–æ–∫—Å–∞–º–∏
        # –í—ã—á–∏—Å–ª—è–µ–º IoU –º–µ–∂–¥—É –±–æ–∫—Å–∞–º–∏ –∏—Å—Ç–∏–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –±–æ–∫—Å–æ–≤
        iou = box_iou(labels[:, 1:], detections[:, :4])

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    correct = np.zeros((detections.shape[0], iouv.shape[0])).astype(bool)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–ª–∞—Å—Å–æ–≤ –º–µ–∂–¥—É –º–µ—Ç–∫–∞–º–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
    correct_class = labels[:, 0:1] == detections[:, 5]
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–º—É —É—Ä–æ–≤–Ω—é IoU
    for i in range(len(iouv)):
        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã, –≥–¥–µ IoU –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ –∏ –∫–ª–∞—Å—Å—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç
        x = torch.where((iou >= iouv[i]) & correct_class)  # IoU > –ø–æ—Ä–æ–≥ –∏ –∫–ª–∞—Å—Å—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç
        if x[0].shape[0]:
            # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π [–º–µ—Ç–∫–∞, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ, IoU]
            matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1).cpu().numpy()
            if x[0].shape[0] > 1:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ —É–±—ã–≤–∞–Ω–∏—é IoU
                matches = matches[matches[:, 2].argsort()[::-1]]
                # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∏–Ω–¥–µ–∫—Å—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                matches = matches[np.unique(matches[:, 1], return_index=True)[1]]
                # –°–Ω–æ–≤–∞ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é IoU
                # matches = matches[matches[:, 2].argsort()[::-1]]
                # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∏–Ω–¥–µ–∫—Å—É –º–µ—Ç–∫–∏
                matches = matches[np.unique(matches[:, 0], return_index=True)[1]]
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –º–∞—Ç—Ä–∏—Ü–µ
            correct[matches[:, 1].astype(int), i] = True
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ –≤–∏–¥–µ —Ç–µ–Ω–∑–æ—Ä–∞
    return torch.tensor(correct, dtype=torch.bool, device=iouv.device)

@smart_inference_mode()
def run(
        data,
        weights=None,  # –ü—É—Ç—å(–∏) –∫ —Ñ–∞–π–ª—É(–∞–º) –º–æ–¥–µ–ª–∏ model.pt
        batch_size=32,  # –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞
        imgsz=640,  # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)
        conf_thres=0.001,  # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        iou_thres=0.6,  # –ü–æ—Ä–æ–≥ IoU –¥–ª—è NMS
        max_det=300,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        task='val',  # –ó–∞–¥–∞—á–∞: train, val, test, speed –∏–ª–∏ study
        device='',  # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ CUDA, –Ω–∞–ø—Ä–∏–º–µ—Ä 0 –∏–ª–∏ 0,1,2,3 –∏–ª–∏ cpu
        workers=8,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–Ω–∞ RANK –≤ —Ä–µ–∂–∏–º–µ DDP)
        single_cls=False,  # –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –∫–∞–∫ –æ–¥–Ω–æ–∫–ª–∞—Å—Å–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
        augment=False,  # –£—Å–∏–ª–µ–Ω–Ω–æ–µ –≤—ã–≤–æ–¥
        verbose=False,  # –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥
        save_txt=False,  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª *.txt
        save_hybrid=False,  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –≥–∏–±—Ä–∏–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–º–µ—Ç–∫–∞ + –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ) –≤ —Ñ–∞–π–ª *.txt
        save_conf=False,  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –º–µ—Ç–∫–∞—Ö --save-txt
        save_json=False,  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ COCO - JSON
        project=ROOT / 'runs/val-seg',  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ project/name
        name='exp',  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ project/name
        exist_ok=False,  # –ï—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π project/name –æ–∫, –Ω–µ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å –Ω–æ–º–µ—Ä
        half=True,  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–ª–Ω–æ—Ä–∞–∑–º–µ—Ä–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å FP16 –¥–ª—è –≤—ã–≤–æ–¥–∞
        dnn=False,  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OpenCV DNN –¥–ª—è –≤—ã–≤–æ–¥–∞ ONNX
        model=None,
        dataloader=None,
        save_dir=Path(''),
        plots=True,
        overlap=False,
        mask_downsample_ratio=1,
        compute_loss=None,
        callbacks=Callbacks(),
):
    if save_json:
        # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ JSON, —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –µ—Å—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
        check_requirements(['pycocotools'])
        # –í—ã–±–∏—Ä–∞–µ–º –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–∞—Å–∫–∏
        process = process_mask_upsample
    else:
        # –í –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ –≤—ã–±–∏—Ä–∞–µ–º –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–∞—Å–∫–∏
        process = process_mask

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è/–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    training = model is not None
    if training:  # –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ train.py
        # –ü–æ–ª—É—á–∞–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –∏ —Ñ–ª–∞–≥–∏ –æ —Ç–∏–ø–µ –º–æ–¥–µ–ª–∏
        device, pt, jit, engine = next(model.parameters()).device, True, False, False
        # –ü–æ–ª–Ω–æ—Ä–∞–∑–º–µ—Ä–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ CUDA
        half &= device.type != 'cpu'
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
        model.half() if half else model.float()
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Å–æ–∫
        nm = de_parallel(model).model[-1].nm
    else:  # –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é
        # –í—ã–±–∏—Ä–∞–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        device = select_device(device, batch_size=batch_size)

        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –Ω–æ–º–µ—Ä –∑–∞–ø—É—Å–∫–∞, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
        save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        stride, pt, jit, engine = model.stride, model.pt, model.jit, model.engine
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        imgsz = check_img_size(imgsz, s=stride)
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–¥–¥–µ—Ä–∂–∫–µ FP16
        half = model.fp16
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Å–æ–∫
        nm = de_parallel(model).model.model[-1].nm if isinstance(model, SegmentationModel) else 32
        if engine:
            batch_size = model.batch_size
        else:
            device = model.device
            if not (pt or jit):
                batch_size = 1  # –ú–æ–¥–µ–ª–∏ –∏–∑ export.py –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–º–µ—é—Ç —Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ 1
                LOGGER.info(f'–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º --batch-size 1 –¥–ª—è –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ (1,3,{imgsz},{imgsz}) –¥–ª—è –Ω–µ-PyTorch –º–æ–¥–µ–ª–µ–π')

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        data = check_dataset(data)

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    model.eval()
    cuda = device.type != 'cpu'
    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö COCO
    is_coco = isinstance(data.get('val'), str) and data['val'].endswith(f'coco{os.sep}val2017.txt')
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
    nc = 1 if single_cls else int(data['nc'])
    # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä IoU –¥–ª—è mAP@0.5:0.95
    iouv = torch.linspace(0.5, 0.95, 10, device=device)
    niou = iouv.numel()

    # –ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö
    if not training:
        if pt and not single_cls:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –¥–∞–Ω–Ω—ã–º
            ncm = model.model.nc
            assert ncm == nc, f'{weights} ({ncm} –∫–ª–∞—Å—Å–æ–≤) –æ–±—É—á–µ–Ω–∞ –Ω–∞ –¥—Ä—É–≥–∏—Ö --data, —á–µ–º —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –ø–µ—Ä–µ–¥–∞–ª–∏ ({nc} –∫–ª–∞—Å—Å–æ–≤). –ü–µ—Ä–µ–¥–∞–π—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é --weights –∏ --data, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –æ–±—É—á–µ–Ω—ã –≤–º–µ—Å—Ç–µ.'
        # –†–∞–∑–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏
        model.warmup(imgsz=(1 if pt else batch_size, 3, imgsz, imgsz))
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –≤ –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö
        pad, rect = (0.0, False) if task == 'speed' else (0.5, pt)
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–¥–∞—á—É
        task = task if task in ('train', 'val', 'test') else 'val'
        # –°–æ–∑–¥–∞–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö
        dataloader = create_dataloader(data[task],
                                       imgsz,
                                       batch_size,
                                       stride,
                                       single_cls,
                                       pad=pad,
                                       rect=rect,
                                       workers=workers,
                                       prefix=colorstr(f'{task}: '),
                                       overlap_mask=overlap,
                                       mask_downsample_ratio=mask_downsample_ratio)[0]

    seen = 0
    # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫
    confusion_matrix = ConfusionMatrix(nc=nc)
    # –ü–æ–ª—É—á–∞–µ–º –∏–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤
    names = model.names if hasattr(model, 'names') else model.module.names
    if isinstance(names, (list, tuple)):  # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç
        names = dict(enumerate(names))
    # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è COCO
    class_map = coco80_to_coco91_class() if is_coco else list(range(1000))
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    s = ('%22s' + '%11s' * 10) % ('Class', 'Images', 'Instances', 'Box(P', "R", "mAP50", "mAP50-95)", "Mask(P", "R",
                                  "mAP50", "mAP50-95)")
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
    dt = Profile(), Profile(), Profile()
    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
    metrics = Metrics()
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–Ω–∑–æ—Ä –ø–æ—Ç–µ—Ä—å
    loss = torch.zeros(4, device=device)
    # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
    jdict, stats = [], []
    # callbacks.run('on_val_start')
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å - –±–∞—Ä
    pbar = tqdm(dataloader, desc=s, bar_format=TQDM_BAR_FORMAT)
    for batch_i, (im, targets, paths, shapes, masks) in enumerate(pbar):
        # callbacks.run('on_val_batch_start')
        with dt[0]:
            if cuda:
                # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ CUDA
                im = im.to(device, non_blocking=True)
                # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–µ—Ç–∫–∏ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ CUDA
                targets = targets.to(device)
                # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–∞—Å–∫–∏ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ CUDA
                masks = masks.to(device)
            masks = masks.float()
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –Ω—É–∂–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å
            im = im.half() if half else im.float()
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            im /= 255
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –ø–∞–∫–µ—Ç–∞, –∫–∞–Ω–∞–ª–æ–≤, –≤—ã—Å–æ—Ç—ã –∏ —à–∏—Ä–∏–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            nb, _, height, width = im.shape

        # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å (–≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π)
        with dt[1]:
            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –ø–æ—Ç–µ—Ä—å, —Ç–æ –ø–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –ø—Ä–æ—Ç–æ - –º–∞—Å–∫–∏ –∏ –≤—ã—Ö–æ–¥ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –º–æ–¥–µ–ª–∏
            # –í –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ –ø–æ–ª—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –ø—Ä–æ—Ç–æ - –º–∞—Å–∫–∏
            preds, protos, train_out = model(im) if compute_loss else (*model(im, augment=augment)[:2], None)

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å
        if compute_loss:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—É–º–º–∞—Ä–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏ –Ω–∞ –ø–æ—Ç–µ—Ä–∏ —Ç–µ–∫—É—â–µ–≥–æ –ø–∞–∫–µ—Ç–∞ (–±–æ–∫—Å, –æ–±—ä–µ–∫—Ç, –∫–ª–∞—Å—Å)
            loss += compute_loss((train_out, protos), targets, masks)[1]

            # –ù–µ–ª–æ–∫–∞–ª—å–Ω–æ–µ –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ –º–∞–∫—Å–∏–º—É–º–æ–≤ (NMS)
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –º–µ—Ç–æ–∫ –∏–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –ø–∏–∫—Å–µ–ª–∏
        targets[:, 2:] *= torch.tensor((width, height, width, height), device=device)
        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–µ—Ç–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–∫–µ—Ç–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≥–∏–±—Ä–∏–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        lb = [targets[targets[:, 0] == i, 1:] for i in range(nb)] if save_hybrid else []
        with dt[2]:
            # –ü—Ä–∏–º–µ–Ω—è–µ–º NMS –∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º
            preds = non_max_suppression(preds,
                                        conf_thres,
                                        iou_thres,
                                        labels=lb,
                                        multi_label=True,
                                        agnostic=single_cls,
                                        max_det=max_det,
                                        nm=nm)

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        plot_masks = []  # –ú–∞—Å–∫–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        for si, (pred, proto) in enumerate(zip(preds, protos)):
            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∫–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            labels = targets[targets[:, 0] == si, 1:]
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ç–æ–∫ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            nl, npr = labels.shape[0], pred.shape[0]
            # –ü—É—Ç—å –∫ —Ç–µ–∫—É—â–µ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏ –µ–≥–æ –∏—Å—Ö–æ–¥–Ω–∞—è —Ñ–æ—Ä–º–∞
            path, shape = Path(paths[si]), shapes[si][0]
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–∞—Ç—Ä–∏—Ü—ã –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –º–∞—Å–∫ –∏ –±–æ–∫—Å–æ–≤
            correct_masks = torch.zeros(npr, niou, dtype=torch.bool, device=device)
            correct_bboxes = torch.zeros(npr, niou, dtype=torch.bool, device=device)
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            seen += 1

            if npr == 0:
                if nl:
                    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –ø—É—Å—Ç—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π, –µ—Å–ª–∏ –µ—Å—Ç—å –º–µ—Ç–∫–∏
                    stats.append((correct_masks, correct_bboxes, *torch.zeros((2, 0), device=device), labels[:, 0]))
                    if plots:
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–∫–µ—Ç –¥–ª—è –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
                        confusion_matrix.process_batch(detections=None, labels=labels[:, 0])
                continue

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Å–æ–∫
            midx = [si] if overlap else targets[:, 0] == si
            # –ü–æ–ª—É—á–∞–µ–º –º–∞—Å–∫–∏ –∏—Å—Ç–∏–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            gt_masks = masks[midx]
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–∞—Å–∫–∏
            pred_masks = process(proto, pred[:, 6:], pred[:, :4], shape=im[si].shape[1:])

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            if single_cls:
                # –ï—Å–ª–∏ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º –∫–∞–∫ –æ–¥–Ω–æ–∫–ª–∞—Å—Å–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–ª–∞—Å—Å –≤—Å–µ—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Ä–∞–≤–Ω—ã–º 0
                pred[:, 5] = 0
            predn = pred.clone()
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –±–æ–∫—Å–æ–≤ –¥–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            scale_boxes(im[si].shape[1:], predn[:, :4], shape, shapes[si][1])

            # –û—Ü–µ–Ω–∫–∞
            if nl:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –º–µ—Ç–æ–∫ –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ xywh –≤ xyxy
                tbox = xywh2xyxy(labels[:, 1:5])
                # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –º–µ—Ç–æ–∫ –¥–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                scale_boxes(im[si].shape[1:], tbox, shape, shapes[si][1])
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–∞ –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –±–æ–∫—Å–æ–≤ –≤ –æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä–µ
                labelsn = torch.cat((labels[:, 0:1], tbox), 1)
                # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –±–æ–∫—Å–æ–≤
                correct_bboxes = process_batch(predn, labelsn, iouv)
                # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –º–∞—Å–æ–∫
                correct_masks = process_batch(predn, labelsn, iouv, pred_masks, gt_masks, overlap=overlap, masks=True)
                if plots:
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞–∫–µ—Ç –¥–ª—è –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
                    confusion_matrix.process_batch(predn, labelsn)
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            stats.append((correct_masks, correct_bboxes, pred[:, 4], pred[:, 5], labels[:, 0]))

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–∞—Å–∫–∏ –≤ —Ç–∏–ø uint8
            pred_masks = torch.as_tensor(pred_masks, dtype=torch.uint8)
            if plots and batch_i < 3:
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ø - 15 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –º–∞—Å–æ–∫ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                plot_masks.append(pred_masks[:15].cpu())

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            if save_txt:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
                save_one_txt(predn, save_conf, shape, file=save_dir / 'labels' / f'{path.stem}.txt')
            if save_json:
                # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–∞—Å–∫–∏ –¥–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                pred_masks = scale_image(im[si].shape[1:],
                                         pred_masks.permute(1, 2, 0).contiguous().cpu().numpy(), shape, shapes[si][1])
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ COCO - JSON
                save_one_json(predn, jdict, path, class_map, pred_masks)
                # callbacks.run('on_val_image_end', pred, predn, path, names, im[si])

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        if plots and batch_i < 3:
            if len(plot_masks):
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –º–∞—Å–∫–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ –æ–¥–∏–Ω —Ç–µ–Ω–∑–æ—Ä
                plot_masks = torch.cat(plot_masks, dim=0)
            # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –º–µ—Ç–∫–∞–º–∏
            plot_images_and_masks(im, targets, masks, paths, save_dir / f'val_batch{batch_i}_labels.jpg', names)
            # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
            plot_images_and_masks(im, output_to_target(preds, max_det=15), plot_masks, paths,
                                  save_dir / f'val_batch{batch_i}_pred.jpg', names)
            # callbacks.run('on_val_batch_end')

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ numpy –º–∞—Å—Å–∏–≤—ã
        stats = [torch.cat(x, 0).cpu().numpy() for x in zip(*stats)]
        if len(stats) and stats[0].any():
            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –±–æ–∫—Å–æ–≤ –∏ –º–∞—Å–æ–∫
            results = ap_per_class_box_and_mask(*stats, plot=plots, save_dir=save_dir, names=names)
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            metrics.update(results)
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–µ–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        nt = np.bincount(stats[4].astype(int), minlength=nc)

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        # –§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        pf = '%22s' + '%11i' * 2 + '%11.3g' * 8
        # –í—ã–≤–æ–¥–∏–º —Å—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
        LOGGER.info(pf % ("all", seen, nt.sum(), *metrics.mean_results()))
        if nt.sum() == 0:
            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ, –µ—Å–ª–∏ –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –º–µ—Ç–æ–∫
            LOGGER.warning(f'WARNING ‚ö†Ô∏è no labels found in {task} set, can not compute metrics without labels')

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        if (verbose or (nc < 50 and not training)) and nc > 1 and len(stats):
            for i, c in enumerate(metrics.ap_class_index):
                # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
                LOGGER.info(pf % (names[c], seen, nt[c], *metrics.class_result(i)))

        # –í—ã–≤–æ–¥ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞ –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        t = tuple(x.t / seen * 1E3 for x in dt)
        if not training:
            shape = (batch_size, 3, imgsz, imgsz)
            # –í—ã–≤–æ–¥–∏–º –≤—Ä–µ–º—è –ø—Ä–µ–¥ - –æ–±—Ä–∞–±–æ—Ç–∫–∏, –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∏ NMS –Ω–∞ –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            LOGGER.info(f'Speed: %.1fms pre - process, %.1fms inference, %.1fms NMS per image at shape {shape}' % t)

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤)
    if plots:
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
        confusion_matrix.plot(save_dir=save_dir, names=list(names.values()))
    # callbacks.run('on_val_end')

    # –ü–æ–ª—É—á–∞–µ–º —Å—Ä–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–µ—Ç—Ä–∏–∫ –¥–ª—è –±–æ–∫—Å–æ–≤ –∏ –º–∞—Å–æ–∫
    mp_bbox, mr_bbox, map50_bbox, map_bbox, mp_mask, mr_mask, map50_mask, map_mask = metrics.mean_results()

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON
    if save_json and len(jdict):
        # –ü–æ–ª—É—á–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ —Å –≤–µ—Å–∞–º–∏ –º–æ–¥–µ–ª–∏
        w = Path(weights[0] if isinstance(weights, list) else weights).stem if weights is not None else ''
        # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏ COCO
        anno_json = str(Path(data.get('path', '../coco')) / 'annotations/instances_val2017.json')
        # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
        pred_json = str(save_dir / f"{w}_predictions.json")
        LOGGER.info(f'\nEvaluating pycocotools mAP... saving {pred_json}...')
        with open(pred_json, 'w') as f:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –≤ —Ñ–∞–π–ª JSON
            json.dump(jdict, f)

        try:  # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb
            from pycocotools.coco import COCO
            from pycocotools.cocoeval import COCOeval

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏
            anno = COCO(anno_json)
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
            pred = anno.loadRes(pred_json)
            results = []
            for eval in COCOeval(anno, pred, 'bbox'), COCOeval(anno, pred, 'segm'):
                if is_coco:
                    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ—Ü–µ–Ω–∫–∏
                    eval.params.imgIds = [int(Path(x).stem) for x in dataloader.dataset.im_files]
                    # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—Ü–µ–Ω–∫—É
                eval.evaluate()
                # –ê–∫–∫—É–º—É–ª–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                eval.accumulate()
                # –°–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                eval.summarize()
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–µ –¥–≤–∞ –∑–Ω–∞—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                results.extend(eval.stats[:2])
                # –û–±–Ω–æ–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –¥–ª—è –±–æ–∫—Å–æ–≤ –∏ –º–∞—Å–æ–∫
            map_bbox, map50_bbox, map_mask, map50_mask = results
        except Exception as e:
            LOGGER.info(f'pycocotools unable to run: {e}')

    # –í–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–æ–¥–µ–ª—å –≤ —Ñ–æ—Ä–º–∞—Ç —Å –ø–æ–ª–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é (–¥–ª—è –æ–±—É—á–µ–Ω–∏—è)
    model.float()
    if not training:
        s = f"\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}" if save_txt else ''
        LOGGER.info(f"Results saved to {colorstr('bold', save_dir)}{s}")
    # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    final_metric = mp_bbox, mr_bbox, map50_bbox, map_bbox, mp_mask, mr_mask, map50_mask, map_mask
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏, –∫–∞—Ä—Ç—ã –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∏ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    return (*final_metric, *(loss.cpu() / len(dataloader)).tolist()), metrics.get_maps(nc), t

    def parse_opt():
        # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        parser = argparse.ArgumentParser()
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö
        parser.add_argument('--data', type=str, default=ROOT / 'data/coco128-seg.yaml', help='–ø—É—Ç—å –∫ dataset.yaml')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –ø—É—Ç–∏(–µ–π) –∫ —Ñ–∞–π–ª—É(–∞–º) –º–æ–¥–µ–ª–∏
        parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'yolov5s-seg.pt',
                            help='–ø—É—Ç—å(–∏) –∫ –º–æ–¥–µ–ª–∏(—è–º)')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ –ø–∞–∫–µ—Ç–∞
        parser.add_argument('--batch-size', type=int, default=32, help='—Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞
        parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640,
                            help='—Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –ø–æ—Ä–æ–≥–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        parser.add_argument('--conf-thres', type=float, default=0.001, help='–ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –ø–æ—Ä–æ–≥–∞ IoU –¥–ª—è NMS
        parser.add_argument('--iou-thres', type=float, default=0.6, help='–ø–æ—Ä–æ–≥ IoU –¥–ª—è NMS')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        parser.add_argument('--max-det', type=int, default=300,
                            help='–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
        parser.add_argument('--task', default='val', help='train, val, test, speed –∏–ª–∏ study')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ CUDA
        parser.add_argument('--device', default='', help='—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ CUDA, –Ω–∞–ø—Ä–∏–º–µ—Ä 0 –∏–ª–∏ 0,1,2,3 –∏–ª–∏ cpu')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        parser.add_argument('--workers', type=int, default=8,
                            help='–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–Ω–∞ RANK –≤ —Ä–µ–∂–∏–º–µ DDP)')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–∫ –æ–¥–Ω–æ–∫–ª–∞—Å—Å–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
        parser.add_argument('--single-cls', action='store_true', help='—Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –∫–∞–∫ –æ–¥–Ω–æ–∫–ª–∞—Å—Å–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è —É—Å–∏–ª–µ–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
        parser.add_argument('--augment', action='store_true', help='—É—Å–∏–ª–µ–Ω–Ω–æ–µ –≤—ã–≤–æ–¥')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –º–µ—Ç—Ä–∏–∫ –ø–æ –∫–ª–∞—Å—Å–∞–º
        parser.add_argument('--verbose', action='store_true', help='–æ—Ç—á—ë—Ç –æ mAP –ø–æ –∫–ª–∞—Å—Å–∞–º')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        parser.add_argument('--save-txt', action='store_true', help='—Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ *.txt')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥–∏–±—Ä–∏–¥–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–º–µ—Ç–∫–∞ + –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ) –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        parser.add_argument('--save-hybrid', action='store_true',
                            help='—Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≥–∏–±—Ä–∏–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–º–µ—Ç–∫–∞ + –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ) –≤ *.txt')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–µ–π –≤ –º–µ—Ç–∫–∞—Ö –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        parser.add_argument('--save-conf', action='store_true', help='—Å–æ—Ö—Ä–∞–Ω—è—Ç—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –º–µ—Ç–∫–∞—Ö --save-txt')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ COCO - JSON
        parser.add_argument('--save-json', action='store_true', help='—Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ COCO - JSON')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –ø—É—Ç–∏ –∫ –ø—Ä–æ–µ–∫—Ç—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        parser.add_argument('--project', default=ROOT / 'runs/val-seg', help='—Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ project/name')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –∏–º–µ–Ω–∏ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        parser.add_argument('--name', default='exp', help='—Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ project/name')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞/–∏–º–µ–Ω–∏ –±–µ–∑ —É–≤–µ–ª–∏—á–µ–Ω–∏—è –Ω–æ–º–µ—Ä–∞
        parser.add_argument('--exist-ok', action='store_true',
                            help='—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π project/name –æ–∫, –Ω–µ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å –Ω–æ–º–µ—Ä')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–æ–ª–Ω–æ—Ä–∞–∑–º–µ—Ä–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ FP16 –¥–ª—è –≤—ã–≤–æ–¥–∞
        parser.add_argument('--half', action='store_true', help='–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–ª–Ω–æ—Ä–∞–∑–º–µ—Ä–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å FP16 –¥–ª—è –≤—ã–≤–æ–¥–∞')
        # –ê—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è OpenCV DNN –¥–ª—è –≤—ã–≤–æ–¥–∞ ONNX
        parser.add_argument('--dnn', action='store_true', help='–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OpenCV DNN –¥–ª—è –≤—ã–≤–æ–¥–∞ ONNX')
        # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        opt = parser.parse_args()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ (YAML)
        opt.data = check_yaml(opt.data)
        # opt.save_json |= opt.data.endswith('coco.yaml')
        # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≥–∏–±—Ä–∏–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —Ç–æ —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        opt.save_txt |= opt.save_hybrid
        # –í—ã–≤–æ–¥–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        print_args(vars(opt))
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—ä–µ–∫—Ç —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏
        return opt

def main(opt):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –ø–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º, –∏—Å–∫–ª—é—á–∞—è tensorboard –∏ thop
    check_requirements(requirements=ROOT /'requirements.txt', exclude=('tensorboard', 'thop'))

    if opt.task in ('train', 'val', 'test'):  # –û–±—ã—á–Ω—ã–π –∑–∞–ø—É—Å–∫
        if opt.conf_thres > 0.001:  # https://github.com/ultralytics/yolov5/issues/1466
            # –í—ã–≤–æ–¥ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–º –ø–æ—Ä–æ–≥–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            LOGGER.warning(f'WARNING ‚ö†Ô∏è confidence threshold {opt.conf_thres} > 0.001 produces invalid results')
        if opt.save_hybrid:
            # –í—ã–≤–æ–¥ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≥–∏–±—Ä–∏–¥–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            LOGGER.warning('WARNING ‚ö†Ô∏è --save-hybrid returns high mAP from hybrid labels, not from predictions alone')
        # –ó–∞–ø—É—Å–∫ —Ñ—É–Ω–∫—Ü–∏–∏ run —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ –∏–∑ –æ–±—ä–µ–∫—Ç–∞ opt
        run(**vars(opt))

    else:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º weights –≤ —Å–ø–∏—Å–æ–∫, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å–ø–∏—Å–æ–∫ —É–∂–µ
        weights = opt.weights if isinstance(opt.weights, list) else [opt.weights]
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å FP16 –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ CUDA –∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        opt.half = torch.cuda.is_available() and opt.device != 'cpu'
        if opt.task =='speed':  # –±–µ–Ω—á–º–∞—Ä–∫–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
            # python val.py --task speed --data coco.yaml --batch 1 --weights yolov5n.pt yolov5s.pt...
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ—Ä–æ–≥–æ–≤ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∏ IoU, –∞ —Ç–∞–∫–∂–µ –æ—Ç–∫–ª—é—á–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON
            opt.conf_thres, opt.iou_thres, opt.save_json = 0.25, 0.45, False
            for opt.weights in weights:
                # –ó–∞–ø—É—Å–∫ —Ñ—É–Ω–∫—Ü–∏–∏ run —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ –∏–∑ –æ–±—ä–µ–∫—Ç–∞ opt, –±–µ–∑ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
                run(**vars(opt), plots=False)

        elif opt.task =='study':  # –±–µ–Ω—á–º–∞—Ä–∫–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø—Ä–æ—Ç–∏–≤ mAP
            # python val.py --task study --data coco.yaml --iou 0.7 --weights yolov5n.pt yolov5s.pt...
            for opt.weights in weights:
                # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                f = f'study_{Path(opt.data).stem}_{Path(opt.weights).stem}.txt'
                x, y = list(range(256, 1536 + 128, 128)), []  # –æ—Å—å x (—Ä–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π), –æ—Å—å y
                for opt.imgsz in x:  # —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    LOGGER.info(f'\nRunning {f} --imgsz {opt.imgsz}...')
                    # –ó–∞–ø—É—Å–∫ —Ñ—É–Ω–∫—Ü–∏–∏ run —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ –∏–∑ –æ–±—ä–µ–∫—Ç–∞ opt, –±–µ–∑ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
                    r, _, t = run(**vars(opt), plots=False)
                    y.append(r + t)  # —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –≤—Ä–µ–º–µ–Ω–∞
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
                np.savetxt(f, y, fmt='%10.4g')
            # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤ —Å —Ñ–∞–π–ª–∞–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            os.system('zip -r study.zip study_*.txt')
            # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            plot_val_study(x=x)


if __name__ == "__main__":
    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    opt = parse_opt()
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
    main(opt)