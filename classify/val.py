# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
"""
Validate a trained YOLOv5 classification model on a classification dataset

Usage:
    $ bash data/scripts/get_imagenet.sh --val  # download ImageNet val split (6.3G, 50000 images)
    $ python classify/val.py --weights yolov5m-cls.pt --data ../datasets/imagenet --img 224  # validate ImageNet

Usage - formats:
    $ python classify/val.py --weights yolov5s-cls.pt                 # PyTorch
                                       yolov5s-cls.torchscript        # TorchScript
                                       yolov5s-cls.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                                       yolov5s-cls_openvino_model     # OpenVINO
                                       yolov5s-cls.engine             # TensorRT
                                       yolov5s-cls.mlmodel            # CoreML (macOS-only)
                                       yolov5s-cls_saved_model        # TensorFlow SavedModel
                                       yolov5s-cls.pb                 # TensorFlow GraphDef
                                       yolov5s-cls.tflite             # TensorFlow Lite
                                       yolov5s-cls_edgetpu.tflite     # TensorFlow Edge TPU
                                       yolov5s-cls_paddle_model       # PaddlePaddle
"""

import argparse
import os
import sys
from pathlib import Path

import torch
from tqdm import tqdm

# –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ç–µ–∫—É—â–µ–º—É —Å–∫—Ä–∏–ø—Ç—É
FILE = Path(__file__).resolve()
# –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è YOLOv5 (2 —É—Ä–æ–≤–Ω—è –≤—ã—à–µ)
ROOT = FILE.parents[1]
# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—É—Ç—å
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))
# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—É—Ç–∏ –≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))

# –ò–º–ø–æ—Ä—Ç –∫–ª–∞—Å—Å–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π
from models.common import DetectMultiBackend
# –ò–º–ø–æ—Ä—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
from utils.dataloaders import create_classification_dataloader
# –ò–º–ø–æ—Ä—Ç –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö —É—Ç–∏–ª–∏—Ç
from utils.general import (LOGGER, TQDM_BAR_FORMAT, Profile, check_img_size, check_requirements, colorstr,
                           increment_path, print_args)
# –ò–º–ø–æ—Ä—Ç —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏ PyTorch
from utils.torch_utils import select_device, smart_inference_mode


@smart_inference_mode()  # –ê–∫—Ç–∏–≤–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ –≤—ã–≤–æ–¥–∞
def run(
    # –ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é MNIST)
    data=ROOT / '../datasets/mnist',
    # –ü—É—Ç—å –∫ –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏
    weights=ROOT / 'yolov5s-cls.pt',
    # –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
    batch_size=128,
    # –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–ø–∏–∫—Å–µ–ª–∏)
    imgsz=224,
    # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (CUDA/CPU)
    device='',
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–∞
    workers=8,
    # –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥
    verbose=False,
    # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    project=ROOT / 'runs/val-cls',
    # –ò–º—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    name='exp',
    # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    exist_ok=False,
    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É–ø—Ä–µ—Ü–∏–∑–∏–æ–Ω–Ω–æ–π –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∏
    half=False,
    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ OpenCV DNN –¥–ª—è ONNX
    dnn=False,
    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    model=None,
    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞–Ω–Ω—ã–π –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä
    dataloader=None,
    # –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
    criterion=None,
    # –û–±—ä–µ–∫—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
    pbar=None,
):
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–æ–±—É—á–µ–Ω–∏–µ –∏–ª–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å)
    training = model is not None
    if training:  # –í—ã–∑–æ–≤ –∏–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏
        device, pt, jit, engine = next(model.parameters()).device, True, False, False
        # –ü–æ–ª—É–ø—Ä–µ—Ü–∏–∑–∏—è —Ç–æ–ª—å–∫–æ –Ω–∞ CUDA
        half &= device.type != 'cpu'
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ –ø–æ–ª—É–ø—Ä–µ—Ü–∏–∑–∏–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º
        model.half() if half else model.float()
    else:  # –í—ã–∑–æ–≤ –∫–∞–∫ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç
        # –í—ã–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ —Å —É—á–µ—Ç–æ–º —Ä–∞–∑–º–µ—Ä–∞ –ø–∞–∫–µ—Ç–∞
        device = select_device(device, batch_size=batch_size)

        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)
        save_dir.mkdir(parents=True, exist_ok=True)

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
        model = DetectMultiBackend(weights, device=device, dnn=dnn, fp16=half)
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏
        stride, pt, jit, engine = model.stride, model.pt, model.jit, model.engine
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        imgsz = check_img_size(imgsz, s=stride)
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–¥–¥–µ—Ä–∂–∫–µ –ø–æ–ª—É–ø—Ä–µ—Ü–∏–∑–∏–∏
        half = model.fp16
        if engine:  # –î–ª—è TensorRT –º–æ–¥–µ–ª–∏
            batch_size = model.batch_size
        else:  # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
            device = model.device
            if not (pt or jit):  # –î–ª—è –Ω–µ-PyTorch –º–æ–¥–µ–ª–µ–π
                batch_size = 1
                LOGGER.info(f'–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ 1 –¥–ª—è –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (1,3,{imgsz},{imgsz})')

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Ç–∏ –∫ –¥–∞—Ç–∞—Å–µ—Ç—É
        data = Path(data)
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
        test_dir = data / 'test' if (data / 'test').exists() else data / 'val'
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–∞
        dataloader = create_classification_dataloader(
            path=test_dir,
            imgsz=imgsz,
            batch_size=batch_size,
            augment=False,
            rank=-1,
            workers=workers
        )

    # –†–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏
    model.eval()
    # –°–ø–∏—Å–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    pred, targets, loss = [], [], 0
    # –°—Ä–µ–¥—Å—Ç–≤–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏
    dt = (Profile(), Profile(), Profile())
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π
    n = len(dataloader)
    # –¢–∏–ø –æ–ø–µ—Ä–∞—Ü–∏–∏ (–≤–∞–ª–∏–¥–∞—Ü–∏—è/—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
    action = 'validating' if dataloader.dataset.root.stem == 'val' else 'testing'
    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
    desc = f"{pbar.desc[:-36]}{action:>36}" if pbar else f"{action}"
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
    bar = tqdm(dataloader, desc=desc, total=n, disable=training, bar_format=TQDM_BAR_FORMAT, position=0)

    # –ê–∫—Ç–∏–≤–∞—Ü–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –∞–º–ø–ª–∏—Ç—É–¥—ã
    with torch.cuda.amp.autocast(enabled=device.type != 'cpu'):
        for images, labels in bar:
            with dt[0]:  # –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
                images, labels = images.to(device, non_blocking=True), labels.to(device)

            with dt[1]:  # –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
                y = model(images)

            with dt[2]:  # –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏
                pred.append(y.argsort(1, descending=True)[:, :5])
                targets.append(labels)
                if criterion:
                    loss += criterion(y, labels)

    # –°—Ä–µ–¥–Ω—è—è –ø–æ—Ç–µ—Ä—è
    loss /= n
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    pred, targets = torch.cat(pred), torch.cat(targets)
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏
    correct = (targets[:, None] == pred).float()
    acc = torch.stack((correct[:, 0], correct.max(1).values), dim=1)
    top1, top5 = acc.mean(0).tolist()

    if pbar:  # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
        pbar.desc = f"{pbar.desc[:-36]}{loss:>12.3g}{top1:>12.3g}{top5:>12.3g}"
    if verbose:  # –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥
        LOGGER.info(f"{'Class':>24}{'Images':>12}{'top1_acc':>12}{'top5_acc':>12}")
        LOGGER.info(f"{'all':>24}{targets.shape[0]:>12}{top1:>12.3g}{top5:>12.3g}")
        for i, c in model.names.items():
            aci = acc[targets == i]
            top1i, top5i = aci.mean(0).tolist()
            LOGGER.info(f"{c:>24}{aci.shape[0]:>12}{top1i:>12.3g}{top5i:>12.3g}")

        # –í—ã–≤–æ–¥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        t = tuple(x.t / len(dataloader.dataset.samples) * 1E3 for x in dt)
        shape = (1, 3, imgsz, imgsz)
        LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms post-process per image at shape {shape}' % t)
        LOGGER.info(f"Results saved to {colorstr('bold', save_dir)}")

    return top1, top5, loss


def parse_opt():
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    parser = argparse.ArgumentParser()

    # –ü–∞—Ä–∞–º–µ—Ç—Ä –ø—É—Ç–∏ –∫ –¥–∞—Ç–∞—Å–µ—Ç—É
    parser.add_argument('--data', type=str, default=ROOT / '../datasets/mnist',
                        help='–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä –ø—É—Ç–∏ –∫ –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ)
    parser.add_argument('--weights', nargs='+', type=str,
                        default=ROOT / 'yolov5s-cls.pt',
                        help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª–∞–º —Å –≤–µ—Å–∞–º–∏ –º–æ–¥–µ–ª–∏ (model.pt)')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä —Ä–∞–∑–º–µ—Ä–∞ –ø–∞–∫–µ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö
    parser.add_argument('--batch-size', type=int, default=128,
                        help='–†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ (batch size)')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
    parser.add_argument('--imgsz', '--img', '--img-size', type=int,
                        default=224,
                        help='–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (–ø–∏–∫—Å–µ–ª–∏)')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
    parser.add_argument('--device', default='',
                        help='–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ CUDA (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0 –∏–ª–∏ 0,1,2,3) –∏–ª–∏ cpu')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ä–∞–±–æ—á–∏—Ö –ø–æ—Ç–æ–∫–æ–≤ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–∞
    parser.add_argument('--workers', type=int, default=8,
                        help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–∞ (–Ω–∞ –∫–∞–∂–¥—ã–π RANK –≤ —Ä–µ–∂–∏–º–µ DDP)')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
    parser.add_argument('--verbose', nargs='?', const=True, default=True,
                        help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    parser.add_argument('--project', default=ROOT / 'runs/val-cls',
                        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (project/name)')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä –∏–º–µ–Ω–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    parser.add_argument('--name', default='exp',
                        help='–ò–º—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ (–¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ –ø—É—Ç–∏ project/name)')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    parser.add_argument('--exist-ok', action='store_true',
                        help='–†–∞–∑—Ä–µ—à–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –±–µ–∑ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–º–µ–Ω–∏')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–æ–ª—É–ø—Ä–µ—Ü–∏–∑–∏–æ–Ω–Ω–æ–π –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∏
    parser.add_argument('--half', action='store_true',
                        help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–ª—É–ø—Ä–µ—Ü–∏–∑–∏–æ–Ω–Ω—É—é –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫—É FP16')

    # –ü–∞—Ä–∞–º–µ—Ç—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è OpenCV DNN –¥–ª—è ONNX
    parser.add_argument('--dnn', action='store_true',
                        help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OpenCV DNN –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å –º–æ–¥–µ–ª—è–º–∏ ONNX')

    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∏ –≤—ã–≤–æ–¥ –∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    opt = parser.parse_args()
    print_args(vars(opt))
    return opt


def main(opt):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–µ–±—É–µ–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    check_requirements(exclude=('tensorboard', 'thop'))
    # –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥–∏–∫–∏ —Å –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    run(**vars(opt))


if __name__ == "__main__":
    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    opt = parse_opt()
    # –í—ã–∑–æ–≤ –≥–ª–∞–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
    main(opt)