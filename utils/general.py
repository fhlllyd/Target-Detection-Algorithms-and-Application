# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
"""
–û–±—â–∏–µ —É—Ç–∏–ª–∏—Ç—ã
"""

import contextlib
import glob
import inspect
import logging
import logging.config
import math
import os
import platform
import random
import re
import signal
import sys
import time
import urllib
from copy import deepcopy
from datetime import datetime
from itertools import repeat
from multiprocessing.pool import ThreadPool
from pathlib import Path
from subprocess import check_output
from tarfile import is_tarfile
from typing import Optional
from zipfile import ZipFile, is_zipfile

import cv2
import IPython
import numpy as np
import pandas as pd
import pkg_resources as pkg
import torch
import torchvision
import yaml

from utils import TryExcept, emojis
from utils.downloads import gsutil_getsize
from utils.metrics import box_iou, fitness

FILE = Path(__file__).resolve()
ROOT = FILE.parents[1]  # –ö–æ—Ä–Ω–µ–≤–æ–π –∫–∞—Ç–∞–ª–æ–≥ YOLOv5
RANK = int(os.getenv('RANK', -1))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
NUM_THREADS = min(8, max(1, os.cpu_count() - 1))  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ multiprocessing –¥–ª—è YOLOv5
DATASETS_DIR = Path(os.getenv('YOLOv5_DATASETS_DIR', ROOT.parent / 'datasets'))  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥ –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö
AUTOINSTALL = str(os.getenv('YOLOv5_AUTOINSTALL', True)).lower() == 'true'  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏
VERBOSE = str(os.getenv('YOLOv5_VERBOSE', True)).lower() == 'true'  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º verbose
TQDM_BAR_FORMAT = '{l_bar}{bar:10}| {n_fmt}/{total_fmt} {elapsed}'  # –§–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫–∏ tqdm
FONT = 'Arial.ttf'  # https://ultralytics.com/assets/Arial.ttf

torch.set_printoptions(linewidth=320, precision=5, profile='long')
np.set_printoptions(linewidth=320, formatter={'float_kind': '{:11.5g}'.format})  # –§–æ—Ä–º–∞—Ç –∫–æ—Ä–æ—Ç–∫–æ–≥–æ g, —Ç–æ—á–Ω–æ—Å—Ç—å=5
pd.options.display.max_columns = 10
cv2.setNumThreads(0)  # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å OpenCV (–Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å PyTorch DataLoader)
os.environ['NUMEXPR_MAX_THREADS'] = str(NUM_THREADS)  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ NumExpr
os.environ['OMP_NUM_THREADS'] = '1' if platform.system() == 'darwin' else str(NUM_THREADS)  # –ü–æ—Ç–æ–∫–∏ OpenMP (PyTorch –∏ SciPy)


def is_ascii(s=''):
    # –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ—Å—Ç–æ–∏—Ç –ª–∏ —Å—Ç—Ä–æ–∫–∞ —Ç–æ–ª—å–∫–æ –∏–∑ —Å–∏–º–≤–æ–ª–æ–≤ ASCII
    s = str(s)  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞, –∫–æ—Ä—Ç–µ–∂–∞, None –∏ —Ç.–¥. –≤ —Å—Ç—Ä–æ–∫—É
    return len(s.encode().decode('ascii', 'ignore')) == len(s)


def is_chinese(s='‰∫∫Â∑•Êô∫ËÉΩ'):
    # –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ—Å—Ç–æ–∏—Ç –ª–∏ —Å—Ç—Ä–æ–∫–∞ –∏–∑ –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
    return bool(re.search('[\u4e00-\u9fff]', str(s)))


def is_colab():
    # –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ä–µ–¥–∞ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–º Google Colab
    return 'google.colab' in sys.modules


def is_notebook():
    # –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ä–µ–¥–∞ Jupyter Notebook
    ipython_type = str(type(IPython.get_ipython()))
    return 'colab' in ipython_type or 'zmqshell' in ipython_type


def is_kaggle():
    # –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ä–µ–¥–∞ Kaggle Notebook
    return os.environ.get('PWD') == '/kaggle/working' and os.environ.get('KAGGLE_URL_BASE') == 'https://www.kaggle.com'


def is_docker() -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∑–∞–ø—É—â–µ–Ω –ª–∏ –ø—Ä–æ—Ü–µ—Å—Å –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ Docker."""
    if Path("/.dockerenv").exists():
        return True
    try:  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è Docker –≤ –≥—Ä—É–ø–ø–∞—Ö –∫–æ–Ω—Ç—Ä–æ–ª—è
        with open("/proc/self/cgroup") as file:
            return any("docker" in line for line in file)
    except OSError:
        return False


def is_writeable(dir, test=False):
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –∫–∞—Ç–∞–ª–æ–≥ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∞ –∑–∞–ø–∏—Å–∏, –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ—Ç–∫—Ä—ã—Ç–∏—è —Ñ–∞–π–ª–∞ —Å –ø—Ä–∞–≤–∞–º–∏ –∑–∞–ø–∏—Å–∏, –µ—Å–ª–∏ test=True
    if not test:
        return os.access(dir, os.W_OK)  # –í–æ–∑–º–æ–∂–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã –Ω–∞ Windows
    file = Path(dir) / 'tmp.txt'
    try:
        with open(file, 'w'):  # –û—Ç–∫—Ä—ã–≤–∞–µ—Ç —Ñ–∞–π–ª —Å –ø—Ä–∞–≤–∞–º–∏ –∑–∞–ø–∏—Å–∏
            pass
        file.unlink()  # –£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª
        return True
    except OSError:
        return False


LOGGING_NAME = "yolov5"


def set_logging(name=LOGGING_NAME, verbose=True):
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∂—É—Ä–Ω–∞–ª–∞ —Å –∑–∞–¥–∞–Ω–Ω—ã–º –∏–º–µ–Ω–µ–º
    rank = int(os.getenv('RANK', -1))  # —Ä–∞–Ω–≥ –≤ –º–∏—Ä–µ –¥–ª—è –º–Ω–æ–≥–æ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω—ã—Ö —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫
    level = logging.INFO if verbose and rank in {-1, 0} else logging.ERROR
    logging.config.dictConfig({
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            name: {
                "format": "%(message)s"}},
        "handlers": {
            name: {
                "class": "logging.StreamHandler",
                "formatter": name,
                "level": level,}},
        "loggers": {
            name: {
                "level": level,
                "handlers": [name],
                "propagate": False,}}})


set_logging(LOGGING_NAME)  # –∑–∞–ø—É—Å–∫ –ø–µ—Ä–µ–¥ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º LOGGER
LOGGER = logging.getLogger(LOGGING_NAME)  # –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ
if platform.system() == 'Windows':
    for fn in LOGGER.info, LOGGER.warning:
        setattr(LOGGER, fn.__name__, lambda x: fn(emojis(x)))  # –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∂—É—Ä–Ω–∞–ª —Å —ç–º–æ–¥–∑–∏


def user_config_dir(dir='Ultralytics', env_var='YOLOV5_CONFIG_DIR'):
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –∫–∞—Ç–∞–ª–æ–≥—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏. –ü—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é —Å—Ä–µ–¥—ã, –µ—Å–ª–∏ –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –°–æ–∑–¥–∞–µ—Ç –∫–∞—Ç–∞–ª–æ–≥, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ.
    env = os.getenv(env_var)
    if env:
        path = Path(env)  # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é —Å—Ä–µ–¥—ã
    else:
        cfg = {'Windows': 'AppData/Roaming', 'Linux': '.config', 'Darwin': 'Library/Application Support'}  # –∫–∞—Ç–∞–ª–æ–≥–∏ –¥–ª—è 3 –û–°
        path = Path.home() / cfg.get(platform.system(), '')  # –∫–∞—Ç–∞–ª–æ–≥ OS
        path = (path if is_writeable(path) else Path('/tmp')) / dir  # –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è GCP –∏ AWS lambda, —Ç–æ–ª—å–∫–æ /tmp –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –∑–∞–ø–∏—Å–∏
    path.mkdir(exist_ok=True)  # —Å–æ–∑–¥–∞—Ç—å –∫–∞—Ç–∞–ª–æ–≥, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
    return path


CONFIG_DIR = user_config_dir()  # –∫–∞—Ç–∞–ª–æ–≥ –Ω–∞—Å—Ç—Ä–æ–µ–∫ Ultralytics


class Profile(contextlib.ContextDecorator):
    # –ö–ª–∞—Å—Å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è YOLOv5. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: @Profile() –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –∏–ª–∏ 'with Profile():' –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä
    def __init__(self, t=0.0):
        self.t = t
        self.cuda = torch.cuda.is_available()

    def __enter__(self):
        self.start = self.time()
        return self

    def __exit__(self, type, value, traceback):
        self.dt = self.time() - self.start  # delta-time
        self.t += self.dt  # –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ dt

    def time(self):
        if self.cuda:
            torch.cuda.synchronize()
        return time.time()


class Timeout(contextlib.ContextDecorator):
    # –ö–ª–∞—Å—Å —Ç–∞–π–º–∞—É—Ç–∞ YOLOv5. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: @Timeout(seconds) –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –∏–ª–∏ 'with Timeout(seconds):' –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä
    def __init__(self, seconds, *, timeout_msg='', suppress_timeout_errors=True):
        self.seconds = int(seconds)
        self.timeout_message = timeout_msg
        self.suppress = bool(suppress_timeout_errors)

    def _timeout_handler(self, signum, frame):
        raise TimeoutError(self.timeout_message)

    def __enter__(self):
        if platform.system() != 'Windows':  # –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –Ω–∞ Windows
            signal.signal(signal.SIGALRM, self._timeout_handler)  # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ SIGALRM
            signal.alarm(self.seconds)  # –∑–∞–ø—É—Å–∫ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –æ—Ç—Å—á–µ—Ç–∞ –¥–ª—è SIGALRM

    def __exit__(self, exc_type, exc_val, exc_tb):
        if platform.system() != 'Windows':
            signal.alarm(0)  # –û—Ç–º–µ–Ω–∞ SIGALRM, –µ—Å–ª–∏ –æ–Ω–∞ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∞
            if self.suppress and exc_type is TimeoutError:  # –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ —Ç–∞–π–º–∞—É—Ç–∞
                return True


class WorkingDirectory(contextlib.ContextDecorator):
    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: @WorkingDirectory(dir) –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –∏–ª–∏ 'with WorkingDirectory(dir):' –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä
    def __init__(self, new_dir):
        self.dir = new_dir  # –Ω–æ–≤—ã–π –∫–∞—Ç–∞–ª–æ–≥
        self.cwd = Path.cwd().resolve()  # —Ç–µ–∫—É—â–∏–π –∫–∞—Ç–∞–ª–æ–≥

    def __enter__(self):
        os.chdir(self.dir)

    def __exit__(self, exc_type, exc_val, exc_tb):
        os.chdir(self.cwd)


def methods(instance):
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –∫–ª–∞—Å—Å–∞/—ç–∫–∑–µ–º–ø–ª—è—Ä–∞
    return [f for f in dir(instance) if callable(getattr(instance, f)) and not f.startswith("__")]


def print_args(args: Optional[dict] = None, show_file=True, show_func=False):
    # –í—ã–≤–æ–¥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å args)
    x = inspect.currentframe().f_back  # –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ñ—Ä–µ–π–º
    file, _, func, _, _ = inspect.getframeinfo(x)
    if args is None:  # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        args, _, _, frm = inspect.getargvalues(x)
        args = {k: v for k, v in frm.items() if k in args}
    try:
        file = Path(file).resolve().relative_to(ROOT).with_suffix('')
    except ValueError:
        file = Path(file).stem
    s = (f'{file}: ' if show_file else '') + (f'{func}: ' if show_func else '')
    LOGGER.info(colorstr(s) + ', '.join(f'{k}={v}' for k, v in args.items()))


def init_seeds(seed=0, deterministic=False):
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # –±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è –º–Ω–æ–≥–æ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω—ã—Ö GPU
    if deterministic and check_version(torch.__version__, '1.12.0'):  # https://github.com/ultralytics/yolov5/pull/8213
        torch.use_deterministic_algorithms(True)
        torch.backends.cudnn.deterministic = True
        os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
        os.environ['PYTHONHASHSEED'] = str(seed)


def intersect_dicts(da, db, exclude=()):
    # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–µ–π —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏ –∏ —Ñ–æ—Ä–º–∞–º–∏, –∏—Å–∫–ª—é—á–∞—è 'exclude' –∫–ª—é—á–∏, –∏—Å–ø–æ–ª—å–∑—É—è –∑–Ω–∞—á–µ–Ω–∏—è da
    return {k: v for k, v in da.items() if k in db and all(x not in k for x in exclude) and v.shape == db[k].shape}


def get_default_args(func):
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è func()
    signature = inspect.signature(func)
    return {k: v.default for k, v in signature.parameters.items() if v.default is not inspect.Parameter.empty}


def get_latest_run(search_dir='.'):
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É 'last.pt' –≤ /runs (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è --resume)
    last_list = glob.glob(f'{search_dir}/**/last*.pt', recursive=True)
    return max(last_list, key=os.path.getctime) if last_list else ''


def file_age(path=__file__):
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞
    dt = (datetime.now() - datetime.fromtimestamp(Path(path).stat().st_mtime))  # delta
    return dt.days  # + dt.seconds / 86400  # –¥—Ä–æ–±–Ω—ã–µ –¥–Ω–∏


def file_date(path=__file__):
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä, '2021-3-26'
    t = datetime.fromtimestamp(Path(path).stat().st_mtime)
    return f'{t.year}-{t.month}-{t.day}'


def file_size(path):
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞/–∫–∞—Ç–∞–ª–æ–≥–∞ (–ú–ë)
    mb = 1 << 20  # –±–∞–π—Ç—ã –≤ –ú–∏–ë (1024 ** 2)
    path = Path(path)
    if path.is_file():
        return path.stat().st_size / mb
    elif path.is_dir():
        return sum(f.stat().st_size for f in path.glob('**/*') if f.is_file()) / mb
    else:
        return 0.0


def check_online():
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É
    import socket

    def run_once():
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–¥–∏–Ω —Ä–∞–∑
        try:
            socket.create_connection(("1.1.1.1", 443), 5)  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Ö–æ—Å—Ç–∞
            return True
        except OSError:
            return False

    return run_once() or run_once()  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–≤–∞–∂–¥—ã –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –∫ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –ø—Ä–æ–±–ª–µ–º–∞–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è


def git_describe(path=ROOT):  # path –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–∞—Ç–∞–ª–æ–≥–æ–º
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ git, –Ω–∞–ø—Ä–∏–º–µ—Ä, v5.0-5-g3e25f1e https://git-scm.com/docs/git-describe
    try:
        assert (Path(path) / '.git').is_dir()
        return check_output(f'git -C {path} describe --tags --long --always', shell=True).decode()[:-1]
    except Exception:
        return ''


@TryExcept()
@WorkingDirectory(ROOT)
def check_git_status(repo='ultralytics/yolov5', branch='master'):
    # –°–æ—Å—Ç–æ—è–Ω–∏–µ YOLOv5, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 'git pull', –µ—Å–ª–∏ –∫–æ–¥ —É—Å—Ç–∞—Ä–µ–ª
    url = f'https://github.com/{repo}'
    msg = f', –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–º. {url}'
    s = colorstr('github: ')  # —Å—Ç—Ä–æ–∫–∞
    assert Path('.git').is_dir(), s + '–ø—Ä–æ–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ (–Ω–µ —è–≤–ª—è–µ—Ç—Å—è git-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º)' + msg
    assert check_online(), s + '–ø—Ä–æ–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ (–æ—Ñ—Ñ–ª–∞–π–Ω)' + msg

    splits = re.split(pattern=r'\s', string=check_output('git remote -v', shell=True).decode())
    matches = [repo in s for s in splits]
    if any(matches):
        remote = splits[matches.index(True) - 1]
    else:
        remote = 'ultralytics'
        check_output(f'git remote add {remote} {url}', shell=True)
    check_output(f'git fetch {remote}', shell=True, timeout=5)  # git fetch
    local_branch = check_output('git rev-parse --abbrev-ref HEAD', shell=True).decode().strip()  # —Ç–µ–∫—É—â–∞—è –≤–µ—Ç–∫–∞
    n = int(check_output(f'git rev-list {local_branch}..{remote}/{branch} --count', shell=True))  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–∏—Ç–æ–≤ –ø–æ–∑–∞–¥–∏
    if n > 0:
        pull = 'git pull' if remote == 'origin' else f'git pull {remote} {branch}'
        s += f"‚ö†Ô∏è YOLOv5 —É—Å—Ç–∞—Ä–µ–ª–æ –Ω–∞ {n} –∫–æ–º–º–∏—Ç{'–æ–≤' if n > 1 else ''}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `{pull}` –∏–ª–∏ `git clone {url}` –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è."
    else:
        s += f'–æ–±–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤–µ—Ä—Å–∏–∏ —Å {url} ‚úÖ'
    LOGGER.info(s)


@WorkingDirectory(ROOT)
def check_git_info(path='.'):
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ YOLOv5 git, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç {remote, branch, commit}
    check_requirements('gitpython')
    import git
    try:
        repo = git.Repo(path)
        remote = repo.remotes.origin.url.replace('.git', '')  # –Ω–∞–ø—Ä–∏–º–µ—Ä, 'https://github.com/ultralytics/yolov5'
        commit = repo.head.commit.hexsha  # –Ω–∞–ø—Ä–∏–º–µ—Ä, '3134699c73af83aac2a481435550b968d5792c0d'
        try:
            branch = repo.active_branch.name  # –Ω–∞–ø—Ä–∏–º–µ—Ä, 'main'
        except TypeError:  # –Ω–µ –Ω–∞ –∫–∞–∫–æ–π-–ª–∏–±–æ –≤–µ—Ç–∫–µ
            branch = None  # –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–æ—Å—Ç–æ—è–Ω–∏–µ 'detached HEAD'
        return {'remote': remote, 'branch': branch, 'commit': commit}
    except git.exc.InvalidGitRepositoryError:  # –ø—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è git-–∫–∞—Ç–∞–ª–æ–≥–æ–º
        return {'remote': None, 'branch': None, 'commit': None}


def check_python(minimum='3.7.0'):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ Python –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏
    check_version(platform.python_version(), minimum, name='Python ', hard=True)


def check_version(current='0.0.0', minimum='0.0.0', name='version ', pinned=False, hard=False, verbose=False):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π
    current, minimum = (pkg.parse_version(x) for x in (current, minimum))
    result = (current == minimum) if pinned else (current >= minimum)  # bool
    s = f'WARNING ‚ö†Ô∏è {name}{minimum} —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è YOLOv5, –Ω–æ —Ç–µ–∫—É—â–∞—è –≤–µ—Ä—Å–∏—è {name}{current}'  # —Å—Ç—Ä–æ–∫–∞
    if hard:
        assert result, emojis(s)  # —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
    if verbose and not result:
        LOGGER.warning(s)
    return result


@TryExcept()
def check_requirements(requirements=ROOT / 'requirements.txt', exclude=(), install=True, cmds=''):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º YOLOv5 (–ø–µ—Ä–µ–¥–∞—Ç—å *.txt —Ñ–∞–π–ª –∏–ª–∏ —Å–ø–∏—Å–æ–∫ –ø–∞–∫–µ—Ç–æ–≤ –∏–ª–∏ —Å—Ç—Ä–æ–∫—É —Å –æ–¥–Ω–∏–º –ø–∞–∫–µ—Ç–æ–º)
    prefix = colorstr('red', 'bold', '—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:')
    check_python()  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ Python
    if isinstance(requirements, Path):  # requirements.txt —Ñ–∞–π–ª
        file = requirements.resolve()
        assert file.exists(), f"{prefix} {file} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞."
        with file.open() as f:
            requirements = [f'{x.name}{x.specifier}' for x in pkg.parse_requirements(f) if x.name not in exclude]
    elif isinstance(requirements, str):
        requirements = [requirements]

    s = ''
    n = 0
    for r in requirements:
        try:
            pkg.require(r)
        except (pkg.VersionConflict, pkg.DistributionNotFound):  # –∏—Å–∫–ª—é—á–µ–Ω–∏–µ, –µ—Å–ª–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã
            s += f'"{r}" '
            n += 1

    if s and install and AUTOINSTALL:  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π —Å—Ä–µ–¥—ã
        LOGGER.info(f"{prefix} –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è YOLOv5 {s}–Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è...")
        try:
            # assert check_online(), "–ü—Ä–æ–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (–æ—Ñ—Ñ–ª–∞–π–Ω)"
            LOGGER.info(check_output(f'pip install {s} {cmds}', shell=True).decode())
            source = file if 'file' in locals() else requirements
            s = f"{prefix} {n} –ø–∞–∫–µ—Ç{'–∞' if n % 10 == 1 and n % 100 != 11 else '–æ–≤' if n % 10 in [2, 3, 4] and n % 100 not in [12, 13, 14] else ''} –æ–±–Ω–æ–≤–ª–µ–Ω{'–æ' if n == 1 else '—ã'} –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å {source}\n" \
                f"{prefix} ‚ö†Ô∏è {colorstr('bold', '–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å—Ä–µ–¥—É –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–ª–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É –¥–ª—è –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Å–∏–ª—É')}\n"
            LOGGER.info(s)
        except Exception as e:
            LOGGER.warning(f'{prefix} ‚ùå {e}')


def check_img_size(imgsz, s=32, floor=0):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫—Ä–∞—Ç–µ–Ω —à–∞–≥—É s –≤ –∫–∞–∂–¥–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
    if isinstance(imgsz, int):  # integer i.e. img_size=640
        new_size = max(make_divisible(imgsz, int(s)), floor)
    else:  # list i.e. img_size=[640, 480]
        imgsz = list(imgsz)  # convert to list if tuple
        new_size = [max(make_divisible(x, int(s)), floor) for x in imgsz]
    if new_size != imgsz:
        LOGGER.warning(f'WARNING ‚ö†Ô∏è --img-size {imgsz} –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫—Ä–∞—Ç–µ–Ω –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–º—É —à–∞–≥—É {s}, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–æ {new_size}')
    return new_size


def check_imshow(warn=False):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ —Å—Ä–µ–¥–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    try:
        assert not is_notebook()
        assert not is_docker()
        cv2.imshow('test', np.zeros((1, 1, 3)))
        cv2.waitKey(1)
        cv2.destroyAllWindows()
        cv2.waitKey(1)
        return True
    except Exception as e:
        if warn:
            LOGGER.warning(f'WARNING ‚ö†Ô∏è –°—Ä–µ–¥–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç cv2.imshow() –∏–ª–∏ PIL Image.show()\n{e}')
        return False


def check_suffix(file='yolov5s.pt', suffix=('.pt',), msg=''):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–∞
    if file and suffix:
        if isinstance(suffix, str):
            suffix = [suffix]
        for f in file if isinstance(file, (list, tuple)) else [file]:
            s = Path(f).suffix.lower()  # —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
            if len(s):
                assert s in suffix, f"{msg}{f} –¥–æ–ø—É—Å—Ç–∏–º–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ {suffix}"


def check_yaml(file, suffix=('.yaml', '.yml')):
    # –ü–æ–∏—Å–∫/—Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ YAML (–µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ) –∏ –≤–æ–∑–≤—Ä–∞—Ç –ø—É—Ç–∏, –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    return check_file(file, suffix)


def check_file(file, suffix=''):
    # –ü–æ–∏—Å–∫/—Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ) –∏ –≤–æ–∑–≤—Ä–∞—Ç –ø—É—Ç–∏
    check_suffix(file, suffix)  # –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    file = str(file)  # –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫—É
    if os.path.isfile(file) or not file:  # —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        return file
    elif file.startswith(('http:/', 'https:/')):  # —Å–∫–∞—á–∞—Ç—å
        url = file  # –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: Pathlib –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç :// –≤ :/
        file = Path(urllib.parse.unquote(file).split('?')[0]).name  # '%2F' –≤ '/', —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ https://url.com/file.txt?auth
        if os.path.isfile(file):
            LOGGER.info(f"{file} –Ω–∞–π–¥–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ")  # —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        else:
            LOGGER.info(f'–°–∫–∞—á–∏–≤–∞–Ω–∏–µ {url} –≤ {file}...')
            torch.hub.download_url_to_file(url, file)
            assert Path(file).exists() and Path(file).stat().st_size > 0, f'–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {url}'  # –ø—Ä–æ–≤–µ—Ä–∫–∞
        return file
    elif file.startswith('clearml://'):  # ClearML Dataset ID
        assert 'clearml' in sys.modules, "ClearML –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø–æ—ç—Ç–æ–º—É –Ω–µ–ª—å–∑—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö ClearML. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–ø–æ–ª–Ω–∏—Ç—å 'pip install clearml'."
        return file
    else:  # –ø–æ–∏—Å–∫
        files = []
        for d in 'data', 'models', 'utils':  # –∫–∞—Ç–∞–ª–æ–≥–∏ –ø–æ–∏—Å–∫–∞
            files.extend(glob.glob(str(ROOT / d / '**' / file), recursive=True))  # –ø–æ–∏—Å–∫ —Ñ–∞–π–ª–∞
        assert len(files), f'–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file}'  # —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ, —á—Ç–æ —Ñ–∞–π–ª –Ω–∞–π–¥–µ–Ω
        assert len(files) == 1, f"–ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö '{file}', —É—Ç–æ—á–Ω–∏—Ç–µ –ø—É—Ç—å: {files}"  # —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
        return files[0]  # –≤–æ–∑–≤—Ä–∞—Ç —Ñ–∞–π–ª–∞


def check_font(font=FONT, progress=False):
    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —à—Ä–∏—Ñ—Ç–∞ –≤ CONFIG_DIR, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
    font = Path(font)
    file = CONFIG_DIR / font.name
    if not font.exists() and not file.exists():
        url = f'https://ultralytics.com/assets/{font.name}'
        LOGGER.info(f'–°–∫–∞—á–∏–≤–∞–Ω–∏–µ {url} –≤ {file}...')
        torch.hub.download_url_to_file(url, str(file), progress=progress)


def check_dataset(data, autodownload=True):
    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ, –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏/–∏–ª–∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ

    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    extract_dir = ''
    if isinstance(data, (str, Path)) and (is_zipfile(data) or is_tarfile(data)):
        download(data, dir=f'{DATASETS_DIR}/{Path(data).stem}', unzip=True, delete=False, curl=False, threads=1)
        data = next((DATASETS_DIR / Path(data).stem).rglob('*.yaml'))
        extract_dir, autodownload = data.parent, False

    # –ß—Ç–µ–Ω–∏–µ yaml (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if isinstance(data, (str, Path)):
        data = yaml_load(data)  # —Å–ª–æ–≤–∞—Ä—å

    # –ü—Ä–æ–≤–µ—Ä–∫–∏
    for k in 'train', 'val', 'names':
        assert k in data, emojis(f"–í data.yaml –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ '{k}:'")
    if isinstance(data['names'], (list, tuple)):  # —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –º–∞—Å—Å–∏–≤–∞
        data['names'] = dict(enumerate(data['names']))  # –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å
    assert all(isinstance(k, int) for k in data['names'].keys()), '–ö–ª—é—á–∏ –≤ data.yaml –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ü–µ–ª—ã–º–∏ —á–∏—Å–ª–∞–º–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, 2: car'
    data['nc'] = len(data['names'])

    # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –ø—É—Ç–µ–π
    path = Path(extract_dir or data.get('path') or '')  # –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π 'path' –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é '.'
    if not path.is_absolute():
        path = (ROOT / path).resolve()
        data['path'] = path  # –∫–∞—Ç–∞–ª–æ–≥ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
    for k in 'train', 'val', 'test':
        if data.get(k):  # –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—É—Ç–∏
            if isinstance(data[k], str):
                x = (path / data[k]).resolve()
                if not x.exists() and data[k].startswith('../'):
                    x = (path / data[k][3:]).resolve()
                data[k] = str(x)
            else:
                data[k] = [str((path / x).resolve()) for x in data[k]]

    # –ü–∞—Ä—Å–∏–Ω–≥ yaml
    train, val, test, s = (data.get(x) for x in ('train', 'val', 'test', 'download'))
    if val:
        val = [Path(x).resolve() for x in val]  # val –ø—É—Ç—å
        if not all(x.exists() for x in val):
            LOGGER.info('\n–ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω ‚ö†Ô∏è, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—É—Ç–∏ %s' % [str(x) for x in val if not x.exists()])
            if not s or not autodownload:
                raise Exception('–ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω ‚ùå')
            t = time.time()
            if s.startswith('http') and s.endswith('.zip'):  # URL
                f = Path(s).name  # –∏–º—è —Ñ–∞–π–ª–∞
                LOGGER.info(f'–°–∫–∞—á–∏–≤–∞–Ω–∏–µ {s} –≤ {f}...')
                torch.hub.download_url_to_file(s, f)
                Path(DATASETS_DIR).mkdir(parents=True, exist_ok=True)  # —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ—Ä–Ω–µ–≤–æ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞
                unzip_file(f, path=DATASETS_DIR)  # —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞
                Path(f).unlink()  # —É–¥–∞–ª–µ–Ω–∏–µ zip
                r = None  # —É—Å–ø–µ—à–Ω–æ—Å—Ç—å
            elif s.startswith('bash '):  # bash —Å–∫—Ä–∏–ø—Ç
                LOGGER.info(f'–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ {s} ...')
                r = os.system(s)
            else:  # python —Å–∫—Ä–∏–ø—Ç
                r = exec(s, {'yaml': data})  # –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None
            dt = f'({round(time.time() - t, 1)}—Å)'
            s = f"—É—Å–ø–µ—à–Ω–æ ‚úÖ {dt}, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {colorstr('bold', DATASETS_DIR)}" if r in (0, None) else f"–Ω–µ—É–¥–∞—á–Ω–æ {dt} ‚ùå"
            LOGGER.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö {s}")
    check_font('Arial.ttf' if is_ascii(data['names']) else 'Arial.Unicode.ttf', progress=True)  # –∑–∞–≥—Ä—É–∑–∫–∞ —à—Ä–∏—Ñ—Ç–æ–≤
    return data  # —Å–ª–æ–≤–∞—Ä—å


def check_amp(model):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–º–µ—à–∞–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ (AMP) PyTorch. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–π —Ä–∞–±–æ—Ç–µ
    from models.common import AutoShape, DetectMultiBackend

    def amp_allclose(model, im):
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–ª–∏–∑–æ—Å—Ç–∏ FP32 –∏ AMP —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        m = AutoShape(model, verbose=False)  # –º–æ–¥–µ–ª—å
        a = m(im).xywhn[0]  # –≤—ã–≤–æ–¥ FP32
        m.amp = True
        b = m(im).xywhn[0]  # –≤—ã–≤–æ–¥ AMP
        return a.shape == b.shape and torch.allclose(a, b, atol=0.1)  # –±–ª–∏–∑–æ—Å—Ç—å —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é 10%

    prefix = colorstr('AMP: ')
    device = next(model.parameters()).device  # —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏
    if device.type in ('cpu', 'mps'):
        return False  # AMP –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ CUDA —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö
    f = ROOT / 'data' / 'images' / 'bus.jpg'  # –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    im = f if f.exists() else 'https://ultralytics.com/images/bus.jpg' if check_online() else np.ones((640, 640, 3))
    try:
        assert amp_allclose(deepcopy(model), im) or amp_allclose(DetectMultiBackend('yolov5n.pt', device), im)
        LOGGER.info(f'{prefix}–ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ ‚úÖ')
        return True
    except Exception:
        help_url = 'https://github.com/ultralytics/yolov5/issues/7908'
        LOGGER.warning(f'{prefix}–ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω—ã —Å –æ—à–∏–±–∫–æ–π ‚ùå, –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–º–µ—à–∞–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏. –°–º–æ—Ç—Ä–∏—Ç–µ {help_url}')
        return False


def yaml_load(file='data.yaml'):
    # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ YAML –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
    with open(file, errors='ignore') as f:
        return yaml.safe_load(f)


def yaml_save(file='data.yaml', data={}):
    # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–ø–∏—Å—å YAML –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
    with open(file, 'w') as f:
        yaml.safe_dump({k: str(v) if isinstance(v, Path) else v for k, v in data.items()}, f, sort_keys=False)


def unzip_file(file, path=None, exclude=('.DS_Store', '__MACOSX')):
    # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ *.zip —Ñ–∞–π–ª–∞ –≤ path/, –∏—Å–∫–ª—é—á–∞—è —Ñ–∞–π–ª—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —Å—Ç—Ä–æ–∫–∏ –≤ exclude
    if path is None:
        path = Path(file).parent  # –∫–∞—Ç–∞–ª–æ–≥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    with ZipFile(file) as zipObj:
        for f in zipObj.namelist():  # —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ zip
            if all(x not in f for x in exclude):
                zipObj.extract(f, path=path)


def url2file(url):
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ URL –≤ –∏–º—è —Ñ–∞–π–ª–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä, https://url.com/file.txt?auth -> file.txt
    url = str(Path(url)).replace(':/', '://')  # Pathlib –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç :// –≤ :/
    return Path(urllib.parse.unquote(url)).name.split('?')[0]  # '%2F' –≤ '/', —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ https://url.com/file.txt?auth


def download(url, dir='.', unzip=True, delete=True, curl=False, threads=1, retry=3):
    # –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ —Ñ–∞–π–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –≤ data.yaml –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
    def download_one(url, dir):
        # –ó–∞–≥—Ä—É–∑–∫–∞ 1 —Ñ–∞–π–ª–∞
        success = True
        if os.path.isfile(url):
            f = Path(url)  # –∏–º—è —Ñ–∞–π–ª–∞
        else:  # –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
            f = dir / Path(url).name
            LOGGER.info(f'–°–∫–∞—á–∏–≤–∞–Ω–∏–µ {url} –≤ {f}...')
            for i in range(retry + 1):
                if curl:
                    s = 'sS' if threads > 1 else ''  # —Ç–∏—Ö–∏–π —Ä–µ–∂–∏–º
                    r = os.system(f'curl -# -{s}L "{url}" -o "{f}"')
                    success = r == 0
                else:
                    torch.hub.download_url_to_file(url, f, progress=threads == 1)  # –∑–∞–≥—Ä—É–∑–∫–∞ torch
                    success = f.is_file()
                if success:
                    break
                elif i < retry:
                    LOGGER.warning(f'‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏, –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ {i + 1}/{retry} {url}...')
                else:
                    LOGGER.warning(f'‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å {url}...')

        if unzip and success and (f.suffix == '.gz' or is_zipfile(f) or is_tarfile(f)):
            LOGGER.info(f'–†–∞—Å–ø–∞–∫–æ–≤–∫–∞ {f}...')
            if is_zipfile(f):
                unzip_file(f, dir)  # —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞
            elif is_tarfile(f):
                os.system(f'tar xf {f} --directory {f.parent}')  # —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞
            elif f.suffix == '.gz':
                os.system(f'tar xfz {f} --directory {f.parent}')  # —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞
            if delete:
                f.unlink()  # —É–¥–∞–ª–µ–Ω–∏–µ zip

    dir = Path(dir)
    dir.mkdir(parents=True, exist_ok=True)  # —Å–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∞
    if threads > 1:
        pool = ThreadPool(threads)
        pool.imap(lambda x: download_one(*x), zip(url, repeat(dir)))  # –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
        pool.close()
        pool.join()
    else:
        for u in [url] if isinstance(url, (str, Path)) else url:
            download_one(u, dir)


def make_divisible(x, divisor):
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–ª–∏–∂–∞–π—à–µ–µ –∫ x, –∫—Ä–∞—Ç–Ω–æ–µ divisor
    if isinstance(divisor, torch.Tensor):
        divisor = int(divisor.max())  # –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ int
    return math.ceil(x / divisor) * divisor


def clean_str(s):
    # –û—á–∏—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É, –∑–∞–º–µ–Ω—è—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ _
    return re.sub(pattern="[|@#!¬°¬∑$‚Ç¨%&()=?¬ø^*;:,¬®¬¥><+]", repl="_", string=s)


def one_cycle(y1=0.0, y2=1.0, steps=100):
    # –õ—è–º–±–¥–∞-—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∏–Ω—É—Å–æ–∏–¥–∞–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞ –æ—Ç y1 –∫ y2 https://arxiv.org/pdf/1812.01187.pdf
    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1


def colorstr(*input):
    # –û–∫—Ä–∞—à–∏–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ https://en.wikipedia.org/wiki/ANSI_escape_code, –Ω–∞–ø—Ä–∏–º–µ—Ä, colorstr('blue', 'bold', 'hello world')
    *args, string = input if len(input) > 1 else ('blue', 'bold', input[0])  # —Ü–≤–µ—Ç–æ–≤—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã, —Å—Ç—Ä–æ–∫–∞
    colors = {
        'black': '\033[30m',  # –±–∞–∑–æ–≤—ã–µ —Ü–≤–µ—Ç–∞
        'red': '\033[31m',
        'green': '\033[32m',
        'yellow': '\033[33m',
        'blue': '\033[34m',
        'magenta': '\033[35m',
        'cyan': '\033[36m',
        'white': '\033[37m',
        'bright_black': '\033[90m',  # —è—Ä–∫–∏–µ —Ü–≤–µ—Ç–∞
        'bright_red': '\033[91m',
        'bright_green': '\033[92m',
        'bright_yellow': '\033[93m',
        'bright_blue': '\033[94m',
        'bright_magenta': '\033[95m',
        'bright_cyan': '\033[96m',
        'bright_white': '\033[97m',
        'end': '\033[0m',  # –ø—Ä–æ—á–µ–µ
        'bold': '\033[1m',
        'underline': '\033[4m'}
    return ''.join(colors[x] for x in args) + f'{string}' + colors['end']


def labels_to_class_weights(labels, nc=80):
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤ (–æ–±—Ä–∞—Ç–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞) –∏–∑ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –º–µ—Ç–æ–∫
    if labels[0] is None:  # –º–µ—Ç–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç
        return torch.Tensor()

    labels = np.concatenate(labels, 0)  # labels.shape = (866643, 5) –¥–ª—è COCO
    classes = labels[:, 0].astype(int)  # –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
    weights = np.bincount(classes, minlength=nc)  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ö–æ–∂–¥–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ—á–µ–∫ —Å–µ—Ç–∫–∏ –≤ –Ω–∞—á–∞–ª–æ (–¥–ª—è uCE —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏)
    # gpi = ((320 / 32 * np.array([1, 2, 4])) ** 2 * 3).sum()  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ —Å–µ—Ç–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    # weights = np.hstack([gpi * len(labels)  - weights.sum() * 9, weights * 9]) ** 0.5  # –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–æ—á–µ–∫ —Å–µ—Ç–∫–∏ –≤ –Ω–∞—á–∞–ª–æ

    weights[weights == 0] = 1  # –∑–∞–º–µ–Ω–∞ –ø—É—Å—Ç—ã—Ö –±–∏–Ω–æ–≤ –Ω–∞ 1
    weights = 1 / weights  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–µ–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
    weights /= weights.sum()  # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    return torch.from_numpy(weights).float()


def labels_to_image_weights(labels, nc=80, class_weights=np.ones(80)):
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ class_weights –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: index = random.choices(range(n), weights=image_weights, k=1)  # –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –≤—ã–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    class_counts = np.array([np.bincount(x[:, 0].astype(int), minlength=nc) for x in labels])
    return (class_weights.reshape(1, nc) * class_counts).sum(1)


def coco80_to_coco91_class():  # converts 80-index (val2014) to 91-index (paper)
    # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/
    # a = np.loadtxt('data/coco.names', dtype='str', delimiter='\n')
    # b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\n')
    # x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]  # darknet to coco
    # x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]  # coco to darknet
    return [
        1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34,
        35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,
        64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]


def xyxy2xywh(x):
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ nx4 –∫–æ—Ä–æ–±–æ–∫ –∏–∑ [x1, y1, x2, y2] –≤ [x, y, w, h], –≥–¥–µ xy1 - –≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π —É–≥–æ–ª, xy2 - –Ω–∏–∂–Ω–∏–π –ø—Ä–∞–≤—ã–π —É–≥–æ–ª
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = (x[:, 0] + x[:, 2]) / 2  # —Ü–µ–Ω—Ç—Ä x
    y[:, 1] = (x[:, 1] + x[:, 3]) / 2  # —Ü–µ–Ω—Ç—Ä y
    y[:, 2] = x[:, 2] - x[:, 0]  # —à–∏—Ä–∏–Ω–∞
    y[:, 3] = x[:, 3] - x[:, 1]  # –≤—ã—Å–æ—Ç–∞
    return y


def xywh2xyxy(x):
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ nx4 –∫–æ—Ä–æ–±–æ–∫ –∏–∑ [x, y, w, h] –≤ [x1, y1, x2, y2], –≥–¥–µ xy1 - –≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π —É–≥–æ–ª, xy2 - –Ω–∏–∂–Ω–∏–π –ø—Ä–∞–≤—ã–π —É–≥–æ–ª
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = x[:, 0] - x[:, 2] / 2  # –≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π x
    y[:, 1] = x[:, 1] - x[:, 3] / 2  # –≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π y
    y[:, 2] = x[:, 0] + x[:, 2] / 2  # –Ω–∏–∂–Ω–∏–π –ø—Ä–∞–≤—ã–π x
    y[:, 3] = x[:, 1] + x[:, 3] / 2  # –Ω–∏–∂–Ω–∏–π –ø—Ä–∞–≤—ã–π y
    return y


def xywhn2xyxy(x, w=640, h=640, padw=0, padh=0):
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ nx4 –∫–æ—Ä–æ–±–æ–∫ –∏–∑ [x, y, w, h] normalized –≤ [x1, y1, x2, y2], –≥–¥–µ xy1 - –≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π —É–≥–æ–ª, xy2 - –Ω–∏–∂–Ω–∏–π –ø—Ä–∞–≤—ã–π —É–≥–æ–ª
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = w * (x[:, 0] - x[:, 2] / 2) + padw  # –≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π x
    y[:, 1] = h * (x[:, 1] - x[:, 3] / 2) + padh  # –≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π y
    y[:, 2] = w * (x[:, 0] + x[:, 2] / 2) + padw  # –Ω–∏–∂–Ω–∏–π –ø—Ä–∞–≤—ã–π x
    y[:, 3] = h * (x[:, 1] + x[:, 3] / 2) + padh  # –Ω–∏–∂–Ω–∏–π –ø—Ä–∞–≤—ã–π y
    return y


def xyxy2xywhn(x, w=640, h=640, clip=False, eps=0.0):
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ nx4 –∫–æ—Ä–æ–±–æ–∫ –∏–∑ [x1, y1, x2, y2] –≤ [x, y, w, h] normalized, –≥–¥–µ xy1 - –≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π —É–≥–æ–ª, xy2 - –Ω–∏–∂–Ω–∏–π –ø—Ä–∞–≤—ã–π —É–≥–æ–ª
    if clip:
        clip_boxes(x, (h - eps, w - eps))  # –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –Ω–∞ –º–µ—Å—Ç–µ
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = ((x[:, 0] + x[:, 2]) / 2) / w  # —Ü–µ–Ω—Ç—Ä x
    y[:, 1] = ((x[:, 1] + x[:, 3]) / 2) / h  # —Ü–µ–Ω—Ç—Ä y
    y[:, 2] = (x[:, 2] - x[:, 0]) / w  # —à–∏—Ä–∏–Ω–∞
    y[:, 3] = (x[:, 3] - x[:, 1]) / h  # –≤—ã—Å–æ—Ç–∞
    return y


def xyn2xy(x, w=640, h=640, padw=0, padh=0):
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ –ø–∏–∫—Å–µ–ª—å–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã, —Ñ–æ—Ä–º–∞ (n,2)
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = w * x[:, 0] + padw  # –≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π x
    y[:, 1] = h * x[:, 1] + padh  # –≤–µ—Ä—Ö–Ω–∏–π –ª–µ–≤—ã–π y
    return y


def segment2box(segment, width=640, height=640):
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞ –º–µ—Ç–∫–∏ 1 –≤ –∫–æ—Ä–æ–±–∫—É 1, –ø—Ä–∏–º–µ–Ω—è—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≤–Ω—É—Ç—Ä–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ç–æ –µ—Å—Ç—å (xy1, xy2, ...) –≤ (xyxy)
    x, y = segment.T  # —Å–µ–≥–º–µ–Ω—Ç xy
    inside = (x >= 0) & (y >= 0) & (x <= width) & (y <= height)
    x, y, = x[inside], y[inside]
    return np.array([x.min(), y.min(), x.max(), y.max()]) if any(x) else np.zeros((1, 4))  # xyxy


def segments2boxes(segments):
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ –º–µ—Ç–∫–∏ –∫–æ—Ä–æ–±–æ–∫, —Ç–æ –µ—Å—Ç—å (cls, xy1, xy2, ...) –≤ (cls, xywh)
    boxes = []
    for s in segments:
        x, y = s.T  # —Å–µ–≥–º–µ–Ω—Ç xy
        boxes.append([x.min(), y.min(), x.max(), y.max()])  # cls, xyxy
    return xyxy2xywh(np.array(boxes))  # cls, xywh


def resample_segments(segments, n=1000):
    # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞ (n,2)
    for i, s in enumerate(segments):
        s = np.concatenate((s, s[0:1, :]), axis=0)
        x = np.linspace(0, len(s) - 1, n)
        xp = np.arange(len(s))
        segments[i] = np.concatenate([np.interp(x, xp, s[:, i]) for i in range(2)]).reshape(2, -1).T  # —Å–µ–≥–º–µ–Ω—Ç xy
    return segments


def scale_boxes(img1_shape, boxes, img0_shape, ratio_pad=None):
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ—Ä–æ–±–æ–∫ (xyxy) –∏–∑ img1_shape –≤ img0_shape
    if ratio_pad is None:  # —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –∏–∑ img0_shape
        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new
        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ wh
    else:
        gain = ratio_pad[0][0]
        pad = ratio_pad[1]

    boxes[:, [0, 2]] -= pad[0]  # –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ x
    boxes[:, [1, 3]] -= pad[1]  # –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ y
    boxes[:, :4] /= gain
    clip_boxes(boxes, img0_shape)
    return boxes


def scale_segments(img1_shape, segments, img0_shape, ratio_pad=None, normalize=False):
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (xy1,xy2,...) –∏–∑ img1_shape –≤ img0_shape
    if ratio_pad is None:  # —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –∏–∑ img0_shape
        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new
        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ wh
    else:
        gain = ratio_pad[0][0]
        pad = ratio_pad[1]

    segments[:, 0] -= pad[0]  # –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ x
    segments[:, 1] -= pad[1]  # –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ y
    segments /= gain
    clip_segments(segments, img0_shape)
    if normalize:
        segments[:, 0] /= img0_shape[1]  # —à–∏—Ä–∏–Ω–∞
        segments[:, 1] /= img0_shape[0]  # –≤—ã—Å–æ—Ç–∞
    return segments


def clip_boxes(boxes, shape):
    # –û–±—Ä–µ–∑–∫–∞ –∫–æ—Ä–æ–±–æ–∫ (xyxy) –¥–æ —Ä–∞–∑–º–µ—Ä–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–≤—ã—Å–æ—Ç–∞, —à–∏—Ä–∏–Ω–∞)
    if isinstance(boxes, torch.Tensor):  # –±—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏
        boxes[:, 0].clamp_(0, shape[1])  # x1
        boxes[:, 1].clamp_(0, shape[0])  # y1
        boxes[:, 2].clamp_(0, shape[1])  # x2
        boxes[:, 3].clamp_(0, shape[0])  # y2
    else:  # np.array (–±—ã—Å—Ç—Ä–∞—è –≥—Ä—É–ø–ø–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)
        boxes[:, [0, 2]] = boxes[:, [0, 2]].clip(0, shape[1])  # x1, x2
        boxes[:, [1, 3]] = boxes[:, [1, 3]].clip(0, shape[0])  # y1, y2


def clip_segments(segments, shape):
    # –û–±—Ä–µ–∑–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (xy1,xy2,...) –¥–æ —Ä–∞–∑–º–µ—Ä–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–≤—ã—Å–æ—Ç–∞, —à–∏—Ä–∏–Ω–∞)
    if isinstance(segments, torch.Tensor):  # –±—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏
        segments[:, 0].clamp_(0, shape[1])  # x
        segments[:, 1].clamp_(0, shape[0])  # y
    else:  # np.array (–±—ã—Å—Ç—Ä–∞—è –≥—Ä—É–ø–ø–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)
        segments[:, 0] = segments[:, 0].clip(0, shape[1])  # x
        segments[:, 1] = segments[:, 1].clip(0, shape[0])  # y


def non_max_suppression(
        prediction,
        conf_thres=0.25,
        iou_thres=0.45,
        classes=None,
        agnostic=False,
        multi_label=False,
        labels=(),
        max_det=300,
        nm=0,  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Å–æ–∫
):
    """–ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–º–∞–∫—Å–∏–º—É–º–æ–≤ (NMS) –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –≤—ã–≤–æ–¥–∞ –¥–ª—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏—Ö—Å—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
         —Å–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π, –Ω–∞ –∫–∞–∂–¥–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ (n,6) —Ç–µ–Ω–∑–æ—Ä [xyxy, conf, cls]
    """

    if isinstance(prediction, (list, tuple)):  # –º–æ–¥–µ–ª—å YOLOv5 –≤ —Ä–µ–∂–∏–º–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –≤—ã—Ö–æ–¥ = (–≤—ã–≤–æ–¥_inference, –≤—ã—Ö–æ–¥_loss)
        prediction = prediction[0]  # –≤—ã–±—Ä–∞—Ç—å —Ç–æ–ª—å–∫–æ –≤—ã–≤–æ–¥ inference

    device = prediction.device
    mps = 'mps' in device.type  # Apple MPS
    if mps:  # MPS –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è, –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Ç–µ–Ω–∑–æ—Ä—ã –≤ CPU –ø–µ—Ä–µ–¥ NMS
        prediction = prediction.cpu()
    bs = prediction.shape[0]  # —Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞
    nc = prediction.shape[2] - nm - 5  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
    xc = prediction[..., 4] > conf_thres  # –∫–∞–Ω–¥–∏–¥–∞—Ç—ã

    # –ü—Ä–æ–≤–µ—Ä–∫–∏
    assert 0 <= conf_thres <= 1, f'–ù–µ–¥–æ–ø—É—Å—Ç–∏–º–∞—è –ø–æ—Ä–æ–≥–æ–≤–∞—è Confidence {conf_thres}, –¥–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ–∂–¥—É 0.0 –∏ 1.0'
    assert 0 <= iou_thres <= 1, f'–ù–µ–¥–æ–ø—É—Å—Ç–∏–º–∞—è IoU {iou_thres}, –¥–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ–∂–¥—É 0.0 –∏ 1.0'

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    # min_wh = 2  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –∏ –≤—ã—Å–æ—Ç–∞ –∫–æ—Ä–æ–±–∫–∏ (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)
    max_wh = 7680  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –∏ –≤—ã—Å–æ—Ç–∞ –∫–æ—Ä–æ–±–∫–∏ (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)
    max_nms = 30000  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ—Ä–æ–±–æ–∫ –¥–ª—è torchvision.ops.nms()
    time_limit = 0.5 + 0.05 * bs  # —Å–µ–∫—É–Ω–¥—ã –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    redundant = True  # —Ç—Ä–µ–±–æ–≤–∞—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
    multi_label &= nc > 1  # –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Ç–æ–∫ –Ω–∞ –∫–æ—Ä–æ–±–∫—É (–¥–æ–±–∞–≤–ª—è–µ—Ç 0,5 –º—Å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)
    merge = False  # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å merge-NMS

    t = time.time()
    mi = 5 + nc  # –∏–Ω–¥–µ–∫—Å –Ω–∞—á–∞–ª–∞ –º–∞—Å–∫–∏
    output = [torch.zeros((0, 6 + nm), device=prediction.device)] * bs
    for xi, x in enumerate(prediction):  # –∏–Ω–¥–µ–∫—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤—ã–≤–æ–¥ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
        # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # —à–∏—Ä–∏–Ω–∞-–≤—ã—Å–æ—Ç–∞
        x = x[xc[xi]]  # confidence

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞–ø—Ä–∏–æ—Ä–Ω—ã—Ö –º–µ—Ç–æ–∫
        if labels and len(labels[xi]):
            lb = labels[xi]
            v = torch.zeros((len(lb), nc + nm + 5), device=x.device)
            v[:, :4] = lb[:, 1:5]  # –∫–æ—Ä–æ–±–∫–∞
            v[:, 4] = 1.0  # conf
            v[range(len(lb)), lb[:, 0].long() + 5] = 1.0  # cls
            x = torch.cat((x, v), 0)

        # –ï—Å–ª–∏ –Ω–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        if not x.shape[0]:
            continue

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ conf
        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf

        # –ö–æ—Ä–æ–±–∫–∞/–ú–∞—Å–∫–∞
        box = xywh2xyxy(x[:, :4])  # center_x, center_y, width, height) –≤ (x1, y1, x2, y2)
        mask = x[:, mi:]  # –Ω—É–ª–µ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã, –µ—Å–ª–∏ –Ω–µ—Ç –º–∞—Å–æ–∫

        # –ú–∞—Ç—Ä–∏—Ü–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π nx6 (xyxy, conf, cls)
        if multi_label:
            i, j = (x[:, 5:mi] > conf_thres).nonzero(as_tuple=False).T
            x = torch.cat((box[i], x[i, 5 + j, None], j[:, None].float(), mask[i]), 1)
        else:  # —Ç–æ–ª—å–∫–æ –ª—É—á—à–∏–π –∫–ª–∞—Å—Å
            conf, j = x[:, 5:mi].max(1, keepdim=True)
            x = torch.cat((box, conf, j.float(), mask), 1)[conf.view(-1) > conf_thres]

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª–∞—Å—Å—É
        if classes is not None:
            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]

        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω–µ—á–Ω–æ–≥–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
        # if not torch.isfinite(x).all():
        #     x = x[torch.isfinite(x).all(1)]

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º—ã
        n = x.shape[0]  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ—Ä–æ–±–æ–∫
        if not n:  # –Ω–µ—Ç –∫–æ—Ä–æ–±–æ–∫
            continue
        elif n > max_nms:  # –∏–∑–±—ã—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ—Ä–æ–±–æ–∫
            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ confidence
        else:
            x = x[x[:, 4].argsort(descending=True)]  # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ confidence

        # –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–º–∞–∫—Å–∏–º—É–º–æ–≤ (NMS)
        c = x[:, 5:6] * (0 if agnostic else max_wh)  # –∫–ª–∞—Å—Å—ã
        boxes, scores = x[:, :4] + c, x[:, 4]  # –∫–æ—Ä–æ–±–∫–∏ (—Å–º–µ—â–µ–Ω—ã –∫–ª–∞—Å—Å–æ–º), –æ—Ü–µ–Ω–∫–∏
        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS
        if i.shape[0] > max_det:  # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π
            i = i[:max_det]
        if merge and (1 < n < 3E3):  # Merge-NMS
            # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ—Ä–æ–±–æ–∫ –∫–∞–∫ boxes(i,4) = –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ boxes
            iou = box_iou(boxes[i], boxes) > iou_thres  # –º–∞—Ç—Ä–∏—Ü–∞ iou
            weights = iou * scores[None]  # –≤–µ—Å–∞ –∫–æ—Ä–æ–±–æ–∫
            x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –∫–æ—Ä–æ–±–∫–∏
            if redundant:
                i = i[iou.sum(1) > 1]  # —Ç—Ä–µ–±–æ–≤–∞—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç—å

        output[xi] = x[i]
        if mps:
            output[xi] = output[xi].to(device)
        if (time.time() - t) > time_limit:
            LOGGER.warning(f'WARNING ‚ö†Ô∏è –í—Ä–µ–º—è NMS {time_limit:.3f}—Å –∏—Å—Ç–µ–∫–ª–æ')
            break  # –ø—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è

    return output


def strip_optimizer(f='best.pt', s=''):  # from utils.general import *; strip_optimizer()
    # –£–¥–∞–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∏–∑ 'f' –¥–ª—è —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏, –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ 's'
    x = torch.load(f, map_location=torch.device('cpu'))
    if x.get('ema'):
        x['model'] = x['ema']  # –∑–∞–º–µ–Ω–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ ema
    for k in 'optimizer', 'best_fitness', 'ema', 'updates':  # –∫–ª—é—á–∏
        x[k] = None
    x['epoch'] = -1
    x['model'].half()  # –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ FP16
    for p in x['model'].parameters():
        p.requires_grad = False
    torch.save(x, s or f)
    mb = os.path.getsize(s or f) / 1E6  # —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    LOGGER.info(f"–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —É–¥–∞–ª–µ–Ω –∏–∑ {f},{f' —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ {s},' –µ—Å–ª–∏ {s} —É–∫–∞–∑–∞–Ω–æ {mb:.1f}MB")


def print_mutation(keys, results, hyp, save_dir, bucket, prefix=colorstr('evolve: ')):
    evolve_csv = save_dir / 'evolve.csv'
    evolve_yaml = save_dir / 'hyp_evolve.yaml'
    keys = tuple(keys) + tuple(hyp.keys())  # [results + hyps]
    keys = tuple(x.strip() for x in keys)
    vals = results + tuple(hyp.values())
    n = len(keys)

    # –ó–∞–≥—Ä—É–∑–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if bucket:
        url = f'gs://{bucket}/evolve.csv'
        if gsutil_getsize(url) > (evolve_csv.stat().st_size if evolve_csv.exists() else 0):
            os.system(f'gsutil cp {url} {save_dir}')  # –∑–∞–≥—Ä—É–∑–∫–∞ evolve.csv, –µ—Å–ª–∏ –æ–Ω –±–æ–ª—å—à–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ

    # –ó–∞–ø–∏—Å—å –≤ evolve.csv
    s = '' if evolve_csv.exists() else (('%20s,' * n % keys).rstrip(',') + '\n')  # –∑–∞–≥–æ–ª–æ–≤–æ–∫
    with open(evolve_csv, 'a') as f:
        f.write(s + ('%20.5g,' * n % vals).rstrip(',') + '\n')

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ yaml
    with open(evolve_yaml, 'w') as f:
        data = pd.read_csv(evolve_csv)
        data = data.rename(columns=lambda x: x.strip())  # –æ—á–∏—Å—Ç–∫–∞ –∫–ª—é—á–µ–π
        i = np.argmax(fitness(data.values[:, :4]))  #
        generations = len(data)
        f.write('# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ YOLOv5\n' + f'# –õ—É—á—à–µ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ: {i}\n' +
                f'# –ü–æ—Å–ª–µ–¥–Ω–µ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ: {generations - 1}\n' + '# ' + ', '.join(f'{x.strip():>20s}' for x in keys[:7]) +
                '\n' + '# ' + ', '.join(f'{x:>20.5g}' for x in data.values[i, :7]) + '\n\n')
        yaml.safe_dump(data.loc[i][7:].to_dict(), f, sort_keys=False)

    # –í—ã–≤–æ–¥ –Ω–∞ —ç–∫—Ä–∞–Ω
    LOGGER.info(prefix + f'{generations} –ø–æ–∫–æ–ª–µ–Ω–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ, —Ç–µ–∫—É—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:\n' + prefix +
                ', '.join(f'{x.strip():>20s}' for x in keys) + '\n' + prefix + ', '.join(f'{x:20.5g}'
                                                                                         for x in vals) + '\n\n')

    if bucket:
        os.system(f'gsutil cp {evolve_csv} {evolve_yaml} gs://{bucket}')  # –∑–∞–≥—Ä—É–∑–∫–∞


def apply_classifier(x, model, img, im0):
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤—Ç–æ—Ä–∏—á–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –∫ –≤—ã–≤–æ–¥–∞–º YOLO
    # –ü—Ä–∏–º–µ—Ä model = torchvision.models.__dict__['efficientnet_b0'](pretrained=True).to(device).eval()
    im0 = [im0] if isinstance(im0, np.ndarray) else im0
    for i, d in enumerate(x):  # –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if d is not None and len(d):
            d = d.clone()

            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—ã—Ä–µ–∑–∞–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
            b = xyxy2xywh(d[:, :4])  # –∫–æ—Ä–æ–±–∫–∏
            b[:, 2:] = b[:, 2:].max(1)[0].unsqueeze(1)  # –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–≤–∞–¥—Ä–∞—Ç
            b[:, 2:] = b[:, 2:] * 1.3 + 30  # –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ
            d[:, :4] = xywh2xyxy(b).long()

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ—Ä–æ–±–æ–∫ –æ—Ç img_size –∫ —Ä–∞–∑–º–µ—Ä—É im0
            scale_boxes(img.shape[2:], d[:, :4], im0[i].shape)

            # –ö–ª–∞—Å—Å—ã
            pred_cls1 = d[:, 5].long()
            ims = []
            for a in d:
                cutout = im0[i][int(a[1]):int(a[3]), int(a[0]):int(a[2])]
                im = cv2.resize(cutout, (224, 224))  # BGR

                im = im[:, :, ::-1].transpose(2, 0, 1)  # BGR –≤ RGB, –≤ 3x416x416
                im = np.ascontiguousarray(im, dtype=np.float32)  # uint8 –≤ float32
                im /= 255  # 0 - 255 –≤ 0.0 - 1.0
                ims.append(im)

            pred_cls2 = model(torch.Tensor(ims).to(d.device)).argmax(1)  # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
            x[i] = x[i][pred_cls1 == pred_cls2]  # —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫–ª–∞—Å—Å–æ–≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π

    return x


def increment_path(path, exist_ok=False, sep='', mkdir=False):
    # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø—É—Ç–∏ —Ñ–∞–π–ª–∞ –∏–ª–∏ –∫–∞—Ç–∞–ª–æ–≥–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä, runs/exp --> runs/exp{sep}2, runs/exp{sep}3, ... –∏ —Ç.–¥.
    path = Path(path)  # –æ—Å–æ–∑–Ω–∞–Ω–∏–µ OS
    if path.exists() and not exist_ok:
        path, suffix = (path.with_suffix(''), path.suffix) if path.is_file() else (path, '')

        # –ú–µ—Ç–æ–¥ 1
        for n in range(2, 9999):
            p = f'{path}{sep}{n}{suffix}'  # —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø—É—Ç–∏
            if not os.path.exists(p):  #
                break
        path = Path(p)

        # –ú–µ—Ç–æ–¥ 2 (—É—Å—Ç–∞—Ä–µ–≤—à–∏–π)
        # dirs = glob.glob(f"{path}{sep}*")  # –ø–æ—Ö–æ–∂–∏–µ –ø—É—Ç–∏
        # matches = [re.search(rf"{path.stem}{sep}(\d+)", d) for d in dirs]
        # i = [int(m.groups()[0]) for m in matches if m]  # –∏–Ω–¥–µ–∫—Å—ã
        # n = max(i) + 1 if i else 2  # —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –Ω–æ–º–µ—Ä–∞
        # path = Path(f"{path}{sep}{n}{suffix}")  # —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø—É—Ç–∏

    if mkdir:
        path.mkdir(parents=True, exist_ok=True)  # —Å–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∞

    return path


# –î—Ä—É–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫ –∫–∏—Ç–∞–π—Å–∫–æ–º—É —è–∑—ã–∫—É —Ñ—É–Ω–∫—Ü–∏–∏ OpenCV ------------------------------------------------------------------------------------
imshow_ = cv2.imshow  # –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã—Ö –æ—à–∏–±–æ–∫


def imread(path, flags=cv2.IMREAD_COLOR):
    return cv2.imdecode(np.fromfile(path, np.uint8), flags)


def imwrite(path, im):
    try:
        cv2.imencode(Path(path).suffix, im)[1].tofile(path)
        return True
    except Exception:
        return False


def imshow(path, im):
    imshow_(path.encode('unicode_escape').decode(), im)


cv2.imread, cv2.imwrite, cv2.imshow = imread, imwrite, imshow  # –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ