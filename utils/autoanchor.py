# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
"""
AutoAnchor utils
"""

import random

import numpy as np
import torch
import yaml
from tqdm import tqdm

from utils import TryExcept
from utils.general import LOGGER, TQDM_BAR_FORMAT, colorstr

PREFIX = colorstr('AutoAnchor: ')


def check_anchor_order(m):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä—è–¥–∫–∞ —è–∫–æ—Ä–Ω—ã—Ö –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤ –ø–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—é –∫ –ø–æ—Ä—è–¥–∫—É stride –¥–ª—è –º–æ–¥—É–ª—è YOLOv5 Detect() m, –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
    a = m.anchors.prod(-1).mean(-1).view(-1)  # –°—Ä–µ–¥–Ω—è—è –ø–ª–æ—â–∞–¥—å —è–∫–æ—Ä–Ω–æ–≥–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è
    da = a[-1] - a[0]  # –†–∞–∑–Ω–∏—Ü–∞ –≤ a
    ds = m.stride[-1] - m.stride[0]  # –†–∞–∑–Ω–∏—Ü–∞ –≤ s
    if da and (da.sign() != ds.sign()):  # –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –ø–æ—Ä—è–¥–æ–∫
        LOGGER.info(f'{PREFIX}Reversing anchor order')
        m.anchors[:] = m.anchors.flip(0)


@TryExcept(f'{PREFIX}ERROR')
def check_anchors(dataset, model, thr=4.0, imgsz=640):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —è–∫–æ—Ä–Ω—ã—Ö –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã–º, –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
    m = model.module.model[-1] if hasattr(model, 'module') else model.model[-1]  # Detect()
    shapes = imgsz * dataset.shapes / dataset.shapes.max(1, keepdims=True)
    scale = np.random.uniform(0.9, 1.1, size=(shapes.shape[0], 1))  # –ú–∞—Å—à—Ç–∞–± –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
    wh = torch.tensor(np.concatenate([l[:, 3:5] * s for s, l in zip(shapes * scale, dataset.labels)])).float()  # wh

    def metric(k):  # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        r = wh[:, None] / k[None]
        x = torch.min(r, 1 / r).min(2)[0]  # –ú–µ—Ç—Ä–∏–∫–∞ –æ—Ç–Ω–æ—à–µ–Ω–∏—è
        best = x.max(1)[0]  # –õ—É—á—à–µ–µ x
        aat = (x > 1 / thr).float().sum(1).mean()  # –Ø–∫–æ—Ä–Ω—ã–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
        bpr = (best > 1 / thr).float().mean()  # –õ—É—á—à–∏–π –≤–æ–∑–º–æ–∂–Ω—ã–π –ø–æ–ª–Ω–æ—Ç–∞
        return bpr, aat

    stride = m.stride.to(m.anchors.device).view(-1, 1, 1)  # –®–∞–≥–∏ –º–æ–¥–µ–ª–∏
    anchors = m.anchors.clone() * stride  # –¢–µ–∫—É—â–∏–µ —è–∫–æ—Ä–Ω—ã–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏
    bpr, aat = metric(anchors.cpu().view(-1, 2))
    s = f'\n{PREFIX}{aat:.2f} anchors/target, {bpr:.3f} Best Possible Recall (BPR). '
    if bpr > 0.98:  # –ü–æ—Ä–æ–≥ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        LOGGER.info(f'{s}Current anchors are a good fit to dataset ‚úÖ')
    else:
        LOGGER.info(f'{s}Anchors are a poor fit to dataset ‚ö†Ô∏è, attempting to improve...')
        na = m.anchors.numel() // 2  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–∫–æ—Ä–Ω—ã—Ö –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤
        anchors = kmean_anchors(dataset, n=na, img_size=imgsz, thr=thr, gen=1000, verbose=False)
        new_bpr = metric(anchors)[0]
        if new_bpr > bpr:  # –ó–∞–º–µ–Ω–∏—Ç—å —è–∫–æ—Ä–Ω—ã–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏
            anchors = torch.tensor(anchors, device=m.anchors.device).type_as(m.anchors)
            m.anchors[:] = anchors.clone().view_as(m.anchors)
            check_anchor_order(m)  # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø–∏–∫—Å–µ–ª–µ–π (–Ω–µ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ —Å–µ—Ç–∫–∏)
            m.anchors /= stride
            s = f'{PREFIX}Done ‚úÖ (optional: update model *.yaml to use these anchors in the future)'
        else:
            s = f'{PREFIX}Done ‚ö†Ô∏è (original anchors better than new anchors, proceeding with original anchors)'
        LOGGER.info(s)


def kmean_anchors(dataset='./data/coco128.yaml', n=9, img_size=640, thr=4.0, gen=1000, verbose=True):
    """ –°–æ–∑–¥–∞–µ—Ç —è–∫–æ—Ä–Ω—ã–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º kmeans, –∏–∑ –æ–±—É—á–∞—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            dataset: –ø—É—Ç—å –∫ data.yaml, –∏–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
            n: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–∫–æ—Ä–Ω—ã—Ö –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤
            img_size: —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            thr: –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä –ø–æ—Ä–æ–≥–∞ –æ—Ç–Ω–æ—à–µ–Ω–∏—è wh —è–∫–æ—Ä–Ω–æ–≥–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞ –∫ –º–µ—Ç–∫–µ hyp['anchor_t'], –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é=4.0
            gen: –ø–æ–∫–æ–ª–µ–Ω–∏—è –¥–ª—è —ç–≤–æ–ª—é—Ü–∏–∏ —è–∫–æ—Ä–Ω—ã—Ö –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞
            verbose: –ø–µ—á–∞—Ç–∞—Ç—å –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            k: —è–∫–æ—Ä–Ω—ã–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º kmeans

        –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
            from utils.autoanchor import *; _ = kmean_anchors()
    """
    from scipy.cluster.vq import kmeans

    npr = np.random
    thr = 1 / thr

    def metric(k, wh):  # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        r = wh[:, None] / k[None]
        x = torch.min(r, 1 / r).min(2)[0]  # –ú–µ—Ç—Ä–∏–∫–∞ –æ—Ç–Ω–æ—à–µ–Ω–∏—è
        # x = wh_iou(wh, torch.tensor(k))  # –ú–µ—Ç—Ä–∏–∫–∞ IoU
        return x, x.max(1)[0]  # x, –ª—É—á—à–µ–µ x

    def anchor_fitness(k):  # –§–∏—Ç–Ω–µ—Å –º—É—Ç–∞—Ü–∏–∏
        _, best = metric(torch.tensor(k, dtype=torch.float32), wh)
        return (best * (best > thr).float()).mean()  # –§–∏—Ç–Ω–µ—Å

    def print_results(k, verbose=True):
        k = k[np.argsort(k.prod(1))]  # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –æ—Ç –º–∞–ª–æ–≥–æ –∫ –±–æ–ª—å—à–æ–º—É
        x, best = metric(k, wh0)
        bpr, aat = (best > thr).float().mean(), (x > thr).float().mean() * n  # –õ—É—á—à–∏–π –≤–æ–∑–º–æ–∂–Ω—ã–π –ø–æ–ª–Ω–æ—Ç–∞, —è–∫–æ—Ä—å > thr
        s = f'{PREFIX}thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\n' \
            f'{PREFIX}n={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, ' \
            f'past_thr={x[x > thr].mean():.3f}-mean: '
        for x in k:
            s += '%i,%i, ' % (round(x[0]), round(x[1]))
        if verbose:
            LOGGER.info(s[:-2])
        return k

    if isinstance(dataset, str):  # –§–∞–π–ª *.yaml
        with open(dataset, errors='ignore') as f:
            data_dict = yaml.safe_load(f)  # –°–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–∏
        from utils.dataloaders import LoadImagesAndLabels
        dataset = LoadImagesAndLabels(data_dict['train'], augment=True, rect=True)

    # –ü–æ–ª—É—á–µ–Ω–∏–µ wh –º–µ—Ç–∫–∏
    shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)
    wh0 = np.concatenate([l[:, 3:5] * s for s, l in zip(shapes, dataset.labels)])  # wh

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    i = (wh0 < 3.0).any(1).sum()
    if i:
        LOGGER.info(f'{PREFIX}WARNING ‚ö†Ô∏è Extremely small objects found: {i} of {len(wh0)} labels are <3 pixels in size')
    wh = wh0[(wh0 >= 2.0).any(1)].astype(np.float32)  # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è > 2 –ø–∏–∫—Å–µ–ª—è
    # wh = wh * (npr.rand(wh.shape[0], 1) * 0.9 + 0.1)  # –£–º–Ω–æ–∂–∏—Ç—å –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã–π –º–∞—Å—à—Ç–∞–± 0-1

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Kmeans
    try:
        LOGGER.info(f'{PREFIX}Running kmeans for {n} anchors on {len(wh)} points...')
        assert n <= len(wh)  # –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ
        s = wh.std(0)  # –°–∏–≥–º—ã –¥–ª—è –±–µ–ª–æ–≥–æ —à—É–º–∞
        k = kmeans(wh / s, n, iter=30)[0] * s  # –¢–æ—á–∫–∏
        assert n == len(k)  # kmeans –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –º–µ–Ω—å—à–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫, —á–µ–º –∑–∞–ø—Ä–æ—à–µ–Ω–æ, –µ—Å–ª–∏ wh –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –ø–æ—Ö–æ–∂–∏
    except Exception:
        LOGGER.warning(f'{PREFIX}WARNING ‚ö†Ô∏è switching strategies from kmeans to random init')
        k = np.sort(npr.rand(n * 2)).reshape(n, 2) * img_size  # –°–ª—É—á–∞–π–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    wh, wh0 = (torch.tensor(x, dtype=torch.float32) for x in (wh, wh0))
    k = print_results(k, verbose=False)

    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
    # k, d = [None] * 20, [None] * 20
    # for i in tqdm(range(1, 21)):
    #     k[i-1], d[i-1] = kmeans(wh / s, i)  # –¢–æ—á–∫–∏, —Å—Ä–µ–¥–Ω–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
    # fig, ax = plt.subplots(1, 2, figsize=(14, 7), tight_layout=True)
    # ax = ax.ravel()
    # ax[0].plot(np.arange(1, 21), np.array(d) ** 2, marker='.')
    # fig, ax = plt.subplots(1, 2, figsize=(14, 7))  # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ wh
    # ax[0].hist(wh[wh[:, 0]<100, 0],400)
    # ax[1].hist(wh[wh[:, 1]<100, 1],400)
    # fig.savefig('wh.png', dpi=200)

    # –≠–≤–æ–ª—é—Ü–∏—è
    f, sh, mp, s = anchor_fitness(k), k.shape, 0.9, 0.1  # –§–∏—Ç–Ω–µ—Å, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å, –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º—É—Ç–∞—Ü–∏–∏, —Å–∏–≥–º–∞
    pbar = tqdm(range(gen), bar_format=TQDM_BAR_FORMAT)  # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
    for _ in pbar:
        v = np.ones(sh)
        while (v == 1).all():  # –ú—É—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–æ —Ç–µ—Ö –ø–æ—Ä, –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–µ (–ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã)
            v = ((npr.random(sh) < mp) * random.random() * npr.randn(*sh) * s + 1).clip(0.3, 3.0)
        kg = (k.copy() * v).clip(min=2.0)
        fg = anchor_fitness(kg)
        if fg > f:
            f, k = fg, kg.copy()
            pbar.desc = f'{PREFIX}Evolving anchors with Genetic Algorithm: fitness = {f:.4f}'
            if verbose:
                print_results(k, verbose)

    return print_results(k).astype(np.float32)