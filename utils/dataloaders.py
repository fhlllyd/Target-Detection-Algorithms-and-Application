# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
"""
–ú–æ–¥—É–ª—å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏ —É—Ç–∏–ª–∏—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏
"""

import contextlib
import glob
import hashlib
import json
import math
import os
import random
import shutil
import time
from itertools import repeat
from multiprocessing.pool import Pool, ThreadPool
from pathlib import Path
from threading import Thread
from urllib.parse import urlparse

import numpy as np
import torch
import torch.nn.functional as F
import torchvision
import yaml
from PIL import ExifTags, Image, ImageOps
from torch.utils.data import DataLoader, Dataset, dataloader, distributed
from tqdm import tqdm

# ... (–ò–º–ø–æ—Ä—Ç—ã –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
HELP_URL = '–°–º. https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data'  # –°—Å—ã–ª–∫–∞ –Ω–∞ —Å–ø—Ä–∞–≤–∫—É
IMG_FORMATS = 'bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp', 'pfm'  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
VID_FORMATS = 'asf', 'avi', 'gif', 'm4v', 'mkv', 'mov', 'mp4', 'mpeg', 'mpg', 'ts', 'wmv'  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –≤–∏–¥–µ–æ
LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # –õ–æ–∫–∞–ª—å–Ω—ã–π —Ä–∞–Ω–≥ –¥–ª—èÂàÜÂ∏ÉÂºè –æ–±—É—á–µ–Ω–∏—è
RANK = int(os.getenv('RANK', -1))
PIN_MEMORY = str(os.getenv('PIN_MEMORY', True)).lower() == 'true'  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ñ–ª–∞–≥ –¥–ª—è –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–≥–∞ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏ EXIF
for orientation in ExifTags.TAGS.keys():
    if ExifTags.TAGS[orientation] == 'Orientation':
        break

def get_hash(paths):
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ö–µ—à-—Å—É–º–º—É —Å–ø–∏—Å–∫–∞ –ø—É—Ç–µ–π (—Ñ–∞–π–ª–æ–≤ –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π)
    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # –†–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤
    h = hashlib.md5(str(size).encode())  # –•–µ—à —Ä–∞–∑–º–µ—Ä–æ–≤
    h.update(''.join(paths).encode())  # –•–µ—à –ø—É—Ç–µ–π
    return h.hexdigest()  # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ö–µ—à-—Å—É–º–º—É

def exif_size(img):
    # –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–º–µ—Ä PIL —Å —É—á–µ—Ç–æ–º EXIF-–æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏
    s = img.size  # (—à–∏—Ä–∏–Ω–∞, –≤—ã—Å–æ—Ç–∞)
    try:
        rotation = dict(img._getexif().items())[orientation]
        if rotation in [6, 8]:  # –ü–æ–≤–æ—Ä–æ—Ç –Ω–∞ 270 –∏–ª–∏ 90 –≥—Ä–∞–¥—É—Å–æ–≤
            s = (s[1], s[0])
    except:
        pass
    return s

# ... (–û—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –∫–ª–∞—Å—Å—ã)

class LoadImagesAndLabels(Dataset):
    # –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –º–µ—Ç–æ–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ YOLOv5
    cache_version = 0.6  # –í–µ—Ä—Å–∏—è –∫—ç—à–∞ –º–µ—Ç–æ–∫
    rand_interp_methods = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4]

    def __init__(self,
                 path,
                 img_size=640,
                 batch_size=16,
                 augment=False,
                 hyp=None,
                 rect=False,
                 image_weights=False,
                 cache_images=False,
                 single_cls=False,
                 stride=32,
                 pad=0.0,
                 min_items=0,
                 prefix=''):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        self.img_size = img_size
        self.augment = augment
        self.hyp = hyp
        self.image_weights = image_weights
        self.rect = rect
        self.mosaic = augment and not rect  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–∑–∞–∏–∫—É (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏)
        self.mosaic_border = [-img_size // 2, -img_size // 2]
        self.stride = stride
        self.path = path
        self.albumentations = Albumentations(size=img_size) if augment else None

        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        try:
            # –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏–ª–∏ —Ñ–∞–π–ª–µ
            f = []  # –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
            for p in path if isinstance(path, list) else [path]:
                p = Path(p)
                if p.is_dir():  # –ï—Å–ª–∏ –ø—É—Ç—å ‚Äî –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
                    f += glob.glob(str(p / '**' / '*.*'), recursive=True)
                elif p.is_file():  # –ï—Å–ª–∏ –ø—É—Ç—å ‚Äî —Ñ–∞–π–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Å –ø—É—Ç—è–º–∏)
                    with open(p) as t:
                        t = t.read().strip().splitlines()
                        parent = str(p.parent) + os.sep
                        f += [x.replace('./', parent, 1) if x.startswith('./') else x for x in t]
            self.im_files = sorted(x for x in f if x.split('.')[-1].lower() in IMG_FORMATS)
            assert self.im_files, f'{prefix}–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π'
        except Exception as e:
            raise Exception(f'{prefix}–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {path}: {e}\n{HELP_URL}') from e

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–æ–∫ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
        self.label_files = img2label_paths(self.im_files)  # –ü—É—Ç–∏ –∫ –º–µ—Ç–∫–∞–º
        cache_path = (p if p.is_file() else Path(self.label_files[0]).parent).with_suffix('.cache')
        try:
            cache, exists = np.load(cache_path, allow_pickle=True).item(), True
            assert cache['version'] == self.cache_version
            assert cache['hash'] == get_hash(self.label_files + self.im_files)
        except:
            cache, exists = self.cache_labels(cache_path, prefix), False

        # ... (–û—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –∫–ª–∞—Å—Å–∞)

    def __getitem__(self, index):
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        index = self.indices[index]  # –õ–∏–Ω–µ–π–Ω—ã–π, –ø–µ—Ä–µ–º–µ—à–∞–Ω–Ω—ã–π –∏–ª–∏ –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å

        hyp = self.hyp
        mosaic = self.mosaic and random.random() < hyp['mosaic']
        if mosaic:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–∑–∞–∏–∫–∏ (4 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
            img, labels = self.load_mosaic(index)
            shapes = None

            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ MixUp
            if random.random() < hyp['mixup']:
                img, labels = mixup(img, labels, *self.load_mosaic(random.randint(0, self.n - 1)))

        else:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—ã—á–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            img, (h0, w0), (h, w) = self.load_image(index)

            # –ü—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ (letterbox)
            shape = self.batch_shapes[self.batch[index]] if self.rect else self.img_size
            img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)
            shapes = (h0, w0), ((h / h0, w / w0), pad)

            labels = self.labels[index].copy()
            if labels.size:
                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], ratio[0] * w, ratio[1] * h, padw=pad[0], padh=pad[1])

            if self.augment:
                img, labels = random_perspective(img,
                                                 labels,
                                                 degrees=hyp['degrees'],
                                                 translate=hyp['translate'],
                                                 scale=hyp['scale'],
                                                 shear=hyp['shear'],
                                                 perspective=hyp['perspective'])

        # ... (–û—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –º–µ—Ç–æ–¥–∞)

def create_dataloader(path,
                      imgsz,
                      batch_size,
                      stride,
                      single_cls=False,
                      hyp=None,
                      augment=False,
                      cache=False,
                      pad=0.0,
                      rect=False,
                      rank=-1,
                      workers=8,
                      image_weights=False,
                      quad=False,
                      prefix='',
                      shuffle=False):
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    if rect and shuffle:
        LOGGER.warning('–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï ‚ö†Ô∏è --rect –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º —Åshuffle, shuffle –≤—ã–∫–ª—é—á–µ–Ω')
        shuffle = False
    with torch_distributed_zero_first(rank):  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫—ç—à–∞ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ÂàÜÂ∏ÉÂºè –æ–±—É—á–µ–Ω–∏–∏
        dataset = LoadImagesAndLabels(
            path,
            imgsz,
            batch_size,
            augment=augment,
            hyp=hyp,
            rect=rect,
            cache_images=cache,
            single_cls=single_cls,
            stride=int(stride),
            pad=pad,
            image_weights=image_weights,
            prefix=prefix)

    batch_size = min(batch_size, len(dataset))
    nd = torch.cuda.device_count()
    nw = min([os.cpu_count() // max(nd, 1), batch_size if batch_size > 1 else 0, workers])
    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)
    loader = DataLoader if image_weights else InfiniteDataLoader
    generator = torch.Generator()
    generator.manual_seed(6148914691236517205 + RANK)
    return loader(dataset,
                  batch_size=batch_size,
                  shuffle=shuffle and sampler is None,
                  num_workers=nw,
                  sampler=sampler,
                  pin_memory=PIN_MEMORY,
                  collate_fn=LoadImagesAndLabels.collate_fn4 if quad else LoadImagesAndLabels.collate_fn,
                  worker_init_fn=seed_worker,
                  generator=generator), dataset